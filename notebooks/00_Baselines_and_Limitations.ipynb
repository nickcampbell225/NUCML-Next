{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML for Nuclear Data: A Supervised Learning Starting Point\n",
    "\n",
    "This notebook trains and evaluates two classical supervised-learning models\n",
    "-- a Decision Tree and an XGBoost ensemble -- on neutron-induced\n",
    "cross-section data from the EXFOR database.\n",
    "\n",
    "### Why nuclear data?\n",
    "\n",
    "Nuclear cross sections describe the probability of a reaction occurring\n",
    "when a neutron strikes a target nucleus. They depend on:\n",
    "\n",
    "- **Energy** -- cross sections vary over many orders of magnitude as\n",
    "  incident energy changes from thermal (~0.01 eV) to fast (~20 MeV).\n",
    "- **Isotope** (Z, A) -- each target nucleus has a different cross-section\n",
    "  curve.\n",
    "- **Reaction channel** (MT code) -- fission, capture, elastic scattering,\n",
    "  (n,p), etc. each have distinct energy dependences.\n",
    "\n",
    "The EXFOR database aggregates experimental measurements from laboratories\n",
    "worldwide. Individual datasets vary in energy coverage, resolution, and\n",
    "reported uncertainties, making cross-section prediction a heterogeneous\n",
    "regression problem.\n",
    "\n",
    "### Supervised learning setup\n",
    "\n",
    "| | |\n",
    "|---|---|\n",
    "| **Inputs (features)** | Z, A, N, Energy, particle-emission vector, AME2020 nuclear properties |\n",
    "| **Target** | Cross section $\\sigma$ (barns) |\n",
    "| **Training set** | Full EXFOR database (all isotopes, neutron-induced) |\n",
    "| **Evaluation isotopes** | U-235 fission (data-rich) and Cl-35 (n,p) (data-sparse) |\n",
    "\n",
    "### What this notebook covers\n",
    "\n",
    "- **Data loading** -- EXFOR measurements filtered to neutron-induced\n",
    "  reactions in the 0.01 eV -- 20 MeV range, with configurable feature tiers.\n",
    "- **Baseline models** -- Decision Tree and XGBoost, each with randomised\n",
    "  hyperparameter search so that results reflect tuned performance.\n",
    "- **Evaluation** -- predictions plotted against EXFOR data and the\n",
    "  ENDF/B-VIII.0 evaluated library; feature-importance analysis.\n",
    "- **Interpretation guidance** -- what the metrics and plots show, and what\n",
    "  to look for when reading the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:32:33.424519Z",
     "iopub.status.busy": "2026-01-26T21:32:33.423592Z",
     "iopub.status.idle": "2026-01-26T21:33:01.577384Z",
     "shell.execute_reply": "2026-01-26T21:33:01.574266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u00e2\u0153\u201c Imports successful\n",
      "\u00e2\u0153\u201c EXFOR data found\n",
      "Welcome to NUCML-Next: Understanding ML Limitations with Real Nuclear Data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from nucml_next.data import NucmlDataset\n",
    "from nucml_next.baselines import XGBoostEvaluator, DecisionTreeEvaluator\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Verify EXFOR data exists\n",
    "exfor_path = Path('../data/exfor_processed.parquet')\n",
    "if not exfor_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"EXFOR data not found at {exfor_path}\\n\"\n",
    "        \"Please run: python scripts/ingest_exfor.py --x4-db data/x4sqlite1.db --output data/exfor_processed.parquet\"\n",
    "    )\n",
    "\n",
    "print(\"\u00e2\u0153\u201c Imports successful\")\n",
    "print(\"\u00e2\u0153\u201c EXFOR data found\")\n",
    "print(\"Welcome to NUCML-Next: Understanding ML Limitations with Real Nuclear Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The cell below sets three groups of options that control the rest of the\n",
    "notebook:\n",
    "\n",
    "1. **Feature tiers** -- which AME2020 / NUBASE2020 nuclear-property columns\n",
    "   to include alongside the core coordinates (Z, A, N, Energy) and\n",
    "   particle-emission vector.\n",
    "2. **Transformation pipeline** -- log-scaling for energy and cross section,\n",
    "   optional feature standardisation.\n",
    "3. **Uncertainty weighting** -- whether to weight training samples by\n",
    "   inverse measurement uncertainty, and how to handle missing values.\n",
    "\n",
    "All settings are defined once here; every subsequent cell reads from these\n",
    "variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:33:01.664692Z",
     "iopub.status.busy": "2026-01-26T21:33:01.663004Z",
     "iopub.status.idle": "2026-01-26T21:33:01.685980Z",
     "shell.execute_reply": "2026-01-26T21:33:01.682728Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================================\n# USER CONFIGURATION: Feature Tiers and Transformations\n# ============================================================================\n# Change these settings in ONE place instead of scattered throughout the notebook\n\nfrom nucml_next.data.selection import TransformationConfig\n\n# ============================================================================\n# FEATURE TIER SELECTION\n# ============================================================================\n# Choose which AME2020/NUBASE2020 enrichment tiers to include\n#\n# Tier A (13 features) - ALWAYS INCLUDED:\n#   - Z, A, N, Energy (nuclear coordinates)\n#   - 9-feature Numerical Particle Vector:\n#     out_n, out_p, out_a, out_g, out_f, out_t, out_h, out_d, is_met\n#\n# Tier B (+2 features) - Geometric:\n#   + R_fm (nuclear radius)\n#   + kR (dimensionless interaction parameter)\n#\n# Tier C (+7 features) - Energetics: RECOMMENDED FOR BASELINES\n#   + Mass_Excess_MeV (mass excess)\n#   + Binding_Energy_MeV (total binding energy)\n#   + Binding_Per_Nucleon_MeV (B/A)\n#   + S_1n_MeV, S_2n_MeV (neutron separation energies)\n#   + S_1p_MeV, S_2p_MeV (proton separation energies)\n#\n# Tier D (+9 features) - Topological:\n#   + Spin, Parity (nuclear structure)\n#   + Isomer_Level, Half_Life_log10_s (log10-transformed half-life)\n#   + Valence_N, Valence_P (distance to magic numbers)\n#   + P_Factor (pairing: even-even/odd-odd)\n#   + Shell_Closure_N, Shell_Closure_P\n#\n# Tier E (+8 features) - Complete Q-values:\n#   + Q_alpha_MeV, Q_2beta_minus_MeV, Q_ep_MeV, etc.\n#   + All 8 reaction Q-values from AME2020\n\nSELECTED_TIERS = ['A', 'C']  # Change tiers HERE (only place to modify)\n\nprint(f\"Selected Feature Tiers: {SELECTED_TIERS}\")\nprint(f\"   Features: Tier A (core + particle vector) + Tier C (energetics)\")\nprint()\n\n# ============================================================================\n# TRANSFORMATION CONFIGURATION\n# ============================================================================\n# Configure log-scaling and standardization for ML training.\n#\n# IMPORTANT: For tree-based models (Decision Trees, XGBoost, Random Forest),\n# feature scaling is NOT mathematically necessary because trees only care about\n# the ordering of values, not their magnitude. Trees find optimal split points\n# regardless of scale.\n#\n# However, log-transforms for Energy and CrossSection ARE important because:\n#   - Energy spans ~12 orders of magnitude (1e-5 eV to 1e7 eV)\n#   - CrossSection spans ~10 orders of magnitude (microbarns to kilobarns)\n#   - Log-transform compresses this range for better numerical stability\n#\n# For neural networks (future work), scaling IS necessary because gradients\n# depend on feature magnitudes. The TransformationPipeline class supports this.\n\nTRANSFORMATION_CONFIG = TransformationConfig(\n    # ============================================================================\n    # Target (cross-section) transformations\n    # ============================================================================\n    log_target=True,              # Enable log10 transform for cross-sections\n                                  # Stabilizes gradients and handles wide range (ub to kb)\n    \n    target_epsilon=1e-10,         # Epsilon for log(xs + epsilon) to prevent log(0)\n                                  # Increase if you have very small cross-sections\n    \n    log_base=10,                  # Logarithm base: 10 | 'e' | 2\n                                  # Base-10 is standard in nuclear physics\n    \n    # ============================================================================\n    # Energy transformations\n    # ============================================================================\n    log_energy=True,              # Enable log10 transform for energies\n                                  # Handles wide energy range (eV to MeV)\n    \n    energy_log_base=10,           # Energy log base: 10 | 'e' | 2\n    \n    # ============================================================================\n    # Feature standardization (Z-score, MinMax, etc.)\n    # ============================================================================\n    # For TREE-BASED models: Set to 'none' (trees are scale-invariant)\n    # For NEURAL NETWORKS: Set to 'standard' or 'minmax'\n    scaler_type='none',           # Feature scaling method:\n                                  # 'none'     = No scaling [DEFAULT for trees]\n                                  # 'standard' = Z-score normalization (X-mu)/sigma\n                                  # 'minmax'   = Min-max scaling to [0,1]\n                                  # 'robust'   = Robust scaling using median and IQR\n    \n    scale_features=None           # Columns to scale (only used if scaler_type != 'none')\n                                  # None = auto-detect numeric columns\n                                  # Example: ['Z', 'A', 'N', 'Mass_Excess_MeV']\n)\n\nprint(\"Transformation Configuration:\")\nprint(TRANSFORMATION_CONFIG)\nprint()\nprint(\"NOTE: scaler_type='none' because Decision Trees and XGBoost are\")\nprint(\"      scale-invariant. Log-transforms for Energy/CrossSection are kept.\")\nprint()\n\n# ============================================================================\n# UNCERTAINTY WEIGHTING CONFIGURATION\n# ============================================================================\n# Configure how to use experimental uncertainties during training.\n#\n# The EXFOR database contains measurement uncertainties for ~66% of cross-section\n# values. These uncertainties can be used to weight samples during training,\n# giving more influence to precise measurements and less to uncertain ones.\n#\n# Statistical basis: Inverse-variance weighting (w_i = 1/sigma_i^2) is the\n# optimal weighting for least-squares regression when errors are heteroscedastic.\n\nUSE_UNCERTAINTY_WEIGHTS = 'xs'    # Uncertainty weighting mode:\n                                  # None   = No weighting (equal weight)\n                                  # 'xs'   = Weight by cross-section uncertainty (1/sigma_xs^2)\n                                  # 'both' = Weight by XS AND energy uncertainty\n                                  #          (1/sigma_xs^2 * 1/sigma_E^2)\n\nMISSING_UNCERTAINTY_HANDLING = 'median'\n                                  # How to handle samples with missing uncertainties\n                                  # (only used when USE_UNCERTAINTY_WEIGHTS is not None):\n                                  # 'median'  = Assign median weight from valid samples (default)\n                                  # 'equal'   = Assign weight of 1.0\n                                  # 'exclude' = Exclude samples without valid uncertainty\n                                  #             (equivalent to requiring uncertainty)\n\nprint(\"=\" * 80)\nprint(\"Uncertainty Weighting Configuration:\")\nprint(f\"  USE_UNCERTAINTY_WEIGHTS:       {USE_UNCERTAINTY_WEIGHTS}\")\nprint(f\"  MISSING_UNCERTAINTY_HANDLING:  '{MISSING_UNCERTAINTY_HANDLING}'\")\nif USE_UNCERTAINTY_WEIGHTS:\n    print(f\"\\n  NOTE: Uncertainty weighting enabled (mode='{USE_UNCERTAINTY_WEIGHTS}').\")\n    print(\"        Samples with lower uncertainty get higher weight.\")\n    if MISSING_UNCERTAINTY_HANDLING == 'exclude':\n        print(\"\\n  NOTE: MISSING_UNCERTAINTY_HANDLING='exclude' will filter to only\")\n        print(\"        samples with valid uncertainty (~66% of data).\")\nprint()\nprint(\"To change settings, modify SELECTED_TIERS and TRANSFORMATION_CONFIG above\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: EXFOR-derived processed dataset\n",
    "\n",
    "The notebook loads a Parquet file produced by the NUCML-Next ingestion\n",
    "pipeline (`scripts/ingest_exfor.py`). A `DataSelection` object specifies\n",
    "the selection constraints used here for consistency:\n",
    "\n",
    "- **Projectile**: neutron only.\n",
    "- **Energy range**: 1e-5 eV to 2e7 eV (thermal through fast reactor\n",
    "  energies).\n",
    "- **Reaction channels**: all physical MT codes, including bookkeeping\n",
    "  channels (MT 0, 1, >= 9000).\n",
    "- **Validity filter**: rows with NaN or non-positive cross sections are\n",
    "  dropped so that log-transforms are well-defined.\n",
    "\n",
    "The full training set contains all isotopes. Two evaluation isotopes are\n",
    "loaded separately:\n",
    "\n",
    "| Isotope | Reaction | Role |\n",
    "|---------|----------|------|\n",
    "| U-235 | Fission (MT 18) | Data-rich: thousands of EXFOR points |\n",
    "| Cl-35 | (n,p) (MT 103) | Data-sparse: tens of EXFOR points |\n",
    "\n",
    "Comparing a data-rich and a data-sparse case illustrates how model\n",
    "behaviour changes with measurement density.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:33:01.695938Z",
     "iopub.status.busy": "2026-01-26T21:33:01.694354Z",
     "iopub.status.idle": "2026-01-26T21:34:53.672027Z",
     "shell.execute_reply": "2026-01-26T21:34:53.655001Z"
    }
   },
   "outputs": [],
   "source": [
    "# CRITICAL FIX: Use physics-aware DataSelection for scientifically defensible filtering\n",
    "# This demonstrates proper ML workflow with predicate pushdown for efficiency\n",
    "\n",
    "from nucml_next.data import DataSelection\n",
    "\n",
    "# Strategy: Train on neutron-induced reactions at reactor energies (scientifically defensible default)\n",
    "# This avoids training on:\n",
    "# - Non-reactor energies (too high/low for criticality calculations)\n",
    "# - Non-neutron projectiles (we're focused on reactor physics)\n",
    "# \n",
    "# NOTE: We now INCLUDE all MT codes (including 0, 1, and >=9000) in 'all_physical' mode\n",
    "\n",
    "print(\"Creating physics-aware data selection...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Training selection: Reactor physics, neutrons, all physical reactions\n",
    "training_selection = DataSelection(\n",
    "    # ============================================================================\n",
    "    # PROJECTILE SELECTION\n",
    "    # ============================================================================\n",
    "    projectile='neutron',          # Options: 'neutron' | 'all'\n",
    "                                   # 'neutron' = Only neutron-induced reactions (reactor physics)\n",
    "                                   # 'all' = All projectiles (n, p, d, \u00ce\u00b1, \u00ce\u00b3, etc.)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # ENERGY RANGE (eV)\n",
    "    # ============================================================================\n",
    "    energy_min=1e-5,               # Minimum energy in eV (1e-5 = 0.01 eV, thermal neutrons)\n",
    "    energy_max=2e7,                # Maximum energy in eV (2e7 = 20 MeV, reactor physics upper bound)\n",
    "                                   # Common ranges:\n",
    "                                   #   - Thermal: 1e-5 to 1 eV\n",
    "                                   #   - Resonance: 1 to 1e4 eV\n",
    "                                   #   - Fast: 1e4 to 2e7 eV (20 MeV)\n",
    "                                   #   - High energy: up to 1e9 eV (1 GeV)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # REACTION (MT) MODE SELECTION\n",
    "    # ============================================================================\n",
    "    mt_mode='all_physical',        # Options:\n",
    "                                   # 'reactor_core'   \u00e2\u2020\u2019 Essential for reactor modeling\n",
    "                                   #                    (MT 2, 4, 16, 18, 102, 103, 107)\n",
    "                                   #                    [elastic, inelastic, (n,2n), fission,\n",
    "                                   #                     capture, (n,p), (n,\u00ce\u00b1)]\n",
    "                                   #\n",
    "                                   # 'threshold_only' \u00e2\u2020\u2019 Reactions with energy thresholds\n",
    "                                   #                    (MT 16, 17, 103, 104, 105, 106, 107)\n",
    "                                   #                    [(n,2n), (n,3n), (n,p), (n,d), (n,t),\n",
    "                                   #                     (n,\u00c2\u00b3He), (n,\u00ce\u00b1)]\n",
    "                                   #\n",
    "                                   # 'fission_details'\u00e2\u2020\u2019 Fission breakdown channels\n",
    "                                   #                    (MT 18, 19, 20, 21, 38)\n",
    "                                   #                    [total fission, 1st chance, 2nd chance,\n",
    "                                   #                     3rd chance, 4th chance]\n",
    "                                   #\n",
    "                                   # 'all_physical'   \u00e2\u2020\u2019 All MT codes including bookkeeping\n",
    "                                   #                    (MT 0, 1, and >=9000 now INCLUDED)\n",
    "                                   #\n",
    "                                   # 'custom'         \u00e2\u2020\u2019 Use custom_mt_codes list (see below)\n",
    "    \n",
    "    custom_mt_codes=None,          # Used only when mt_mode='custom'\n",
    "                                   # Example: [2, 18, 102]  # Elastic, fission, capture\n",
    "                                   # Example: [16, 17, 18]  # (n,2n), (n,3n), fission\n",
    "                                   # Example: list(range(50, 92))  # MT 50-91 (inelastic levels)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # EXCLUSION RULES\n",
    "    # ============================================================================\n",
    "    exclude_bookkeeping=False,     # Set to False to INCLUDE MT 0, 1, and MT >= 9000\n",
    "                                   # MT 0 = Undefined\n",
    "                                   # MT 1 = Total cross-section (sum of others)\n",
    "                                   # MT >= 9000 = Lumped reaction covariances\n",
    "                                   # Now including these for comprehensive analysis\n",
    "    \n",
    "    # ============================================================================\n",
    "    # DATA VALIDITY\n",
    "    # ============================================================================\n",
    "    drop_invalid=True,             # Drop NaN or non-positive cross-sections\n",
    "                                   # Essential for log-transform: log(\u00cf\u0192) requires \u00cf\u0192 > 0\n",
    "                                   # Prevents training instabilities\n",
    "    \n",
    "    # ============================================================================\n",
    "    # EVALUATION CONTROLS (Holdout for Extrapolation Testing)\n",
    "    # ============================================================================\n",
    "    holdout_isotopes=None,         # List of (Z, A) tuples to exclude from training\n",
    "                                   # None = Use all data (default for training)\n",
    "                                   # Example: [(92, 235)]           # Hold out U-235 only\n",
    "                                   # Example: [(92, 235), (17, 35)] # Hold out U-235 and Cl-35\n",
    "                                   # Example: [(94, 239), (94, 240), (94, 241)]  # Pu isotopes\n",
    "                                   # Use this to measure TRUE extrapolation capability!\n",
    "    \n",
    "    # ============================================================================\n",
    "    # AME2020/NUBASE2020 ENRICHMENT TIER SELECTION\n",
    "    # ============================================================================\n",
    "    tiers=SELECTED_TIERS,          # \u00f0\u0178\u017d\u00af Using centralized tier configuration\n",
    "    transformation_config=TRANSFORMATION_CONFIG  # Using centralized transformation config\n",
    ")\n",
    "\n",
    "print(\"Training Selection:\")\n",
    "print(training_selection)\n",
    "print()\n",
    "\n",
    "# Load FULL dataset for training with physics-aware filtering\n",
    "# CRITICAL: Predicate pushdown filters at PyArrow fragment level (90% I/O reduction!)\n",
    "print(\"=\" * 80)\n",
    "print(\"Loading training dataset with predicate pushdown...\")\n",
    "print(\"=\" * 80)\n",
    "dataset_full = NucmlDataset(\n",
    "    data_path='../data/exfor_processed.parquet',\n",
    "    mode='tabular',\n",
    "    selection=training_selection  # Physics-aware selection with predicate pushdown\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Project to tabular format with TIER-BASED features (particle vector)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Projecting to tabular format with particle vector...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# NOTE: to_tabular() uses particle emission vectors by default (no mode parameter needed)\n",
    "# This transforms MT codes into physics-aware features (out_n, out_p, out_a, etc.)\n",
    "# Pass extra_metadata to preserve Energy_Uncertainty when using combined weighting\n",
    "_extra_meta = ['Energy_Uncertainty'] if USE_UNCERTAINTY_WEIGHTS == 'both' else None\n",
    "df_tier = dataset_full.to_tabular(extra_metadata=_extra_meta)\n",
    "\n",
    "print(f\"\\n[OK] Training dataset: {df_tier.shape}\")\n",
    "print(f\"  Energy range: {df_tier['Energy'].min():.2e} to {df_tier['Energy'].max():.2e} eV\")\n",
    "\n",
    "# ============================================================================\n",
    "# DATA QUALITY: UNCERTAINTY COVERAGE\n",
    "# ============================================================================\n",
    "# Display statistics about experimental uncertainty availability.\n",
    "# This informs users about data quality for uncertainty-weighted training.\n",
    "#\n",
    "# From X4Pro C5 format investigation:\n",
    "# - Total uncertainty (dy \u00e2\u2020\u2019 Uncertainty): ~72% coverage in EXFOR\n",
    "# - Energy uncertainty (dx1 \u00e2\u2020\u2019 Energy_Uncertainty): ~55% coverage in EXFOR\n",
    "#\n",
    "# These uncertainties are EXCLUDED by default but can be enabled in cell-3.\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA QUALITY: UNCERTAINTY COVERAGE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cross-section uncertainty (Uncertainty column)\n",
    "if 'Uncertainty' in df_tier.columns:\n",
    "    total_samples = len(df_tier)\n",
    "    valid_xs_unc = df_tier['Uncertainty'].notna() & (df_tier['Uncertainty'] > 0)\n",
    "    n_valid_xs_unc = valid_xs_unc.sum()\n",
    "    pct_xs_unc = 100 * n_valid_xs_unc / total_samples\n",
    "\n",
    "    print(f\"\\n  Cross-section uncertainty (Uncertainty column):\")\n",
    "    print(f\"    Valid values:    {n_valid_xs_unc:>10,} / {total_samples:,} ({pct_xs_unc:.1f}%)\")\n",
    "    print(f\"    Missing/invalid: {total_samples - n_valid_xs_unc:>10,} ({100 - pct_xs_unc:.1f}%)\")\n",
    "\n",
    "    if n_valid_xs_unc > 0:\n",
    "        valid_unc = df_tier.loc[valid_xs_unc, 'Uncertainty']\n",
    "        print(f\"    Range:           {valid_unc.min():.2e} to {valid_unc.max():.2e} barns\")\n",
    "        print(f\"    Median:          {valid_unc.median():.2e} barns\")\n",
    "else:\n",
    "    print(\"\\n  Cross-section uncertainty: NOT AVAILABLE (Uncertainty column missing)\")\n",
    "\n",
    "# Energy uncertainty (Energy_Uncertainty column) - if present\n",
    "if 'Energy_Uncertainty' in df_tier.columns:\n",
    "    valid_e_unc = df_tier['Energy_Uncertainty'].notna() & (df_tier['Energy_Uncertainty'] > 0)\n",
    "    n_valid_e_unc = valid_e_unc.sum()\n",
    "    pct_e_unc = 100 * n_valid_e_unc / total_samples\n",
    "\n",
    "    print(f\"\\n  Energy uncertainty (Energy_Uncertainty column):\")\n",
    "    print(f\"    Valid values:    {n_valid_e_unc:>10,} / {total_samples:,} ({pct_e_unc:.1f}%)\")\n",
    "    print(f\"    Missing/invalid: {total_samples - n_valid_e_unc:>10,} ({100 - pct_e_unc:.1f}%)\")\n",
    "\n",
    "    if n_valid_e_unc > 0:\n",
    "        valid_e_unc_vals = df_tier.loc[valid_e_unc, 'Energy_Uncertainty']\n",
    "        print(f\"    Range:           {valid_e_unc_vals.min():.2e} to {valid_e_unc_vals.max():.2e} eV\")\n",
    "        print(f\"    Median:          {valid_e_unc_vals.median():.2e} eV\")\n",
    "else:\n",
    "    print(\"\\n  Energy uncertainty: NOT AVAILABLE (Energy_Uncertainty column missing)\")\n",
    "\n",
    "# Usage note\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"  NOTE: Uncertainties are EXCLUDED from training features by default.\")\n",
    "print(\"        To enable uncertainty weighting, modify settings in cell-3:\")\n",
    "print(\"          USE_UNCERTAINTY_WEIGHTS = 'xs'    # Weight by cross-section uncertainty\")\n",
    "print(\"          USE_UNCERTAINTY_WEIGHTS = 'both'  # Weight by XS AND energy uncertainty\")\n",
    "print(\"        Set MISSING_UNCERTAINTY_HANDLING = 'exclude' to filter to only\")\n",
    "print(\"        samples with valid uncertainty. See cell-3 for all options.\")\n",
    "print(\"        NOTE: Energy_Uncertainty is only included when mode='both'.\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# DISPLAY FEATURES BASED ON SELECTED TIERS\n",
    "# ============================================================================\n",
    "# Define tier feature mappings for documentation\n",
    "# NOTE: Half_Life_s is log-transformed to Half_Life_log10_s (spans ~54 orders of magnitude)\n",
    "TIER_FEATURES = {\n",
    "    'A': {\n",
    "        'name': 'Core + Particle Vector',\n",
    "        'features': ['Z', 'A', 'N', 'Energy', 'out_n', 'out_p', 'out_a', 'out_g', 'out_f', 'out_t', 'out_h', 'out_d', 'is_met'],\n",
    "        'description': 'Nuclear coordinates (Z, A, N, Energy) + 9-feature particle emission vector'\n",
    "    },\n",
    "    'B': {\n",
    "        'name': 'Geometric',\n",
    "        'features': ['R_fm', 'kR'],\n",
    "        'description': 'Nuclear radius and dimensionless interaction parameter'\n",
    "    },\n",
    "    'C': {\n",
    "        'name': 'Energetics',\n",
    "        'features': ['Mass_Excess_MeV', 'Binding_Energy_MeV', 'Binding_Per_Nucleon_MeV', 'S_1n_MeV', 'S_2n_MeV', 'S_1p_MeV', 'S_2p_MeV'],\n",
    "        'description': 'Mass excess, binding energies, separation energies (AME2020)'\n",
    "    },\n",
    "    'D': {\n",
    "        'name': 'Topological',\n",
    "        'features': ['Spin', 'Parity', 'Isomer_Level', 'Half_Life_log10_s', 'Valence_N', 'Valence_P', 'P_Factor', 'Shell_Closure_N', 'Shell_Closure_P'],\n",
    "        'description': 'Nuclear structure: spin, parity, valence, magic numbers (NUBASE2020). Half-life is log10-transformed.'\n",
    "    },\n",
    "    'E': {\n",
    "        'name': 'Q-values',\n",
    "        'features': ['Q_alpha', 'Q_2beta_minus', 'Q_ep', 'Q_beta_n', 'Q_4beta_minus', 'Q_d_alpha', 'Q_p_alpha', 'Q_n_alpha'],\n",
    "        'description': 'Reaction Q-values from AME2020'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"FEATURES AVAILABLE (Based on SELECTED_TIERS = {SELECTED_TIERS})\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_tier_features = 0\n",
    "for tier in sorted(SELECTED_TIERS):\n",
    "    if tier in TIER_FEATURES:\n",
    "        info = TIER_FEATURES[tier]\n",
    "        n_features = len(info['features'])\n",
    "        total_tier_features += n_features\n",
    "        print(f\"\\nTier {tier} - {info['name']} ({n_features} features):\")\n",
    "        print(f\"  {info['description']}\")\n",
    "        print(f\"  Features: {', '.join(info['features'])}\")\n",
    "\n",
    "# Also show metadata columns that are preserved\n",
    "metadata_cols = ['Entry', 'MT', 'CrossSection', 'Uncertainty']\n",
    "if USE_UNCERTAINTY_WEIGHTS == 'both':\n",
    "    metadata_cols.append('Energy_Uncertainty')\n",
    "print(f\"\\nMetadata columns (preserved for reference): {', '.join(metadata_cols)}\")\n",
    "print(f\"\\nTotal: {len(df_tier.columns)} columns in dataframe\")\n",
    "print(f\"       ({total_tier_features} tier features + {len(metadata_cols)} metadata)\")\n",
    "\n",
    "print(f\"\\nAll column names:\")\n",
    "print(df_tier.columns.tolist())\n",
    "\n",
    "# Show isotope distribution in training data\n",
    "print(\"\\n[*] Training Data Distribution (Top 10 Isotopes):\")\n",
    "isotope_counts = dataset_full.df.groupby(['Z', 'A']).size().sort_values(ascending=False).head(10)\n",
    "for (z, a), count in isotope_counts.items():\n",
    "    # Simple element lookup (extend as needed)\n",
    "    element_map = {92: 'U', 17: 'Cl', 94: 'Pu', 26: 'Fe', 8: 'O', 1: 'H',\n",
    "                   82: 'Pb', 6: 'C', 13: 'Al', 7: 'N', 11: 'Na', 79: 'Au'}\n",
    "    elem = element_map.get(z, f'Z{z}')\n",
    "    print(f\"  {elem}-{a:3d}: {count:>8,} measurements\")\n",
    "\n",
    "print(f\"\\n[OK] Total isotopes: {dataset_full.df.groupby(['Z', 'A']).ngroups} unique Z/A combinations\")\n",
    "print(f\"[OK] Total reaction types: {dataset_full.df['MT'].nunique()} unique MT codes\")\n",
    "print(f\"[OK] Total measurements: {len(dataset_full.df):,}\")\n",
    "\n",
    "# Show MT distribution\n",
    "print(\"\\n[*] Top 10 Reaction Types (MT codes):\")\n",
    "mt_counts = dataset_full.df['MT'].value_counts().head(10)\n",
    "mt_names = {18: 'Fission', 102: '(n,gamma) Capture', 103: '(n,p)', 2: 'Elastic',\n",
    "            16: '(n,2n)', 17: '(n,3n)', 4: 'Inelastic', 107: '(n,alpha)',\n",
    "            0: 'Undefined', 1: 'Total XS'}\n",
    "for mt, count in mt_counts.items():\n",
    "    name = mt_names.get(mt, f'MT-{mt}')\n",
    "    print(f\"  MT {mt:3d} {name:15s}: {count:>8,} measurements\")\n",
    "\n",
    "print(f\"\\n[OK] Training on neutron-induced reactions (reactor energies 0.01 eV - 20 MeV)\")\n",
    "print(f\"[OK] Including ALL MT codes (0, 1, and >=9000 now included)\")\n",
    "print(f\"[OK] Using Tier A + C features with particle vector transformation\")\n",
    "\n",
    "# Now load evaluation targets (U-235 and Cl-35) using legacy filters for specific selection\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Loading evaluation targets (U-235 and Cl-35)...\")\n",
    "print(f\"NOTE: Using same energy range as training: {training_selection.energy_min:.2e} to {training_selection.energy_max:.2e} eV\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create evaluation selection with same energy limits but specific isotopes\n",
    "eval_selection = DataSelection(\n",
    "    projectile='neutron',\n",
    "    energy_min=training_selection.energy_min,  # SAME as training\n",
    "    energy_max=training_selection.energy_max,  # SAME as training  \n",
    "    mt_mode='all_physical',        # Same as training\n",
    "    exclude_bookkeeping=False,     # Include all MT codes\n",
    "    drop_invalid=True,\n",
    "    tiers=SELECTED_TIERS,          # Using centralized tier configuration\n",
    ")\n",
    "\n",
    "dataset_eval = NucmlDataset(\n",
    "    data_path='../data/exfor_processed.parquet',\n",
    "    mode='tabular',\n",
    "    selection=eval_selection\n",
    ")\n",
    "\n",
    "# Filter to U-235 and Cl-35 only\n",
    "dataset_eval.df = dataset_eval.df[\n",
    "    ((dataset_eval.df['Z'] == 92) & (dataset_eval.df['A'] == 235)) |\n",
    "    ((dataset_eval.df['Z'] == 17) & (dataset_eval.df['A'] == 35))\n",
    "].copy()\n",
    "\n",
    "print(f\"[OK] Evaluation dataset: {len(dataset_eval.df)} measurements\")\n",
    "print(f\"  Energy range: {dataset_eval.df['Energy'].min():.2e} to {dataset_eval.df['Energy'].max():.2e} eV\")\n",
    "print(\"\\n[*] Evaluation Isotopes:\")\n",
    "for (z, a), group in dataset_eval.df.groupby(['Z', 'A']):\n",
    "    isotope = f\"{'U' if z==92 else 'Cl'}-{a}\"\n",
    "    e_min = group['Energy'].min()\n",
    "    e_max = group['Energy'].max()\n",
    "    print(f\"  {isotope:8s}: {len(group):>6,} measurements (Energy: {e_min:.2e} to {e_max:.2e} eV)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Display sample data transposed for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "print(df_tier.sample(5).T.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature representation\n",
    "\n",
    "Reaction channels (MT codes) are encoded as a 9-component\n",
    "**particle-emission vector** (`out_n`, `out_p`, `out_a`, ..., `is_met`)\n",
    "rather than one-hot indicators. This preserves information about which\n",
    "particles are emitted in each reaction.\n",
    "\n",
    "If Tier C is selected, seven AME2020 energetics columns (mass excess,\n",
    "binding energies, separation energies) are appended. The full set of\n",
    "available tiers is documented in the configuration cell above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1 -- Decision Tree\n",
    "\n",
    "A single Decision Tree is trained on the full EXFOR dataset. To ensure the\n",
    "results reflect a well-tuned model rather than arbitrary defaults, a\n",
    "randomised hyperparameter search is run first on a 10 % subsample of the\n",
    "data, and the best parameters are then used to train on the complete\n",
    "training set.\n",
    "\n",
    "A Decision Tree partitions feature space into axis-aligned rectangles,\n",
    "returning a constant prediction within each rectangle. The resulting\n",
    "cross-section curve is therefore piecewise constant by construction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:34:53.746941Z",
     "iopub.status.busy": "2026-01-26T21:34:53.743177Z",
     "iopub.status.idle": "2026-01-26T21:45:39.106787Z",
     "shell.execute_reply": "2026-01-26T21:45:39.099894Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HYPERPARAMETER OPTIMIZATION FOR DECISION TREE\n",
    "# ============================================================================\n",
    "# Use Randomized Search with subsampling to find good hyperparameters efficiently.\n",
    "# This ensures we're evaluating Decision Trees at their BEST, not strawman configs.\n",
    "#\n",
    "# MEMORY OPTIMIZATION: The full dataset (~10M samples) is too large for grid search.\n",
    "# We use two strategies:\n",
    "#   1. SUBSAMPLING: Use 10% of data (~1M samples) for hyperparameter search\n",
    "#   2. RANDOMIZED SEARCH: Sample from parameter space instead of exhaustive grid\n",
    "#\n",
    "# The final model is still trained on FULL data with the best found parameters.\n",
    "\n",
    "# ============================================================================\n",
    "# USER CONFIGURATION: Hyperparameter Search Space\n",
    "# ============================================================================\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# max_depth: Maximum tree depth (how many splits from root to leaf)\n",
    "# ----------------------------------------------------------------------------\n",
    "# Deeper trees capture more complex patterns but risk overfitting.\n",
    "# None = unlimited depth (grows until leaves are pure or hit min_samples)\n",
    "DT_DEPTHS = [40, 60, 80, 100, None]  # Options to sample from\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# min_samples_split: Minimum samples required to split an internal node\n",
    "# ----------------------------------------------------------------------------\n",
    "# Higher values = fewer splits = more regularization\n",
    "DT_MSS_VALUES = [2, 4, 6, 8, 10, 12]  # Options to sample from\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# min_samples_leaf: Minimum samples required in a leaf node\n",
    "# ----------------------------------------------------------------------------\n",
    "# Higher values = larger leaves = smoother predictions\n",
    "DT_MSL_VALUES = [1, 2, 4, 6, 8, 10]  # Options to sample from\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Subsampling for memory efficiency\n",
    "# ----------------------------------------------------------------------------\n",
    "# subsample_fraction: Fraction of data to use for hyperparameter search\n",
    "#   - 0.1 = 10% of data (~1M samples for 10M dataset)\n",
    "#   - Reduces memory by ~90%, makes search feasible\n",
    "#   - Final model trained on FULL data with best params\n",
    "DT_SUBSAMPLE_FRACTION = 0.1  # 10% of data for search\n",
    "\n",
    "# subsample_max_samples: Alternative to fraction - absolute maximum\n",
    "#   - Set to None to use fraction only\n",
    "#   - Set to e.g., 1_000_000 to cap at 1M samples\n",
    "DT_SUBSAMPLE_MAX = 1_000_000  # Cap at 1M samples\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Randomized search settings\n",
    "# ----------------------------------------------------------------------------\n",
    "# n_iter: Number of random parameter combinations to try\n",
    "#   - Higher = more thorough search but slower\n",
    "#   - 20-50 typically finds good solutions\n",
    "DT_N_ITER = 20  # Number of random combinations to try\n",
    "\n",
    "# cv: Number of cross-validation folds\n",
    "#   - 2-3: Faster, recommended for large datasets\n",
    "#   - 5: Standard choice if memory allows\n",
    "DT_CV = 2\n",
    "\n",
    "# n_jobs: Number of parallel jobs\n",
    "#   - -1: Use all CPU cores\n",
    "#   - 1: Sequential (less memory)\n",
    "DT_N_JOBS = -1\n",
    "\n",
    "# scoring: Loss function to optimize\n",
    "DT_SCORING = 'neg_mean_squared_error'\n",
    "\n",
    "# ============================================================================\n",
    "# BUILD PARAMETER GRID\n",
    "# ============================================================================\n",
    "DT_PARAM_GRID = {\n",
    "    'max_depth': DT_DEPTHS,\n",
    "    'min_samples_split': DT_MSS_VALUES,\n",
    "    'min_samples_leaf': DT_MSL_VALUES,\n",
    "    'max_features': [None],  # Use all features at each split\n",
    "}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DECISION TREE HYPERPARAMETER OPTIMIZATION (Randomized Search + Subsampling)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Parameter search space:\")\n",
    "print(f\"  max_depth:         {DT_DEPTHS}\")\n",
    "print(f\"  min_samples_split: {DT_MSS_VALUES}\")\n",
    "print(f\"  min_samples_leaf:  {DT_MSL_VALUES}\")\n",
    "print(f\"\\nMemory optimization:\")\n",
    "print(f\"  subsample_fraction:    {DT_SUBSAMPLE_FRACTION} ({DT_SUBSAMPLE_FRACTION*100:.0f}% of data)\")\n",
    "print(f\"  subsample_max_samples: {DT_SUBSAMPLE_MAX:,}\")\n",
    "print(f\"\\nOptimization settings:\")\n",
    "print(f\"  method: Randomized Search (n_iter={DT_N_ITER})\")\n",
    "print(f\"  cv={DT_CV}, n_jobs={DT_N_JOBS}, scoring='{DT_SCORING}'\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# RUN RANDOMIZED SEARCH WITH SUBSAMPLING\n",
    "# ============================================================================\n",
    "dt_optimizer = DecisionTreeEvaluator()\n",
    "\n",
    "opt_result_dt = dt_optimizer.optimize_hyperparameters(\n",
    "    df_tier,\n",
    "    method='random',  # Randomized search instead of grid\n",
    "    param_grid=DT_PARAM_GRID,\n",
    "    n_iter=DT_N_ITER,  # Number of random combinations\n",
    "    cv_folds=DT_CV,\n",
    "    scoring=DT_SCORING,\n",
    "    verbose=True,\n",
    "    n_jobs=DT_N_JOBS,\n",
    "    # Memory optimization via subsampling\n",
    "    subsample_fraction=DT_SUBSAMPLE_FRACTION,\n",
    "    subsample_max_samples=DT_SUBSAMPLE_MAX,\n",
    "    # Uncertainty-based sample filtering\n",
    "    use_uncertainty_weights=USE_UNCERTAINTY_WEIGHTS,\n",
    "    missing_uncertainty_handling=MISSING_UNCERTAINTY_HANDLING,\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN FINAL MODEL WITH OPTIMAL HYPERPARAMETERS ON FULL DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING FINAL MODEL WITH OPTIMAL HYPERPARAMETERS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show uncertainty weighting configuration\n",
    "print(f\"\\nUncertainty Weighting:\")\n",
    "print(f\"  use_uncertainty_weights:      {USE_UNCERTAINTY_WEIGHTS}\")\n",
    "print(f\"  missing_uncertainty_handling: '{MISSING_UNCERTAINTY_HANDLING}'\")\n",
    "print()\n",
    "\n",
    "dt_model = DecisionTreeEvaluator(**opt_result_dt['best_params'])\n",
    "dt_metrics = dt_model.train(\n",
    "    df_tier,\n",
    "    use_uncertainty_weights=USE_UNCERTAINTY_WEIGHTS,\n",
    "    missing_uncertainty_handling=MISSING_UNCERTAINTY_HANDLING,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHT:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"This is an OPTIMIZED Decision Tree with hyperparameters found via\")\n",
    "print(\"Randomized Search on a 10% subsample. The 'staircase effect' you'll\")\n",
    "print(\"see in the plots is NOT due to poor tuning - it's an inherent\")\n",
    "print(\"limitation of tree-based models that partition feature space into\")\n",
    "print(\"axis-aligned rectangles.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree predictions\n",
    "\n",
    "The plots below overlay the Decision Tree's predictions on actual EXFOR\n",
    "data points together with the ENDF/B-VIII.0 evaluated curve.\n",
    "\n",
    "- **U-235 fission** (data-rich): many training points are available for\n",
    "  this isotope/reaction.\n",
    "- **Cl-35 (n,p)** (data-sparse): the model relies on patterns learned from\n",
    "  other isotopes to fill gaps in energy coverage.\n",
    "\n",
    "Look at the shape of the predicted curve relative to the ENDF reference\n",
    "line to see how the model's piecewise-constant structure appears in\n",
    "practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:45:39.157756Z",
     "iopub.status.busy": "2026-01-26T21:45:39.155688Z",
     "iopub.status.idle": "2026-01-26T21:45:48.995366Z",
     "shell.execute_reply": "2026-01-26T21:45:48.991588Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================================\n# VISUALIZATION: U-235 (data-rich) vs Cl-35 (data-sparse) with CrossSectionFigure\n# ============================================================================\n# Using the modular visualization framework for publication-quality plots.\n# CrossSectionFigure provides:\n#   - Automatic ENDF-B overlay for comparison with evaluated data\n#   - EXFOR experimental data display\n#   - ML model predictions\n#   - Method chaining API for clean, readable code\n\nfrom nucml_next.visualization import CrossSectionFigure\n\n# ============================================================================\n# FIXED ENERGY RANGE FOR PLOTS\n# ============================================================================\nE_MIN_PLOT = 1e-4   # 10^-4 eV\nE_MAX_PLOT = 1e7    # 10^7 eV\n\n# ============================================================================\n# HELPER: Clip predictions to positive values for log scale\n# ============================================================================\ndef _clip_positive(arr, floor=1e-30):\n    \"\"\"Clip array values to minimum positive floor for log scale.\"\"\"\n    arr = np.asarray(arr)\n    return np.clip(arr, floor, None)\n\n# ============================================================================\n# LEFT PANEL: U-235 Fission (Data-Rich)\n# ============================================================================\n\nZ_u, A_u, mt_u = 92, 235, 18  # U-235 Fission\n\n# Extract U-235 fission data from training set for prediction\nmask_u_train = (df_tier['Z'] == Z_u) & (df_tier['A'] == A_u)\ndf_u_train = df_tier[mask_u_train].copy()\ndf_u_train = df_u_train[(df_u_train['Energy'] >= E_MIN_PLOT) & (df_u_train['Energy'] <= E_MAX_PLOT)]\ndf_u_train = df_u_train.sort_values('Energy').reset_index(drop=True)\n\n# Get Decision Tree predictions on actual data points\npredictions_dt_u = dt_model.predict(df_u_train)\npredictions_dt_u = _clip_positive(predictions_dt_u)\nenergies_dt_u = df_u_train['Energy'].values\n\n# Extract U-235 fission EXFOR ground truth for plotting\nmask_u_eval = (dataset_eval.df['Z'] == Z_u) & (dataset_eval.df['A'] == A_u) & (dataset_eval.df['MT'] == mt_u)\ndf_u = dataset_eval.df[mask_u_eval].copy()\ndf_u = df_u[(df_u['Energy'] > 0) & (df_u['CrossSection'] > 0)]\ndf_u = df_u[(df_u['Energy'] >= E_MIN_PLOT) & (df_u['Energy'] <= E_MAX_PLOT)]\n\n# Create U-235 figure using CrossSectionFigure\nfig_u235 = (\n    CrossSectionFigure(\n        isotope='U-235',\n        mt=18,\n        title='U-235 Fission (DATA-RICH): Staircase Effect vs ENDF-B',\n        figsize=(14, 7),\n        endf_dir='../data/ENDF-B/neutrons',\n    )\n    .add_exfor(\n        df_u,\n        label=f'EXFOR ({len(df_u)} pts)',\n        color='tab:blue',\n        s=30,\n        alpha=0.5,\n        zorder=1,\n    )\n    .add_endf_auto(\n        color='black',\n        linewidth=1.5,\n        linestyle='-',\n        alpha=0.8,\n        label='ENDF/B-VIII.0 (Evaluated)',\n        zorder=2,\n    )\n    .add_model(\n        energies_dt_u,\n        predictions_dt_u,\n        label='Decision Tree (Staircase)',\n        color='tab:red',\n        linewidth=2.5,\n        linestyle='-',\n        alpha=0.9,\n        zorder=3,\n    )\n    .set_energy_range(E_MIN_PLOT, E_MAX_PLOT)\n    .add_legend(loc='best', fontsize=11)\n)\n\n# Add annotation for staircase effect\nif len(predictions_dt_u) > 250:\n    mid_idx = len(predictions_dt_u) // 2\n    sort_idx = np.argsort(energies_dt_u)\n    fig_u235.add_annotation(\n        'Unphysical steps!\\n(ENDF curve is smooth)',\n        xy=(energies_dt_u[sort_idx][mid_idx], predictions_dt_u[sort_idx][mid_idx]),\n        xytext=(energies_dt_u[sort_idx][mid_idx] * 2, predictions_dt_u[sort_idx][mid_idx] * 3),\n        arrowprops={'arrowstyle': '->', 'color': 'tab:red', 'lw': 2},\n        color='tab:red',\n        bbox={'boxstyle': 'round', 'facecolor': 'yellow', 'alpha': 0.7},\n    )\n\nfig_u235.show()\n\n# ============================================================================\n# RIGHT PANEL: Cl-35 (n,p) (Data-Sparse)\n# ============================================================================\n\nZ_cl, A_cl, mt_cl = 17, 35, 103  # Cl-35 (n,p)\n\n# Extract Cl-35 data from training set for prediction\nmask_cl_train = (df_tier['Z'] == Z_cl) & (df_tier['A'] == A_cl)\ndf_cl_train = df_tier[mask_cl_train].copy()\ndf_cl_train = df_cl_train[(df_cl_train['Energy'] >= E_MIN_PLOT) & (df_cl_train['Energy'] <= E_MAX_PLOT)]\ndf_cl_train = df_cl_train.sort_values('Energy').reset_index(drop=True)\n\n# Get Decision Tree predictions on actual data points\npredictions_dt_cl = dt_model.predict(df_cl_train)\npredictions_dt_cl = _clip_positive(predictions_dt_cl)\nenergies_dt_cl = df_cl_train['Energy'].values\n\n# Extract Cl-35 (n,p) EXFOR ground truth for plotting\nmask_cl_eval = (dataset_eval.df['Z'] == Z_cl) & (dataset_eval.df['A'] == A_cl) & (dataset_eval.df['MT'] == mt_cl)\ndf_cl = dataset_eval.df[mask_cl_eval].copy()\ndf_cl = df_cl[(df_cl['Energy'] > 0) & (df_cl['CrossSection'] > 0)]\ndf_cl = df_cl[(df_cl['Energy'] >= E_MIN_PLOT) & (df_cl['Energy'] <= E_MAX_PLOT)]\n\n# Create Cl-35 figure using CrossSectionFigure\nfig_cl35 = (\n    CrossSectionFigure(\n        isotope='Cl-35',\n        mt=103,\n        title='Cl-35 (n,p) (DATA-SPARSE): Transfer Learning Test vs ENDF-B',\n        figsize=(14, 7),\n        endf_dir='../data/ENDF-B/neutrons',\n    )\n    .add_exfor(\n        df_cl,\n        label=f'EXFOR ({len(df_cl)} pts)',\n        color='tab:blue',\n        s=80,\n        alpha=0.6,\n        edgecolors='black',\n        zorder=1,\n    )\n    .add_endf_auto(\n        color='black',\n        linewidth=1.5,\n        linestyle='-',\n        alpha=0.8,\n        label='ENDF/B-VIII.0 (Evaluated)',\n        zorder=2,\n    )\n    .add_model(\n        energies_dt_cl,\n        predictions_dt_cl,\n        label='Decision Tree (Extrapolation)',\n        color='tab:red',\n        linewidth=2.5,\n        linestyle='-',\n        alpha=0.9,\n        zorder=3,\n    )\n    .set_energy_range(E_MIN_PLOT, E_MAX_PLOT)\n    .add_legend(loc='best', fontsize=11)\n)\n\n# Add annotation\nif len(predictions_dt_cl) > 10:\n    mid_idx = len(predictions_dt_cl) // 2\n    sort_idx_cl = np.argsort(energies_dt_cl)\n    fig_cl35.add_annotation(\n        'Can the model\\ntransfer knowledge?',\n        xy=(energies_dt_cl[sort_idx_cl][mid_idx], predictions_dt_cl[sort_idx_cl][mid_idx]),\n        xytext=(energies_dt_cl[sort_idx_cl][mid_idx] * 1.5, predictions_dt_cl[sort_idx_cl][mid_idx] * 0.5),\n        arrowprops={'arrowstyle': '->', 'color': 'tab:red', 'lw': 2},\n        color='tab:red',\n        bbox={'boxstyle': 'round', 'facecolor': 'yellow', 'alpha': 0.7},\n    )\n\nfig_cl35.show()\n\n# ============================================================================\n# OBSERVATIONS\n# ============================================================================\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"OBSERVATIONS: Decision Tree vs ENDF-B Evaluated Data\")\nprint(\"=\" * 80)\nprint(f\"Fixed Plot Range: {E_MIN_PLOT:.2e} to {E_MAX_PLOT:.2e} eV\")\nprint()\nprint(\"NEW: ENDF/B-VIII.0 evaluated data overlay (black line) shows the 'ground truth'\")\nprint(\"     that reactor physicists trust. Compare ML predictions against this!\")\nprint()\nprint(\"U-235 Fission (Data-Rich):\")\nprint(\"  \u00e2\u20ac\u00a2 ENDF-B curve is SMOOTH (physics-based evaluation)\")\nprint(\"  \u00e2\u20ac\u00a2 Decision Tree creates JAGGED predictions (staircase effect)\")\nprint(\"  \u00e2\u20ac\u00a2 Blue scatter: EXFOR experimental measurements\")\nprint(\"  \u00e2\u20ac\u00a2 Red line: Decision Tree - discontinuous, unphysical\")\nprint()\nprint(\"Cl-35 (n,p) (Data-Sparse):\")\nprint(\"  \u00e2\u20ac\u00a2 ENDF-B provides smooth reference even where EXFOR is sparse\")\nprint(\"  \u00e2\u20ac\u00a2 Decision Tree must transfer knowledge from other isotopes\")\nprint(\"  \u00e2\u20ac\u00a2 Large gaps between measurements test generalization\")\nprint(\"  \u00e2\u20ac\u00a2 This is where physics-informed models REALLY shine!\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Decision Trees produce predictions\n",
    "\n",
    "A Decision Tree recursively splits on feature thresholds:\n",
    "\n",
    "```\n",
    "if Energy < 10.5:\n",
    "    if Energy < 5.2:\n",
    "        return 150.0   # constant within this leaf\n",
    "    else:\n",
    "        return 89.0    # discontinuous jump at boundary\n",
    "else:\n",
    "    return 45.0\n",
    "```\n",
    "\n",
    "Each leaf returns a single value, so the predicted cross-section curve is a\n",
    "step function regardless of how the tree is tuned. Compare this with the\n",
    "smooth Breit-Wigner form that describes resonance peaks in nuclear\n",
    "cross sections:\n",
    "\n",
    "$$\\sigma(E) = \\sigma_0 \\frac{\\Gamma}{(E - E_r)^2 + \\Gamma^2/4}$$\n",
    "\n",
    "---\n",
    "\n",
    "## Baseline 2 -- XGBoost\n",
    "\n",
    "XGBoost builds an ensemble of shallow decision trees via gradient boosting.\n",
    "Because many trees contribute to each prediction, the resulting curve is\n",
    "a sum of many step functions -- still piecewise constant, but with finer\n",
    "steps.\n",
    "\n",
    "The same randomised hyperparameter search and subsampling strategy are\n",
    "applied here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:45:49.019962Z",
     "iopub.status.busy": "2026-01-26T21:45:49.018865Z",
     "iopub.status.idle": "2026-01-26T21:53:51.719087Z",
     "shell.execute_reply": "2026-01-26T21:53:51.711598Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HYPERPARAMETER OPTIMIZATION FOR XGBOOST\n",
    "# ============================================================================\n",
    "# Use Randomized Search with subsampling to find good hyperparameters efficiently.\n",
    "# XGBoost is an ensemble of decision trees trained via gradient boosting.\n",
    "#\n",
    "# MEMORY OPTIMIZATION: The full dataset (~10M samples) is too large for grid search.\n",
    "# We use two strategies:\n",
    "#   1. SUBSAMPLING: Use 10% of data (~1M samples) for hyperparameter search\n",
    "#   2. RANDOMIZED SEARCH: Sample from parameter space instead of exhaustive grid\n",
    "#\n",
    "# The final model is still trained on FULL data with the best found parameters.\n",
    "\n",
    "# ============================================================================\n",
    "# USER CONFIGURATION: Hyperparameter Search Space\n",
    "# ============================================================================\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# n_estimators: Number of boosting rounds (trees in the ensemble)\n",
    "# ----------------------------------------------------------------------------\n",
    "# More trees = more capacity, but diminishing returns after ~200-500\n",
    "XGB_ESTIMATORS = [100, 150, 200, 250, 300]  # Options to sample from\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# max_depth: Maximum depth of each tree in the ensemble\n",
    "# ----------------------------------------------------------------------------\n",
    "# XGBoost trees are typically SHALLOWER than single Decision Trees\n",
    "# because the ensemble combines many weak learners.\n",
    "XGB_DEPTHS = [4, 5, 6, 7, 8, 10]  # Options to sample from\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# learning_rate (eta): Step size shrinkage to prevent overfitting\n",
    "# ----------------------------------------------------------------------------\n",
    "# Lower = more conservative, needs more trees\n",
    "# Higher = faster learning, risk of overfitting\n",
    "XGB_LEARNING_RATES = [0.01, 0.05, 0.1, 0.15, 0.2]  # Options to sample from\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# subsample: Fraction of training samples used per tree\n",
    "# ----------------------------------------------------------------------------\n",
    "# Lower values add randomness, reducing overfitting\n",
    "XGB_SUBSAMPLES = [0.7, 0.8, 0.9, 1.0]  # Options to sample from\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# colsample_bytree: Fraction of features used per tree\n",
    "# ----------------------------------------------------------------------------\n",
    "XGB_COLSAMPLE = [0.7, 0.8, 0.9, 1.0]  # Options to sample from\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Subsampling for memory efficiency (data subsampling, not XGBoost subsample)\n",
    "# ----------------------------------------------------------------------------\n",
    "XGB_DATA_SUBSAMPLE_FRACTION = 0.1  # 10% of data for search\n",
    "XGB_DATA_SUBSAMPLE_MAX = 1_000_000  # Cap at 1M samples\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Randomized search settings\n",
    "# ----------------------------------------------------------------------------\n",
    "XGB_N_ITER = 20  # Number of random combinations to try\n",
    "XGB_CV = 2  # Cross-validation folds\n",
    "XGB_N_JOBS = -1  # Use all CPU cores\n",
    "XGB_SCORING = 'neg_mean_squared_error'\n",
    "\n",
    "# ============================================================================\n",
    "# BUILD PARAMETER GRID\n",
    "# ============================================================================\n",
    "XGB_PARAM_GRID = {\n",
    "    'n_estimators': XGB_ESTIMATORS,\n",
    "    'max_depth': XGB_DEPTHS,\n",
    "    'learning_rate': XGB_LEARNING_RATES,\n",
    "    'subsample': XGB_SUBSAMPLES,\n",
    "    'colsample_bytree': XGB_COLSAMPLE,\n",
    "}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"XGBOOST HYPERPARAMETER OPTIMIZATION (Randomized Search + Subsampling)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Parameter search space:\")\n",
    "print(f\"  n_estimators:     {XGB_ESTIMATORS}\")\n",
    "print(f\"  max_depth:        {XGB_DEPTHS}\")\n",
    "print(f\"  learning_rate:    {XGB_LEARNING_RATES}\")\n",
    "print(f\"  subsample:        {XGB_SUBSAMPLES}\")\n",
    "print(f\"  colsample_bytree: {XGB_COLSAMPLE}\")\n",
    "print(f\"\\nMemory optimization:\")\n",
    "print(f\"  data_subsample_fraction: {XGB_DATA_SUBSAMPLE_FRACTION} ({XGB_DATA_SUBSAMPLE_FRACTION*100:.0f}% of data)\")\n",
    "print(f\"  data_subsample_max:      {XGB_DATA_SUBSAMPLE_MAX:,}\")\n",
    "print(f\"\\nOptimization settings:\")\n",
    "print(f\"  method: Randomized Search (n_iter={XGB_N_ITER})\")\n",
    "print(f\"  cv={XGB_CV}, n_jobs={XGB_N_JOBS}, scoring='{XGB_SCORING}'\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARE DATA FOR RANDOMIZED SEARCH\n",
    "# ============================================================================\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from nucml_next.data.transformations import TransformationPipeline\n",
    "from nucml_next.data.selection import TransformationConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Create transformation pipeline\n",
    "xgb_transform_config = TransformationConfig(\n",
    "    log_target=True,\n",
    "    target_epsilon=1e-10,\n",
    "    log_base=10,\n",
    "    log_energy=True,\n",
    "    energy_log_base=10,\n",
    "    scaler_type='standard',\n",
    ")\n",
    "\n",
    "# Get feature columns (same logic as evaluators)\n",
    "exclude_columns = ['CrossSection', 'Uncertainty', 'Energy_Uncertainty', 'Entry', 'MT']\n",
    "numeric_cols = df_tier.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_columns = [col for col in numeric_cols if col not in exclude_columns]\n",
    "\n",
    "X_features = df_tier[feature_columns]\n",
    "y = df_tier['CrossSection']\n",
    "energy = df_tier['Energy']\n",
    "\n",
    "# Fit and transform\n",
    "xgb_pipeline = TransformationPipeline(config=xgb_transform_config)\n",
    "xgb_pipeline.fit(X_features, y, energy, feature_columns=feature_columns)\n",
    "\n",
    "X_transformed = xgb_pipeline.transform(X_features, energy)\n",
    "y_transformed = xgb_pipeline.transform_target(y)\n",
    "\n",
    "X_arr = X_transformed[feature_columns].values\n",
    "y_arr = y_transformed.values\n",
    "\n",
    "# Handle NaN/inf\n",
    "valid_target = np.isfinite(y_arr)\n",
    "if not valid_target.all():\n",
    "    print(f\"  Removing {(~valid_target).sum():,} rows with invalid target\")\n",
    "    X_arr = X_arr[valid_target]\n",
    "    y_arr = y_arr[valid_target]\n",
    "\n",
    "if MISSING_UNCERTAINTY_HANDLING == 'exclude':\n",
    "    # Drop rows with any NaN/inf in features (no imputation)\n",
    "    nan_rows = np.isnan(X_arr).any(axis=1) | np.isinf(X_arr).any(axis=1)\n",
    "    if nan_rows.any():\n",
    "        n_before = len(X_arr)\n",
    "        X_arr = X_arr[~nan_rows]\n",
    "        y_arr = y_arr[~nan_rows]\n",
    "        print(f\"  Dropping {n_before - len(X_arr):,} rows with NaN/inf features (exclude mode)\")\n",
    "else:\n",
    "    X_arr = np.nan_to_num(X_arr, nan=0.0, posinf=1e10, neginf=-1e10)\n",
    "\n",
    "print(f\"\\nFull dataset: {X_arr.shape[0]:,} samples x {X_arr.shape[1]} features\")\n",
    "\n",
    "# ============================================================================\n",
    "# APPLY SUBSAMPLING FOR HYPERPARAMETER SEARCH\n",
    "# ============================================================================\n",
    "n_samples = len(X_arr)\n",
    "target_size = min(\n",
    "    int(n_samples * XGB_DATA_SUBSAMPLE_FRACTION),\n",
    "    XGB_DATA_SUBSAMPLE_MAX\n",
    ")\n",
    "\n",
    "if target_size < n_samples:\n",
    "    rng = np.random.default_rng(42)\n",
    "    subsample_idx = rng.choice(n_samples, size=target_size, replace=False)\n",
    "    X_arr_search = X_arr[subsample_idx]\n",
    "    y_arr_search = y_arr[subsample_idx]\n",
    "    print(f\"Subsampled for search: {n_samples:,} \u00e2\u2020\u2019 {target_size:,} samples ({100*target_size/n_samples:.1f}%)\")\n",
    "else:\n",
    "    X_arr_search = X_arr\n",
    "    y_arr_search = y_arr\n",
    "\n",
    "# Split subsampled data for search\n",
    "X_train_search, X_test_search, y_train_search, y_test_search = train_test_split(\n",
    "    X_arr_search, y_arr_search, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Also split full data for final evaluation\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
    "    X_arr, y_arr, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Search train set: {len(X_train_search):,} samples\")\n",
    "print(f\"Full train set:   {len(X_train_full):,} samples\")\n",
    "\n",
    "# ============================================================================\n",
    "# RUN RANDOMIZED SEARCH\n",
    "# ============================================================================\n",
    "print(\"\\nStarting Randomized Search...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "base_xgb = xgb.XGBRegressor(\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror',\n",
    "    tree_method='hist',\n",
    "    n_jobs=-1,\n",
    "    verbosity=0,\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    base_xgb,\n",
    "    XGB_PARAM_GRID,\n",
    "    n_iter=XGB_N_ITER,\n",
    "    cv=XGB_CV,\n",
    "    scoring=XGB_SCORING,\n",
    "    n_jobs=XGB_N_JOBS,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_search, y_train_search)\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Get best params\n",
    "best_params_xgb = random_search.best_params_.copy()\n",
    "best_params_xgb['random_state'] = 42\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SEARCH COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Best CV Score ({XGB_SCORING}): {random_search.best_score_:.6f}\")\n",
    "print()\n",
    "print(\"Optimal Hyperparameters (found on subsampled data):\")\n",
    "for key, value in best_params_xgb.items():\n",
    "    if key != 'random_state':\n",
    "        print(f\"  {key:20s}: {value}\")\n",
    "\n",
    "# ============================================================================\n",
    "# RETRAIN ON FULL DATA WITH BEST PARAMETERS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RETRAINING ON FULL DATA WITH OPTIMAL HYPERPARAMETERS\")\n",
    "print(f\"Training set: {len(X_train_full):,} samples\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "final_xgb = xgb.XGBRegressor(\n",
    "    **best_params_xgb,\n",
    "    objective='reg:squarederror',\n",
    "    tree_method='hist',\n",
    "    n_jobs=-1,\n",
    "    verbosity=0,\n",
    ")\n",
    "final_xgb.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Evaluate on full test set\n",
    "y_test_pred = final_xgb.predict(X_test_full)\n",
    "\n",
    "# Inverse transform\n",
    "import pandas as pd\n",
    "y_test_pred_orig = xgb_pipeline.inverse_transform_target(pd.Series(y_test_pred)).values\n",
    "y_test_orig = xgb_pipeline.inverse_transform_target(pd.Series(y_test_full)).values\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "test_mse = mean_squared_error(y_test_orig, y_test_pred_orig)\n",
    "test_mae = mean_absolute_error(y_test_orig, y_test_pred_orig)\n",
    "test_r2 = r2_score(y_test_orig, y_test_pred_orig)\n",
    "\n",
    "print(f\"\\nFinal Model Performance (on full test set):\")\n",
    "print(f\"  Test MSE: {test_mse:.4e}\")\n",
    "print(f\"  Test MAE: {test_mae:.4e}\")\n",
    "print(f\"  Test R\u00c2\u00b2:  {test_r2:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN FINAL MODEL VIA EVALUATOR FOR CONSISTENT API\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING FINAL MODEL WITH EVALUATOR API\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show uncertainty weighting configuration\n",
    "print(f\"\\nUncertainty Weighting:\")\n",
    "print(f\"  use_uncertainty_weights:      {USE_UNCERTAINTY_WEIGHTS}\")\n",
    "print(f\"  missing_uncertainty_handling: '{MISSING_UNCERTAINTY_HANDLING}'\")\n",
    "print()\n",
    "\n",
    "xgb_model = XGBoostEvaluator(**best_params_xgb)\n",
    "xgb_metrics = xgb_model.train(\n",
    "    df_tier,\n",
    "    use_uncertainty_weights=USE_UNCERTAINTY_WEIGHTS,\n",
    "    missing_uncertainty_handling=MISSING_UNCERTAINTY_HANDLING,\n",
    ")\n",
    "\n",
    "# Store pipeline for predictions\n",
    "xgb_model.pipeline = xgb_pipeline\n",
    "xgb_model.feature_columns = feature_columns\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY INSIGHT:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"XGBoost produces SMOOTHER predictions than a single Decision Tree\")\n",
    "print(\"because it averages many shallow trees. However, it's still\")\n",
    "print(\"fundamentally piecewise constant - just with more (smaller) steps.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:53:51.758854Z",
     "iopub.status.busy": "2026-01-26T21:53:51.756731Z",
     "iopub.status.idle": "2026-01-26T21:53:54.113670Z",
     "shell.execute_reply": "2026-01-26T21:53:54.110641Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================================\n# XGBoost vs Decision Tree Comparison with ENDF-B Reference\n# ============================================================================\n# Using CrossSectionFigure for consistent, publication-quality visualization.\n# Now includes ENDF/B-VIII.0 evaluated data as the physics reference.\n\nfrom nucml_next.visualization import CrossSectionFigure\n\n# ============================================================================\n# FIXED ENERGY RANGE FOR COMPARISON PLOTS\n# ============================================================================\nE_MIN_PLOT = 1e-4   # 10^-4 eV\nE_MAX_PLOT = 1e7    # 10^7 eV\n\n# U-235 fission comparison\nZ, A, mt_code = 92, 235, 18\nenergy_range = (E_MIN_PLOT, E_MAX_PLOT)\n\n# Extract U-235 data from training set for prediction\n# Use ACTUAL data points, not synthetic energies\nmask_u235 = (df_tier['Z'] == Z) & (df_tier['A'] == A)\ndf_u235_pred = df_tier[mask_u235].copy()\ndf_u235_pred = df_u235_pred[(df_u235_pred['Energy'] >= E_MIN_PLOT) & (df_u235_pred['Energy'] <= E_MAX_PLOT)]\ndf_u235_pred = df_u235_pred.sort_values('Energy').reset_index(drop=True)\n\n# Get XGBoost predictions on actual data points\npredictions_xgb = xgb_model.predict(df_u235_pred)\npredictions_xgb = _clip_positive(predictions_xgb)\nenergies_xgb = df_u235_pred['Energy'].values\n\n# Get Decision Tree predictions on actual data points\npredictions_dt = dt_model.predict(df_u235_pred)\npredictions_dt = _clip_positive(predictions_dt)\nenergies_dt = df_u235_pred['Energy'].values\n\n# Get ground truth from evaluation dataset\nmask = (dataset_eval.df['Z'] == Z) & (dataset_eval.df['A'] == A) & (dataset_eval.df['MT'] == mt_code)\ndf_truth = dataset_eval.df[mask].copy()\ndf_truth = df_truth[(df_truth['Energy'] > 0) & (df_truth['CrossSection'] > 0)]\ndf_truth = df_truth[(df_truth['Energy'] >= energy_range[0]) & (df_truth['Energy'] <= energy_range[1])]\n\n# ============================================================================\n# Create comparison figure using CrossSectionFigure\n# ============================================================================\nfig_comparison = (\n    CrossSectionFigure(\n        isotope='U-235',\n        mt=18,\n        title='XGBoost vs Decision Tree vs ENDF-B: Classical ML Limitations\\nU-235 Fission (Model trained on full EXFOR)',\n        figsize=(14, 7),\n        endf_dir='../data/ENDF-B/neutrons',\n    )\n    # Ground truth - EXFOR scatter (zorder=1, behind)\n    .add_exfor(\n        df_truth,\n        label=f'EXFOR ({len(df_truth)} pts)',\n        color='tab:blue',\n        s=30,\n        alpha=0.5,\n        zorder=1,\n    )\n    # ENDF-B evaluated reference (zorder=2, physics ground truth)\n    .add_endf_auto(\n        color='black',\n        linewidth=2.0,\n        linestyle='-',\n        alpha=0.9,\n        label='ENDF/B-VIII.0 (Physics Reference)',\n        zorder=2,\n    )\n    # Decision Tree (zorder=3, middle)\n    .add_model(\n        energies_dt,\n        predictions_dt,\n        label='Decision Tree (Staircase)',\n        color='tab:red',\n        linewidth=2.0,\n        linestyle='--',\n        alpha=0.8,\n        zorder=3,\n    )\n    # XGBoost (zorder=4, on top)\n    .add_model(\n        energies_xgb,\n        predictions_xgb,\n        label='XGBoost (Tier-Based Features)',\n        color='tab:green',\n        linewidth=2.5,\n        linestyle='-',\n        alpha=0.9,\n        zorder=4,\n    )\n    .set_energy_range(E_MIN_PLOT, E_MAX_PLOT)\n    .add_legend(loc='best', fontsize=11)\n)\n\nfig_comparison.show()\n\n# ============================================================================\n# SUMMARY: Classical ML Limitations\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"COMPARISON: XGBoost vs Decision Tree vs ENDF-B\")\nprint(\"=\" * 80)\nprint()\nprint(\"Legend:\")\nprint(\"  Blue scatter : EXFOR experimental measurements\")\nprint(\"  Black line   : ENDF/B-VIII.0 evaluated data (physics reference)\")\nprint(\"  Red dashed   : Decision Tree (staircase effect)\")\nprint(\"  Green solid  : XGBoost (smoother but still piecewise)\")\nprint()\nprint(\"Key Insights:\")\nprint(\"  [OK] XGBoost is SMOOTHER than Decision Tree (ensemble averaging)\")\nprint(\"  [!]  But XGBoost still has micro-steps - fundamentally piecewise constant\")\nprint(\"  [!]  Neither model matches the smooth ENDF-B curve (physics-based)\")\nprint(\"  [!]  No awareness of resonance physics or nuclear structure\")\nprint()\nprint(\"The ENDF/B-VIII.0 curve demonstrates what physics-informed evaluation\")\nprint(\"looks like: smooth, continuous, respecting nuclear physics constraints.\")\nprint(\"Classical ML cannot achieve this without architectural changes.\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Decision Tree and XGBoost\n",
    "\n",
    "The comparison plot shows both models against the ENDF/B-VIII.0 reference.\n",
    "You may observe that:\n",
    "\n",
    "- XGBoost produces a smoother curve than the single Decision Tree because\n",
    "  it averages hundreds of weak learners.\n",
    "- Both models are piecewise constant by construction -- the underlying\n",
    "  architecture does not enforce continuity or smoothness.\n",
    "- The ENDF/B-VIII.0 evaluated curve, derived from nuclear-physics models,\n",
    "  is smooth and continuous across the full energy range.\n",
    "\n",
    "---\n",
    "\n",
    "## Feature importance\n",
    "\n",
    "XGBoost provides per-feature importance scores (gain-based). The bar chart\n",
    "below shows which input features the model relies on most heavily when\n",
    "making splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:53:54.124896Z",
     "iopub.status.busy": "2026-01-26T21:53:54.124306Z",
     "iopub.status.idle": "2026-01-26T21:53:54.598201Z",
     "shell.execute_reply": "2026-01-26T21:53:54.595351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAjyBJREFUeJzt3Qm8TfX+//HPMROR46REaCJRGTJEJYrKcKVyq5s0l1RKrjGzm5LoIpSikhSSBlE0UqHJLYVKyBBCdMhs/x/v7/+x9m+fyRnsdfY+67yej8d2ztlr77W/e3332tZnfT7f70oIhUIhAwAAAAAAUVcg+qsEAAAAAAAE3QAAAAAA+IhMNwAAAAAAPiHoBgAAAADAJwTdAAAAAAD4hKAbAAAAAACfEHQDAAAAAOATgm4AAAAAAHxC0A0AAAAAgE8K+bViAIDZ119/bf/6178sFApZiRIlbO7cuXbSSSeFN8327dvtiiuusL/++ssSEhJs6tSpVrdu3RSb7pNPPrFZs2bZ999/b9u2bXOP0zr0uI4dO9rZZ5+d4vFjxoyxsWPHptn8BQsWtKJFi9opp5xiLVu2tLvvvtuKFCkS1920cuVKq169eqaPq1atWqaPufnmm61v377mtwMHDtj69evt9NNPt3jlba/69evblClTLGi0/U844QQrWbKkBZHeX6tWraxKlSr21ltvZenz7/nggw/sjTfeCH9HvPTSS9agQQPLLRm1tXDhwlamTBmrUaOGdenSxc477zzLKy6//HL77bff3Hfrhx9+mOHjNmzYYM2bN890fb1797ZbbrnF/LZ79277888/rVKlSpZX/PDDD9a+fXu78MILbfLkybFuDpBlZLoBwEcKjG+88Ub3+99//21Dhw5Nsfzxxx93Abdcf/31KQLuPXv2WLdu3eyuu+6yefPm2caNG23//v22b98+W7t2rb3++uvu4GPatGlZasvhw4ddG37++Wd3wP3AAw9YvNq8ebP16tXLrr76assrdGLlnXfecSdR3n333Vg3J1/auXOnDRs2zK688kr3e1D95z//cd8FOqEXFAcPHrQ//vjDnWS86aab7Jtvvol1kwLr0KFD7gSvThZ8+eWXlpecc845dv7559vnn39ub775ZqybA2QZmW4A8JkCZ2U/fv/9d5s/f777vVmzZu5gxztoKF++vHXv3j3F8/r06eOCbaldu7bdcccdduaZZ9quXbts9uzZ7qDpyJEjNnjwYHcgcu6556Z57aeeeso9VwGhgm4Fs4MGDbKffvrJPvroI/viiy+sUaNGcfcZ+Pe//21Lly7N9vN0MPbf//433WXHHXec+Un9+fDDD/v6Gjg6ncRSVUiQfffdd27f1ee5TZs27j4FqpH++c9/un1dFTGvvfZaimVJSUl266232nXXXef+Llu2rMVC5L6q7zGdTNT348iRI121yJNPPum+44JKJ+eU0U5PqVKlfH3tt99+2/2/kVfpRPayZcts1KhRruKjUCHCGcQ/PqUA4DOVuCrQVcZahgwZYvXq1XP3efr375+iFFYHn17AffHFF9v48eNTHFgowC5evLg999xz7oD1hRdecAerqemAOrKcvWLFinb//fe7myxfvjwug+6cUrl85PvNTTqxgdjKD33w/PPPu59NmzZ1Q1Yk9WdeQ0m8n+ntD/quiXXpfXr7qoa8qFpEJwX13RRk+v7muypnVKKv4Qg6kf3ee++5wBuId5SXA0AuuOSSS6x169bu902bNlmHDh1cmbdofPVll12W4vGvvvpqiox3emfyb7/9dpdFnzRpkg0YMCDLbSlQ4P+++lNnuRTAT58+3ZW668SAslHt2rVzr6HsU2q6T0GAysCVUddNWbaZM2emCYCUoVfpr0oaa9as6W46eNJJCC2LHPMZmeXW3xq7Hk16nxrLqkxhrVq13Njme+65x2URU1PGUCdFVJ2gkx116tRxfakSfZX4euPoNWbco2Vq95IlS9zfeq7+1s9Iysrqft0iM7TefY899pi7abvqdb3PhV5Xr6HPjrajxjfqs/Drr7/meJtoG+s19dnU8IV7773Xvaa2jT6DycnJ7v7OnTu79mgcsIYARPad3q/Xdp040nhxtVHb+KqrrkrxuY6kigttf70PvR/tD48++qibwyCStrO3/q+++sr1nx6vcvKLLrrIjVX26LMVub2z0o+p+0RzCuiElredW7Roke44Uj1fJ8bUHq1b20b7UHrlr6tXr7YHH3zQGjZs6LaLMp5PP/10ijZkZO/evS7LLam/M7Ijcjt6n1GPxohfe+21bky1hrvoc/3pp5+meExkP2ubK1jWe1H//fjjj3YsvO+n1N9N+q7RdlKfqe+0ndWXjzzyiG3ZsiXFY7/99lv3edIJRY0R1+OV2deQnNSysy/pdfSZV99p+2jctT4jfspO+3755RdXbaMTMnqsvsM1BOnFF19033mi9kdm2PW7+lHjzcXr19Tfuel9ZvQc7z79P9CjRw+3XfSd8fHHH7vHaPiUvvfVV2qT9tN+/fql6TPv5LH3f4mqtxo3buxOEHv/V3p0wkh9IKkrOYB4RaYbAHKJJvH67LPP3MQ1a9ascfcdf/zx7gAkvQnYRBPzVK1aNd316aBUB7vZGcenoGncuHHub01apADYo/JzHaimPsBesWKFuymI0oGVl13TmHMdmGlim0gq+9NN61H5n7JtOqBSSWvqx+qg7eWXX3YHyQr2c6tMUKX8c+bMSXFAr2Bm0aJF7gBXB62iQFPjSzVxVeRBsA4CddMJFAWHflGQ4I35FwUPauttt93mgs7ICfn0fnSgq5MJOrjNKQWnCrwjg2m1Q59ZHeh7Y6U1P4ACLv09YcKENOvRQfqqVatSBJs6OaRtpqDBo+fqcxJJ21uBgsbG62d6k9Ip+Pe2jYZdHC0zmtN+1AmhyO28bt06dxJE5b8KTEX9oeArcgyy1q3PtG7abgqyRSd19FjtOx4tHz16tDvxoIBeGbyM6GSUF5wrMIm2ESNG2MSJE1PcpwBLrztw4EB3IiE1bTevHzTJY3YmdfPoBJ22iYbNeEGsV/4euc8qqxlJ81zMmDHDDe3QZ0XfNdrG+l7SGHGP1q37dVNb9V0k2dmXduzY4U4oKrvqUZ95c3b4ITvt03epxvhHzmWgbaDvXN00aZomqPOL9mPvc6D/S3TCVt8h+sxEniDYunWr+67X960CZv0fJ9qvtK9H0km3999/330G1c+VK1cOL9P6Fy5c6PY7nYxS5QAQz8h0A0AuUZDslXV7dDCuMZaRFJTrIEJOPPHEFMu8cdnp3dKjLJWXiVDmQGV4OgBTWeMzzzzjgn6PAmov4FaGSFlJZf28DL0ObnRgFDl+1guitV49Vs9RdkJ0gOyVwir75T1WY9NVOq+DZAVCoqyHAhRvfKoOqDz6O6Nx2qkpOPDeb+RN2R2PZpD3Am5l8TW+UQd/CmJ0kKqsrpfVX7BggQvIREGH/tY40woVKrj7vJmKdRCv8fMeBVZq97EGRjqI1TbS9tL6zzrrLHeg7R2Ea1t6gelpp53mgotjnaFdfaF1qVpBmSevDFn9rxnB9f51okQnbUTv0/u8RlLArSEVKhdW/+m58uyzz4YPwrVOb7vp4FvZYvXNQw895E7AaGItTfinz31qCk7VDh3A62SR+lBZY4/+9rJgWe3H1BSkKfDWgf+dd94Zvj+yKkGBshdwKxupwFFt0v7mvV8F+wos1TfqI20LndxRv+qkm7K7ChwzG8PsvY7225NPPtmiSe/VC7iVjdSJFmXqlaFU2xVcK2BK74SGMpnqN30/eKXt2dlXdYUCZdW1rUXBbeQJRZ0s9MatKxjXdlPbmjRpEl7ufaZ0v/ZjnRzU8Bv19SuvvOJOzOgzped6Wd/s7EsKKr2A29s+Wq9OikaeRMkqnbBK77tKJ6s82Wmf3reCXJXta3/T+9b79+ay8D7jymynznRr2x7r50nfVTqZpu9X7dP6ftBP9YtOxug7WNte+7j+z9O+HTmxqIJqUZ9qH1L7tVyfJ+3/+juSd1UL9bX3fwcQz8h0A0Au0YFr6lmtdQY/9QzEkeXfqYMNZTNU4pqeyKxiZpRB0AGjgjgvc+0d8OvkgMo4vYO1J554wpUtKgOlYKNnz57uvejASLQOPcY72FYwoTbqoErlxQq8SpcuHX5tZSQVkHhlywqqIpfrhEDkpcyiPe5RQaAXtOkkiA7EFcToIF/BmzJJOvmg8l2VOqosWkHTGWec4Z6ngFxtUhDnZYMVmEaWw+rvaLS7WLFiblI5/fQqHrz2K2D0SkDVV/pd8wSon1SZkPpSctmhMmyV5YrKOL0DXp0kUsmqd78XwOiAO3WmScu9ieW8CQC1Xn12dNkqBQ76DHrDEHSA7k0GqG2tz4+Can32lFH0AizPDTfcYBdccEGK+yLbUK5cufAJraz2Y2rK+Osmei9qr4KdyLJ37wSOst86EeW1QTOMq90KpBRka//UWGWvPSrHFn3OvGyeArGjXSrKC3pTn4yLBu9zJdontf283xWwKcOu76/U7VMfqIRZvG2rrHDq4SjZGUeuiiBVnWhYjujSaAqsVGmgz70ufahtocynHideH3ong9TexYsXu/7QttZVHvS8yO+W7OxLXtCv70vNn+GdsNSEbzrZ4ofstE9ZbPWNtou+K7RfKrutfUCfWW/76Ls28mSrfo/Gd5VOmnknSrRvR/5/p5OoGgIi+l655ppr3EkMZet1kln7h26qntGl11QppRO/OsGiYSLpTfYXuQ9EVh8A8YqgGwByiQ7YI8sEvWywMgPeAYl3UKQDOx2AqHzyWHizl3sZAR3gKHDWAagyIwrqddCo+71sucbkRc70rZMACqB0gKd1eJkLr8xV41cjs1tquw6yVI6uA0AdgOs6sBojrCyHDoR1k1NPPdUFU8psZeV63DmdvTwyGFNWzNseGV0zVycGvDGzCv4UXCozpwPcyHJvL2Pm18Rf2m4KuCN57Vew6AUl6bX/WIJuHTR7Ij8LXlCV+v7IUl5PZLWCVxrv8caPeieKFIylnn1fY1cVdHuPSx10K5DPjpz0Y2RZuz7zCugUwGiohkeBoCgAjPycaftH9oE3pEQ0R4JuqanUXcFqZGAYSSeExI9J0LzPVXql3Z7Uw0My6oeuXbumufrAfffdl6LSJ/Xs5aqW0PvXiQt9PvR9oe8o7zOn70NdJkq377//Ps2YYO8EpQJSnSRQdY0yvbrpBJsCbw2n0UkUb/tlZ1/yKiUU0EYGrTohoM9Fdi9Rl9Hs5ZF9m919Xf9fqHJH/8/o+1rbLLe+q1J/DvR/irdNdMIkvfarTWqnAmxVfChTrqBb1SiiYFv/v6giyRvyk973j7dfAPGM8nIAyAU6aFJw69E4PY8u3aLANJI3o7gOJiIn99KBvQIQ7+aNh8uIN3u5bgrgFNjogEYHiqJMhILnzMZSRx5wKfjI7uO9A3FlBXXwrQBMWScdYOlkhDJ/GZX45mRG5NS3yEx6Vspfvf5QplIZUpV8KrupkwPK5Od0EqvUlQuZTZ6VXnCVlfbrgPdYRAb6kZUXkfd7/ZqR1JnO9D4TR3sv6T0+p5dVymk/pj7hkV57vXZGBuLpycp8Bfp8ZJR1j5TZts+J7OwX0bi8VeS+qkyuTnAoENXQAm97alI374SJJqnTd6Xmu7j00ktdcJ56uI4oANbQCJ3gU4Ct7zqdFFJpvp6jLKt3wiU7+5K3zdMLPiP3kezOXp76FrnPZ6d9OkGh4FTDGfR+NeRFv6d3Kcnc+K7K6jAD7zOlPlUFjIJvBdj6ztYynZRWBn348OEZruNo8yAA8YJMNwDkApXVeuP+VIqpEm2VxOmAQgcWOpiMHBOsSZp0ACIaL6mxtQpSUwc16c0onhXeAZEyDcqGqLTPG2enIF9t9TIJeow3W60OlJUF1X36Xa+vZfrbO/DU+v73v/+533UQqXXrwFBZLGVuVE6vg2XvQFjl57pGr7KaqWf39g5yoxlkeCcudNCrcbTeAZtOcCggUybLyzR6s0rrgFLl9N793vjDSJFtTH1g7r2Gyj0jZVYWmd7BpNqvjKOCiciJpbQuZQtVPRAP163Vto2k7KTHmxBJgZayztou+txFBggKlD3pZe3Te48Z9UF2+jG79F5UNq4TSBrf7AWher8ao6z9RcGf+sWjwFJDGTzKymr/Sz2/Q2qJiYnuZ07GEGflfXg0vKJ8+fLud/WNsvl6H+lNVpVeP2hYSU5Frs97n6rM8TLNCqa96h1lsVNTRYFu2he8MeL6jlVlgcase+PDFcRnZ1/S7/oO07q1TSKz5emdjIiG7LRP/38oUFY/6XPt7QvpBauZfVfpu/lYv6sUNHsVAJrnI7KyQ9tM/wfppLH+39D3v/YhbVudkNU8FmqXJl/UsA5lwzX8Sb97/3dFVqp480UA8YxMNwD4TOM0NcuqaJykAm7RpW68DKyCb43r9Cj49K49qsBU41e1XAf2OgDRBDua4ExB8tHoYNCbaE0HTTqI0UzR+ik6QPMOWLzZmBV8KijWuDoFA5oAx5tRWFkilY/rgNObtEoHSxp3rMfqOXqu1y5vojQdxKvsU1kMlVQqIFF7dPMyKpEH25EnGJTZiuZleXSwLTpo1SVu1G4F4Tqga9u2rSt79S575B3066ey9DooVPbIG0cameGMbLPGIesA3TsYjwxglIXzTmTk5HI3Xvt14KqJhvQ62p7KBmmYgsbYpjfhVW7zgk59PnQCyZuhXAfZXlm/95kTlZZqRmN9NrWNvcuLac4AlZhmRWRZtoJ4L9DPTj9mlzLo3skm7QcKkrz3rpNP2v9VcaL34Q2hUACidmh/VoZS20Hl8+llbiOpWkUymjjxWHifK9F3lPZlb8Z5nShUoJt6MqtjoRN2kRNBqqRcJ1oih4d4QxIiTzJou+mzryodb6JG8b5HNNZZM9trtnOdrNRjtT9ElqN73zXZ2Ze8uTT0vaFx7vp86bspcib+aMtO+7xtpO9UjZVW32liO30Xpf58R35XeVen8ErRve8qPU/7h7arhmVE/v+U3fZrSIDGcGtokk7GderUyVWZKKOtgFsnOzXLub6PNW+ExvTr86A+04ks73sj8mRB5HdcdoeaALEQ+1PhABBgCj6VqfZotllvoh8F4DrI8GagVdm3DqK8IFizBevgSGOwdSCf0QG5MmsZLfMuVZQeZQwiZ/XWGEqNvdN4ax306BZJB8DeCQPvpIGCYQVVmvAnciIm0eRCXhm9TiDoIFkHg94tdbCkjLdHwYl3okKZcY3rjLzE17HQuE6NL1S2S21KPbmdAiBvEjEdaCsAV9YlcltF0gGjMvo6geFl/5WV0k3ZJx0c6wSJVy2g/ta20zoV4Cu4yQ6dgNG4TX0mlFFMnVXUAbkfE21ll2ZDVvWCNy7bowmfvKyvhlEo46sDck1yFpn9FWV+tQ2zWr4bOS+AgiFlZrV9s9OP2aXPuD7Peh2dNPCuo+1RAOgN51DfaxZqlZCnDtb0vaChF0fjTWKnLJ+Cq2jOYK7JDfXZUlZZwW9kpYHopEB6lSg5pe2V0Thl0Wzm3ok97bM60aiTVel95sU70aeTegrqVF2j797I71/Rvu2d9MnOvnT77be7eSr0fRf5/ajPmKpjIsfsR0t22qfPuDLcOimQej8SbQ8F3jrhEHlZN2+9eq4qTfRdpf1RwbbeswLdnH5XqR0aNqSx5jrpFnlpQO3TOtGpIRwVK1Z0w480QZ2qKiKHX0V+b0R+D3gnYrX9c3KZOiC3kekGAB+pbNwbo6kxa15WLDLA0yRlXobZK4cUHYzogFFjnvU4BXUq+db9KstTUKvsh7LIOsjMjA6eVAKooP7iiy92lzqKPOhVwKj71AYd8CqYV9CvQEbBti5VE1leqiy9LpujEwc6YFcGXMs1EZvapYyVVwqoAz2Np1WZvQ7sFGDoPgVVeh/KanoBhWgWXm0vTVik9xzN4ELbQeN59Z5Utqw2K3Ov693qvStT5tGJAAVHChK1LbTdNW4yMhvnDQPQ9tL788rT9Vgvo6SJqRQMqFxUy/QY/R35Wlml/lcAopMkKs/Wa6gvtP10vef0DrhjQVUR2p56z/rc6cSJPhepA0uVWutzp0BI5dN6rLadLnenUvD0rtGdkX/84x8uu6b1qF/1msqkZacfs0vr076h7Kfaqv7V51snqRRERJ740oz9upyYTsTopJveqz7byiTr/syCB+1b3tUGlD2MNmW11UcKsLTfaRsqQ68M/rhx43I0djmr9F2h19M2VDCp0nHv+8P7bOt7Ro/RttNJAJ3Q8baHNyeEtqGqSVRlo5Mderz6SJ8F7RsKML2KiOzsS9oeeq7mA9B3qNarsmmVPWsb+SE77dMJHQWr3uzu+qyrukh9KjoZ6J0o0LoU5CrY1bbwTgqJ9k+dKNLnUsv0Hamx8Dn5XlE/KZjXvqwqDX3eVfWhvtM+r/3Voz5X9Ykux6Zsu3dVCVW56MSbTlZF8qqRtK54GE4DZCYhlNl0hAAAAFmgbL4OsNObrRrRoSEaCtCVkYycnBHIL3QCQVUyGq6jrLxO0ALxjkw3AABAHqGxr6KsZXqXagOCTp99BdyqWFHVFpAXEHQDAADkESqx1iRUGqOrMcZAfuNNsqjJ8rJ6aTIg1gi6AQAA8hDNR6DxsRpLDuQnmgFdk2Bq0tHUc6QA8Ywx3QAAAAAA+IRMNwAAAAAAPiHoBgAAAADAJwTdAAAAAAD4hKvJI184fPiI7dixJ9bNgA/Klj2Ovg0w+je46Nvgom+Djf4NLvo2Z5KSSmX6GDLdyBcKFixgCQmxbgWiTX1K3wYX/Rtc9G1w0bfBRv8GF33rL4JuAAAAAAB8QtANAAAAAIBPCLoBAAAAAPAJQTcAAAAAAD4h6AYAAAAAwCcE3QAAAAAA+ISgGwAAAAAAnxB0AwAAAADgE4JuAAAAAAB8QtANAAAAAIBPCLoBAAAAAPAJQTcAAAAAAD4h6AYAAAAAwCcE3QAAAAAA+ISgGwAAAAAAnxB0AwAAAADgE4JuAAAAAAB8QtANAAAAAIBPCLoBAAAAAPAJQTcAAAAAAD4h6AYAAAAAwCcJoVAo5NfKgXixr9vwWDcBAAAAQA4l9+5s8SgpqVSmjyHTDQAAAACATwi6AQAAAADwCUE3AAAAAAA+KeTXigG/bNiwwZo3b57h8lWrVrHxAQAAAMQFgm7kOSeffLItWrQoxX179+61Tp062RlnnBGzdgEAAABAagTdyHMKFixoSUlJKe7r0aOH/f333/boo4/GrF0AAAAAkBpBN/K8d9991958800bPXp0mmAcAAAAAGKJidSQp23ZssUGDRpk7dq1s5YtW8a6OQAAAACQAplu5FmhUMj69Oljxx13nPXr1y/WzQEAAADgk4SEvLtpCbqRZ7388sv2+eef20svvWQlS5aMdXMAAAAA+KRcuVJ5dtsSdCNPWr16tY0YMcJuvfVWu+CCC2LdHAAAAAA+2rYtOc+eDCDoRp5z6NAhN1t55cqV7cEHH4x1cwAAAAD4LBTKu5uYoBt5zvjx423VqlU2ceJE27VrV5rlZcuWdZcVAwAAAIBYI+hGnrN06VI7ePCg3XLLLeku/+CDD6xixYq53i4AAAAASI2gG3nOlClTYt0EAAAAAMgSrtMNAAAAAIBPCLoBAAAAAPAJQTcAAAAAAD5JCIXy8uTrQPau7cenPVgSEv7/tRHp22Cif4OLvg0u+jbY6N/gom9zLikp8+t0k+kGAAAAAMAnBN0AAAAAAPiEoBsAAAAAAJ8QdAMAAAAA4JNCfq0YiCf7ug23krFuBHyxz4y+DTD6N7jo2+Cib/NX/yb37hzD1gB5A5luAAAAAAB8QtANAAAAAIBPCLoBAAAAAPAJQTfytFmzZlm1atVsxowZsW4KAAAAAKRB0I08bc6cOXbqqafam2++GeumAAAAAEAaBN3Is7Zv325ffPGFdenSxb766itbv359rJsEAAAAACkQdCPPmjdvnpUqVcratm1rJ554ItluAAAAAHGH63QjT5eWN23a1AoUKGDNmjWz2bNnu6x3QkJCrJsGAACQL3DYFax+pD/9QdCNPOn333+3b775xm699Vb3d4sWLWzatGn29ddfW7169WLdPAAAgHyhXLlSsW4Coigxkf70A0E38myWu2jRotakSRP3d/369a106dL2xhtvEHQDAADkkm3bktnWAaAMtwLu7duTLRSKdWuCd+KJoBt5Nujet2+f1a1bN3zf4cOH3Tjvfv36WbFixWLaPgAAgPyAAC14/UmfRh9BN/KcNWvW2I8//miPPPKINWjQIHz/L7/8Yg899JDNnz/f2rRpE9M2AgAAAIAweznyZJa7TJky9s9//tPOOuus8O2qq66yM844w02oBgAAAADxgKAbeTLoVia7SJEiaZbdcMMN9vnnn9uWLVti0jYAAAAAiJQQClG1j+Db1214rJsAAAAQOMm9O8e6CYjSRGqaEEwT4xEdZk9SUuYTqZHpBgAAAADAJwTdAAAAAAD4hPJy5BuUywQPpVDBRv8GF30bXPRtsNG/wUXf5hzl5QAAAAAAxBDl5QAAAAAA+ISgGwAAAAAAnxB0AwAAAADgk0J+rRiIt+t0l4x1I+CLfWb0bYDRv8FF3wYXfRt/uJY2EFtkugEAAAAA8AlBNwAAAAAAPiHoBgAAAADAJwTdAXHw4EEbM2aMNW/e3GrWrGlNmza1YcOG2e7du7O1ngMHDljr1q1tyZIlUWtbx44drVq1ajZ79uw0y1avXu2W6TGZ+eKLL9xj165dm+7yli1b2sSJE6PSZgAAAACIBoLugBgxYoS9//77NnToUJs3b54LuD/77DPr3r17ltexf/9+69atm/38889Rb1/hwoXtww8/THP/ggULLCEhIUvrqF+/viUlJbn3mdqPP/5o69atcycMAAAAACBeEHQHxBtvvGFdu3a1Ro0aWcWKFd3PgQMH2kcffWRbt27N9Pm//PKLdejQwX777Tdf2levXj1btGiRy6SnDrrPP//8LK2jYMGCdsUVV6QbdM+dO9fq1q1rJ598ctTaDAAAAADHiqA7IJQtXrx4sR05ciR8X+3atW3OnDl2wgknZPr8pUuXWoMGDey1115Ls2zWrFmu/Hv06NHuMQqglUkPhUJZbp/aUrRoUddGz5YtW1x2WuuM9NVXX1n79u3t3HPPtTZt2th7770XXqa/ly9fbr///nuK5yi7T5YbAAAAQLzhOt0BcfPNN7ugWJnjSy65xC688EJr0qSJnXHGGVl6/o033njU5d9++62VK1fOpk2bZt9//7316tXLLr74YmvcuHGW1l+gQAE3zlwl5nqeqK0XXXSRFSr0fx/DP/74w+6++2576KGH3LJly5a510pMTHTB/nnnnecy+cp2d+rUyT3HC8KVBQcAAEBKWRzJl+X1RGt9iB/0rb8IugOiS5cuVqlSJXvllVds+vTp9uqrr9pxxx1nffv2tWuuueaY13/48GEbMmSIlSxZ0k477TR74YUXXPCd1aBbNMmb1qGyd/nggw9cSXvkGPKpU6e6EwY33XST+7ty5cq2YsUKe/HFF13QLa1atbL58+eHg26VlusEQ1Yy+gAAAPlNuXKlorq+xMTorg/xg771B0F3gLRt29bd/vzzTzd++uWXX3ZBt2b81ozmx0KZZgXcHv1+6NChbK1DAfrOnTvthx9+cCcIlMXWjOuRQfevv/7qxqGrHD1yZvaqVauG/1YZ+bPPPmvbt2937VJpuTLjAAAASGvbtuSoZUMVlG3fnmzZGGWIPIC+9fekFkF3AKxcudJdjktl2KKMr8Y+6xJaLVq0cOOojzXoLlKkSJr7sjOmW4oXL+6y2Coxr1KlipuNXNn4SArk1fZ77rknxf2RJehnnnmmu6k8/eyzz7YdO3a4LDoAAADSinaArPURdAcTfesPJlILAJV+T5482V02K3WgXKxYMStbtqzFCwXHymSrtPzyyy9Ps1wZbU2uprJy76bHvv322ykep2y37lfg3axZMxfQAwAAAEC8IegOgHPOOcdNUnbvvfe64HTDhg2udHvAgAHuEl3KdseLSy+91FatWuXK3/V7ehO6aWK0UaNG2dq1a937GTlypFWoUCHF4zSuWzOua0I1ZcYBAAAAIB5RXh4QTz31lE2YMMHGjh1rmzZtshIlSrjJxTSuO3IsdqxpDLYuBaZy8fQy8Keccop7HyNGjLDnn3/eypcv78rmNVY99eOqV69ua9asydZkbgAAAACQmxJC2R2YC+RB+7oNj3UTAAAAYiK5d+eoTbalSaM0MRsRRLDQtzmXlJT5RGqUlwMAAAAA4BPKy/OBBg0auLHdGZkzZ06aMdPZuT74559/nuHyQYMGpSkNBwAAAID8gqA7H5g5c6YdOXIkw+Unnnhijtetydr27t171DHcAAAAAJBfMaYb+Qbjj4KH8UfBRv8GF30bXPRtsNG/wUXf5hxjugEAAAAAiCEmUgMAAAAAwCcE3QAAAAAA+ISJ1JBvrtNdMtaNgC/2mdG3AUb/Bhd9G1yx6NtoXYcaAPxAphsAAAAAAJ8QdAMAAAAA4BOCbgAAAAAAfMKYbmRJs2bNbOPGjekue+mll6xBgwZsSQAAAABIhaAbWdanTx+76qqr0txfunRptiIAAAAApIOgG1lWqlQpS0pKYosBAAAAQBYxphtRKz+fOnWqdejQwWrVqmX/+Mc/bPny5eHlv//+u91zzz123nnnuceOHTvWDh8+7JbNmjXLrr/+euvSpYvVrVvX3nrrLTty5IiNGDHCla3rNm7cOLv88sttyZIlNn78eGvTpk2K1580aZLdeOON9CYAAACAuELQjagZM2aM3XXXXS5oVlZ86NCh7v5QKGT33XefJSYm2htvvGHDhg2zt99+2yZMmBB+7rfffmtnnHGGTZ8+3Zo0aWLPPPOMzZ4925588kmbPHmyffzxx7Z+/Xr32FatWtlPP/1ka9asCT9/7ty57n4AAAAAiCeUlyPLBgwYYEOGDElxX4UKFWzOnDnu96uvvtouu+wy9/utt95qXbt2db8vXrzYNm3aZDNmzLACBQrYaaedZj179rTevXu77LYkJCRY586drVixYu7vV155xR588EEXgMtjjz1mV155pfv91FNPtXPPPdfmzZvnnqMJ3n788ccUQTwAAMg/EhJi3YL8tZ3Z3sFD3/qLoBtZ9sADD1iLFi1SfoAK/d9HqEqVKuHfS5YsaQcPHnS/r1692nbu3OlKxz0qH9+3b5/9+eef7m9lwb2Ae8eOHbZ161ZXpu5RoB45YZuy2sqaK+hWlrt+/fpuHQAAIP8pV65UrJuQryQmsr2Dir71B0E3skxBbeXKlTNcXrhw4XTvP3TokAuaNS47NZWhS9GiRdME8ipLjxT5t2ZRf/zxx23dunX23nvvubHkAAAgf9q2LTnWTcg32VAFZdu3J1uqwzTkcfStvyf9CLrhu6pVq7ry8rJly4aD7M8++8xNoDZ8+PA0jz/++OPtxBNPtB9++MGqV6/u7tN47r/++iv8GC1Xdvv111+3lStXpsnAAwCA/IMAMPe3N9s8mOhbfxB0I8uSk5Ptjz/+SHP/cccdd9TnaVz2KaecYv/+97/toYcecuvp16+fXXjhhVawYMF0n9OxY0cbPXq0GzN+wgknhCdl09hvT+vWrd0Y88aNG3OtcAAAAABxiaAbWfboo4+6W2rehGkZUWCty3wpQFYZeIkSJeyKK65wk6ll5LbbbnPjuu+//373fM2K/tVXX6UoYVd2e+DAga7UHAAAAADiUUIo9cBZIA58+umnVrNmTVeS7k2u1qhRI/vggw+sYsWK7r61a9dau3btXKl6Ztn2fd3SlrEDAIBgSO7dOdZNyBdUcKjxqxpDTwQRLPRtziUlMaYbedRrr73mLhvWvXt3V1L+3//+181mroB79+7dtmjRIvcYzWKeWcANAAAAALFSIGavDBxF//793TW9r7/+eleSrkuMPf300+HljzzyiO3atcuNEQcAAACAeMWYbsSl8uXLp3uJMe8a4BrfDQAAAADxjqAb+UKxkT0YfxRAjD8KNvo3uOjb4KJvASAtyssBAAAAAPAJQTcAAAAAAD4h6AYAAAAAwCcE3QAAAAAA+ISJ1JAv7Os23ErGuhHwxT7NaM+2DSz6N7jo29yT3LtzLr4aACA1Mt0AAAAAAPiEoBsAAAAAAJ8QdAMAAAAA4BOCbsSFAwcO2PTp02PdDAAAAACIKoJuxIU5c+bYhAkTYt0MAAAAAIgqgm7EhVAoFOsmAAAAAEDUEXQjqjZv3mxdu3a1+vXrW4MGDWzo0KGudHzWrFnWrFmzFI/t2LGjjRkzxpYsWWK9e/e2jRs3WrVq1WzDhg2Zvs6ff/5p9913n9WuXduaN29u06ZNc88FAAAAgHjCdboRNQquO3XqZJUrV7YpU6bYjh07rF+/fm5ZjRo1MnyeAuc+ffrYpEmTbObMmVa2bNlMX6tbt262f/9+F2xv2bLF+vbtS08CAJCOhITcf63cfE3kHvo3uOhbfxF0I2oWLlzoAmBNiFa6dGl3X//+/a1z584uk52RIkWKWKlSpaxgwYKWlJSU6eusWbPGPv/8c1uwYIFVqlTJqlev7rLeAwYMoDcBAEilXLlSub5NEhNz/zWRe+jf4KJv/UHQjahZvXq1ValSJRxwS506dezQoUPuFi2rVq2yMmXKuIDbc/7550dt/QAABMm2bcm5mi3TQfv27cnGdC3BQ/8GF33r74lNgm5ETdGiRdPcd/jwYfdz9+7daZblNBAvVKgQE68BAJBFsQh+9ZoE3cFF/wYXfesPJlJD1FStWtXWrl1rO3fuDN+3bNkyFyQrA75nz54Us5VHTpiWkI3BX6effrrt2rXL1q9fH75v+fLlUXkPAAAAABBNBN2ImsaNG7uS7x49ergS8MWLF9uQIUOsdevWVrNmTReMa4I1BcvDhg1zgbOnePHi7m8F7ZllwBXcN2nSxE2+tnLlSvvss89s9OjR9CQAAACAuEPQjajRRGjjxo1zv3fo0MHNMK7LeQ0ePNhlunv27Gnjx4+3du3auUx3y5Ytw89t2LChm/W8TZs2tmLFikxfS0F7iRIl3OsMHDjQ2rdvb4ULF6Y3AQAAAMSVhJCiHyAP2bt3r5u9/OKLLw4H2nPnzrUnnnjCPvzww3Sfs6/b8FxuJQAA8SG5d+dcey2NFtOkQpq8jSPM4KF/g4u+zbmkpMwnUiPTjTw5YZtKy59++mlXqv7tt9+63yMz5wAAAAAQD5i9HHFHpeK6FndGJk6c6ILs4cOH2+TJk61kyZLWtm1be+ihh3K1nQAAAACQGcrLEXc2bdpkBw8ezHB5+fLlrVixYtleL6VuwUMpVLDRv8FF3wYXfRts9G9w0bf+lpeT6UbcqVChQqybAAAAAABRwZhuAAAAAAB8QtANAAAAAIBPCLoBAAAAAPAJY7qRL+g63SVj3Qj4Yp8ZfRtg9G9w0bd56/rbAICcI9MNAAAAAIBPCLoBAAAAAPAJQTcAAAAAAPEQdFerVi3FrWHDhvbII4/Ynj17wo9p1qyZzZo1K0eN0fP0fFmyZIl7jdzQq1evFO/r7LPPtsaNG9vQoUNt9+7dvrym9/5ee+21dNuj27Hq2LGjjRkzxmJNbdB77d27d5ploVDImjRpkqW+Vl+cd955Nn369HSX67N45513RqXNAAAAABCTTLcCqEWLFtmnn35qEyZMsO+++86GDx8eXj5z5ky76qqrjrlhtWvXdq+TW6688kr3erp9/PHHNmrUKHvvvffsP//5j6+vO3LkSNuxY4cFXeHChe2TTz6xI0eOpLh/2bJltm3btiyto2TJkta0aVN7//330yw7dOiQzZ8/31q3bh21NgMAAABArgfdpUuXtqSkJCtfvrydf/75dvfdd9vcuXPDy8uWLWvFihU75oYVKVLEvU5uUZv1et57q1+/vssUK5Dz03HHHWdPPPGEBV2NGjVs7969LsiOtGDBAvc5yioF1YsXL7bk5OQU93/xxRe2f/9+u+yyy6LWZgAAAACI+Zju4sWLp/g7srxcQev48ePt9ttvt3PPPddatmxpCxcuDD92y5Ytdscdd7ig6+qrr7bffvstvCyyvHzDhg3ud2U4FVTVqlXLBfs7d+4MP14Z6jZt2rjX0TqHDBlyzCXaBQsWdBlajwJwZfFV4nzttdfa0qVLw8v0XvWazZs3d9nYrJal9+3b19544w37+uuvMy25z6hsfPLkye4xqg7Qtl6/fn2663r11VfDj9M6Vq1aFV6mgFXB/yWXXOL645577rHff/89y9s/M0WLFnVl5B9++GGaoDt1oKzX1etrO6u9Y8eOtcOHD7tlap9OkKRej078XHrppe4kBgAAAAAEIuhWWfSUKVOsbdu2GT5GJeitWrWyd955x6pXr279+vULlxh37drV/T5jxgw3FvfFF1886utpXSrHfvnll+377793waYoyOzcubMrEZ89e7YLCqdOnZrj96U2/fjjj24dCqJl5cqV1rNnT/c6b731lnvPavO6detSBMgKXBUkqhQ6K7R+BYsDBw50JdLZpUBar9e9e3cXvCvo1HZNTUGqHqftr8fVrVvXbr75Ztu1a5dbPmDAAHdS4fHHH3frVFvuvffeFOXgGW3/rNJ7jQyWf/nlF9u3b5/VrFkzxRjv++67zxITE107hw0bZm+//bZ7ba8C4vLLL09RYn7w4EH74IMPKC0HAOQrCQnxeYvntnGjf/kMsO8m+PCdl5lC2f2CV6CpDLCCI5ULlylTxgWMGVFmsn379u53Baz/+Mc/7I8//rC//vrLvv32W/voo4+sQoUKduaZZ9ry5ctt3rx5Ga7rgQcecJlsUVZbgZ8oaNf9ChJFQefnn3+erfelwE5juL0gTsGmMtb//ve/3X3PP/+8dejQwb2uKGD98ssvbdq0aeGMuh5fp04dyy5NAKYTEzrpoEx1dmgitltuuSU8jr5///6urQpmIz333HMuO60AXx588EE3Lt87gfDmm2/axIkT3eR4MmLECPd+PvvsM6tatepRt39W6bPQp08fd6KicuXKLsutQDwh4tOq0vFNmza5Pi1QoICddtpp7mSHJmHr0qVL+LX1Wfr777+tRIkS4b6++OKLs9UeAADysnLlSlm8SkyM37bh2NG/wUXf+iPbQbdm9FbZr4LuP//802U9b7jhBhe0KjuZWpUqVcK/e9lfZVGV5VTAroDbowz10YJuBWqR61JwLCqT1nMjqUTay+JmhcqYlS2WQoUKufcSOTZ99erVroQ5crZxvb5Kpj2nnHKK5YSepxMGykQr+M6ONWvW2DnnnBP+u1y5ci5ITU3tVxZemerIkvK1a9e6m04yqF896hsF23qeF3RntP2z6oQTTnAZdmW7b731Vhd0P/zww2naqbJ1Pc6jtukkgj5vWkeDBg2sVKlS7qTBFVdc4T4zGroQORQAAICg27Yt5fwm8UDn0XXQvn17soVCsW4Noo3+DS761t8ToNkOujXJmBd8KaBWwKcgSAHpTTfdlObx6QVCCtgjfx7tsVlZ7mXe03uNrFJZdmRQmZrGFCvL365duxT3RwbmGrecUwpCVRqv2dIjxyVHZoE9kWXoOkGQFWq/ssyNGjVKcb+CZ1UeZPScyPLyaAS1ymyrFFyZeQ0LuOCCC1KMZ9d7U3Z73LhxaZ6rQNvrbwXbKofX+hS8P/3008fcNgAA8pJ4DmrVtnhuH44N/Rtc9G2cTqSmEmAFuN5EV1l11llnuUx05JjoFStW5KgNKk3/4YcfUtyX+u9jpWyvJhRTYO7dlPVWtjUaFNBqXLXGKkdO0Kb7I6+Drm2tdnjUDo039ygbrBLxyMd47d+8eXOK9muctGYTr1SpkgveI2cW13rUN16WO1oUJH/zzTduvLbK11OfNNDrqbxcs+B77dR7GT16dIoTEJrFXJcgU2m5SswVvAMAAABAng+6FSgrM6qbypIHDx7sAu7UM2xn5vTTT3dZV2VfFTQqW6lS9ZzQWGsFjM8++6wrt1Yw+dVXX6WbJc4pjZt+99137aWXXnKzrL/wwgvuFlk+f6xUMaDx1Rs3bgzfp0nGVG6tCeuUGdbEYpFl85qFXGPBtf303hW4V6xY0d1SZ9L1OGXT1X6Vmqs6Qf2gzPp1113nZl/XrPHqD41lP+mkk6xx48YWTQrwlclWX2lCtNRUrq9ye72+hg2oHzX5m2bJV4Y7cviASuB1PXVlzaPZ1wAAAAAQs6D7/vvvd4GRbiq1/vXXX90EXAqmsksBk8boXn/99W6ssQLInFCQpkzo66+/7ibZ0gRtyqhGc4yvgrzhw4fbK6+84oK86dOn25NPPhn1DKvGYx9//PHhvxXU6z5dek3bW5lujV/2aGK62267zQYNGuQmrNM4bW2L1NTmhx56yC1TlljXtdY6vZMGeo0LL7zQTZamMfoqlddJBc0WHm06QaMTNekF9Aqs1S6Vtetkij5vmoBNk82lpvHvqo7wJrcDAAAAgHiTEMru4Oc49NNPP7mxwDVq1Ajfd9ddd7nJ1RS0Afu6DWcjAAACJbl3Z4s3KjzTpEKa5C3vH2EiNfo3uOjbnEtKKuX/mO54oHJplU/r8lYqzdblppTJTa98GQAAAACA3JLt2cvj0WWXXWY///yz9e3b17Zv3+4m41LpevXq1d21nY92zW6VZWscdTR999131qlTpwyX6zJpc+bMsSCYPHlyuuXsHpV+a9w/AAAAAORHgSgvP5qtW7fa3r17M1yu63F71w+PlgMHDtjvv/+e4XLN2J3Ta3rHm7/++svNdJ4Rbdv0rt+e2ygvBwAEDeXlyG2UIAcXfetveXngg27Aw/iy4OE/iGCjf4OLvg0u+jbY6N/gom9zLt+M6QYAAAAAIB4RdAMAAAAA4BOCbgAAAAAAfBKI2cuBrEykFt3p8hAv9mnCvlg3Ar6hf+NTPE7gBQBAvCLTDQAAAACATwi6AQAAAADwCUE3AAAAAAA+ydNBd7Vq1VLcGjZsaI888ojt2bMn/JhmzZrZrFmzcrR+PU/PlyVLlrjXyA29evVK896825gxYyyv0TZU27/88ss0yz799FO3TO85MzNmzLBatWql6F/P/v37rU6dOvbuu+9Grd0AAAAAYPl9IjUFobVr17YjR47Y77//bv3797fhw4fboEGD3PKZM2daiRIljvl19BqLFi2y3HLllVda375909wfjfcSC4ULF7YPP/zQLrjgghT3L1iwwBISErK0jhYtWrh+/eSTT+yqq65KE7yLd5IEAAAAAOJBns50S+nSpS0pKcnKly9v559/vt199902d+7c8PKyZctasWLFjvl1ihQp4l4nt6jNer3Ut+OOO87yonr16rmgO1IoFHL3qd+y2tcXXXSRvffee2mWqc8vu+yyqPQ1AAAAAERLng+6UytevHiKvyPLyzt27Gjjx4+322+/3c4991xr2bKlLVy4MPzYLVu22B133OGCwKuvvtp+++238LLI8vINGza4399//30X6KnkWcH+zp07w49XVrxNmzbudbTOIUOGZKmEOqu0rmHDhtmDDz5o5513nl1yySU2e/bs8PIDBw7Y0KFDrUGDBu7WvXv3cPu89j/99NMu8zx48GB3/1tvveXej9b38MMPW7du3Vwlwddff201atSwHTt2hNe/fPly97jdu3dnqb1NmzZ1r7t69erwfcuWLXOBdJUqVVI8dv78+S6TrfVfe+21tnTp0vAybVNltVVO7tm3b5999NFH1rp16xxtSwAAAADwS6CCbgWFU6ZMsbZt22b4mAkTJlirVq3snXfeserVq1u/fv1cabp07drV/a6xw3feeae9+OKLR309rWvkyJH28ssv2/fff2+TJ092969fv946d+7sSsQVCCsonzp1apTfrbl1nnPOOe69qPR6wIABlpyc7JapXQqMJ06caC+99JILjvX+In3zzTf2+uuv280332xfffWV9enTx50g0EkKnbzwxkdrrLQqCRQMR2aWFeiXLJm1KyQff/zxVrdu3RTZbq1PQX6klStXWs+ePd3200kA9aX6Yt26dW75pZde6n5GnixRubnae+GFF+ZgKwIAAACAf/L8mG4FZAULFnSlynv37rUyZcrYwIEDM3y8AsX27du73xXY/eMf/7A//vjD/vrrL/v2229dxrRChQp25plnuqB13rx5Ga7rgQcecJlsLwOrwFsUtOv+e++91/2tYPfzzz/P1vt6++230y2jnjNnjmufKFut9++9hoLrn3/+2c4++2x3IkABtZed1zh3ZbxXrVoVLlHv1KmTnXrqqe53ZbSVXb7++uvd39qG3hh2jbnWMm2Lf/7zn+4+/d6jR49svafmzZu753lt/uCDD2zEiBEpTkg8//zz1qFDB7c9RScENAHbtGnTXHZfwbXWExmw6wSATnAUKpTnP84AkCdkcSqOTJ9/rOtB/KFvg43+DS761l95PkpRCbXKkBV0//nnny7YvOGGG1zQmpiYmObxkaXMXpb20KFD9ssvv7iA3QtoRRnqowXdlStXTrGugwcPut8V2Oq5kVSyvmvXriy/L5XFqyQ8tRNPPDHT96JMu9riBdAeZfHXrl3rsuNyyimnhJepzV5ALQpga9asGf5bpdsvvPCC28Zav36qZDw7FCw//vjjriJBN5WIp95OKj9XEP3aa6+F79N7adKkSYq2KODX/Xq/ynRPmjQpW20BAORcuXKlorL5EhOjsx7EH/o22Ojf4KJv/ZHng26VPXvBr4JQBZTK6Cpwu+mmm9KdRTs1BeyRP4/22Kws9zLv6b1GVikbHRnUZ/X19TqHDx92v7/yyitpZjvXiQhvbHfRokWz3GZlz5UV12zjCtwVQEc+PysqVqxoZ5xxhn388ce2devWNKXlorYrE96uXbsU90dOkNa4cWOXfdc4e5XTa7I8zS4PAMgd27b9/6FMx5JR0YHd9u3Jls3/HhHn6Ntgo3+Di77190R0ng+6UytQoECKwDOrzjrrLJeJ1thhL9hdsWJFjtqg0nRNPhbphx9+sEqVKllu0OsoiFZwrWBZtm/f7i5B1rt3b7csNQXDaqNH20/vX+PeIzPMKr/XBHPpZeGzQsG6gm5d3k2TtaVWtWpVN+Fa5AkHlcbr/uuuuy58skGT4Kk8XcMCmEANAHJXtAJlrYegO5jo22Cjf4OLvvVHnp9ITYGyxmTrpgysZuJWwJjd6zWffvrp1qhRIzeZmCbzUkZXpeo5oTHJmpn72WeftTVr1rgJ1zRRWVavR+3NyO29r8hbVkrUVWquAFXjspUNVum8yrF1QkHZ5vSoKkDjxTUe/ddff7VHH33UNm7cmKLNCm41zlvtULY5p0G3JkFTiXrqa3bLLbfc4iZw0/h0Bfcqadct9QznGvOt4F3rIugGAAAAEK/yfKb7/vvvD/+uSbY0Dlkzduckqzxq1Cg3m7nGQmtsty4x5l1uLDs0Vnr06NFu/LJ+KkBVsJlZuXoklcdHXm/coxMDCkIzo0nH9Pqa7E1jnxXg6iRAelluUXm2Zj/XZcQ0XvuKK65w90W2WdlnZcR1+bDsvJdI6h/NZK73kV5bNPZdmW1N7KafKml/8skn0wTouu63xqifdNJJrrIAAAAAAOJRQii7g42RqZ9++slN8KXg1HPXXXe5ScMiTxLEk++++85lyE877bTwfbq0mq5p7s32riBXl+xSMN+wYUPLS/Z1Gx7rJgBAYCT37nxMz1cRlcbAaWw4RyHBQt8GG/0bXPRtziUllQp+eXk8Uln0rbfeap999pkr0VbJ9hdffGGXX365xStdLu3uu+921+5W6bdK4jXu+qKLLnLLVcqtknNNaFa/fv1YNxcAAAAA8oQ8X14ejzQrt66XrYnLNIGZJgFT6bomJevSpctRr9k9aNAga9u2reW2f/3rX24CM2XiNSO4JmBTmX5SUlL4+tkan/7UU0+5yeo8yoLr/oxoHSoFBwAAAID8iPLyXKZLZe3duzfD5bqkl3fN7bxg06ZN4euTZ3RJt8jLfcUK5eUAED2UlyMjlKgGG/0bXPStv+XlZLpz2YknnmhBognn8oJiI3swdjCA+A8i2OhfAAAQBIzpBgAAAADAJwTdAAAAAAD4hKAbAAAAAACfEHQDAAAAAOATJlJDvqDZy/POnPDIjn1m9G2AxWv/Huvs3QAAIP8g0w0AAAAAgE8IugEAAAAA8AlBNwAAAAAAPiHoRlw4cOCATZ8+PdbNAAAAAICoIuhGXJgzZ45NmDAh1s0AAAAAgKgi6EZcCIVCsW4CAAAAAEQdQTeiavPmzda1a1erX7++NWjQwIYOHepKx2fNmmXNmjVL8diOHTvamDFjbMmSJda7d2/buHGjVatWzTZs2JDp6+hxb775prVu3dpq1qxpN954o61fv57eBAAAABBXuE43okbBdadOnaxy5co2ZcoU27Fjh/Xr188tq1GjRobPq127tvXp08cmTZpkM2fOtLJly2bp9RSwDxkyxBITE12g/9RTT9mTTz4ZtfcDABlJSGDbRGP7sR2Dh74NNvo3uOhbfxF0I2oWLlxoW7ZscROilS5d2t3Xv39/69y5s8tkZ6RIkSJWqlQpK1iwoCUlJWX59W699VZr1KiR+/2GG26wqVOnRuFdAEDmypUrxWaKgsREtmNQ0bfBRv8GF33rD4JuRM3q1autSpUq4YBb6tSpY4cOHXK3aFNG3VOyZEk7ePBg1F8DANKzbVsyG+YYMyo6sNu+PdmY0iNY6Ntgo3+Di77190Q8QTeipmjRomnuO3z4sPu5e/fuNMuONRAvXLjwMT0fAHKKQDF625FtGUz0bbDRv8FF3/qDidQQNVWrVrW1a9fazp07w/ctW7bMChUq5DLge/bsSTFbeeSEaQkM7AMAAAAQQATdiJrGjRtbpUqVrEePHrZq1SpbvHixm+jMm2FcwbgmWNMs48OGDbNdu3aFn1u8eHH3t4J2P0rRAQAAACAWCLoRNZoIbdy4ce73Dh06WLdu3ax58+Y2ePBgl+nu2bOnjR8/3tq1a+cy3S1btgw/t2HDhm6Mdps2bWzFihX0CgAAAIBASAgp+gECbl+34bFuAoAASe7dOdZNyNM0okgTz2hCOo5CgoW+DTb6N7jo25xLSsp8IjUy3QAAAAAA+ITZyxF32rdvb2vWrMlw+cSJE61evXq52iYAAAAAyAmCbsSdsWPHHvWa2+XLl8/2OouN7EEZYwBRChVs9C8AAAgCgm7EnQoVKsS6CQAAAAAQFYzpBgAAAADAJwTdAAAAAAD4hKAbAAAAAACfMKYb+eY63SVj3Qj4Yp8ZfRtgfvQv19gGAAC5iUw3AAAAAAA+IegGAAAAAMAnBN0AAAAAAPgk3wXd1apVc7dNmzalWTZt2jS3bMyYMRYrGzZsCLcxvVte1KxZM9f2L7/8Ms2yTz/91C3r1atXpuuZMWOG1apVy/bs2ZNm2f79+61OnTr27rvvRq3dAAAAAHCs8l3QLYULF7YPP/wwzf0LFiywhIQEiwcKMBctWpTmlp+3eYsWLSwUCtknn3ySbvDuBfgAAAAAEC/yZdBdr169NAHg7t277dtvv7UaNWpYPChbtqwlJSWluQVpmyuA1n3nn39+ltZRunRpu+iii+y9995Ls2zu3Ll22WWXWbFixaLWZgAAAAA4Vvky6G7evLktXbrUBdqejz/+2AWGxx13XPi+AwcO2LBhw1ygd84557gs6muvvRZe/sUXX9g//vEPV/Ksdb766qvhZSpzbtmypVt21VVXuYxuNLPgNWvWtHXr1rm/V69e7V7Hew3df/vtt1vt2rWtadOm9tJLL4Wf+9NPP1nHjh3t3HPPde2bOnVqeNlff/1l999/v9sOF1xwgXXv3j28jVSOf9ttt7l1NmrUyIYMGWIHDx7McpvVDpXOq62eZcuWuUC6SpUqKR47f/58t83OO+88u/baa11fedq0aeOy2ion9+zbt88++ugja926dTa3JAAAAAD4K18G3WeddZaVL18+XJLsBXrKlEZ69tlnXTCuMd7z5s2zdu3auWBz27ZtdvjwYXvwwQftiiuucFnWrl272qBBg+yXX36x7du3W48ePezuu+92z7vmmmusW7dutnPnzqi0X4Gogl+dEFC2uH///q70Wu1XMKrgWCcPpk+f7paNGjXKBaUKTu+8806rW7euvfXWW9azZ08bN26czZ4926139OjR9scff7ix7QrUV65c6ZaL3neJEiXcY59++mmXbdb6s+r44493rxuZ7U5vm+s11a7OnTu7NrZt29a12TvBcOmll7qfCxcuDD9H5ebFixe3Cy+88Bi3LID8QCNauMV+G9AXse8D+jb22yov3th3Y98H9K3F3T6RmUKWTykzrQBQGVVltD/77DMXoL799tvhx1SvXt0aNmwYLn++5557XMC5du1aK1SokAuiy5UrZxUrVnS3E0880ZWAb9y40WWBTzrpJDvllFNcEKzJwooWLZrl9ilrm3qss7K8gwcPdvfrp7LsykavWbMmPPmbxn3v2LHDHn30UStZsqSdeeaZ9sgjj1iBAgXce0tMTHQnC0QZZrVVAbZOKOh3Bet6Lwpi//vf/4ZfW8uU7a9QoYJVrlzZnZBQIJ3dba6TEAqi5YMPPrARI0akyLY///zz1qFDB/de5eabb3YTsOlEgCZbU7u0nsiAXSc9rrzyStcnAJCZcuVKsZHiRGIifRFU9G2w0b/BRd/6I99GKQrcHnjgATt06JArE1f2WwFpJAV1CsYfe+wx+/XXX+3HH3909yvLXaZMGbvhhhtcQKtssDKwymirXFrBqMqpb731Vqtatap7reuuu84FjFmloFbZ+EgKoj1a71133eWC7ccff9yNARcF4FoW+Vi1S/Q4ZZKVJffovRQsWDAc4N57772ufFw3lZ97we8dd9xhffr0ccHuxRdf7E5WZHf8u7aD2qCTAropK6+y+EgqP1cQHVnGrxMYTZo0SXFCQpUEul/9p0z3pEmTstUWAPnXtm3JsW5Cvqdzyjqw27492UKhfL85AoW+DTb6N7joW39P5ufboFulzvL111+7sdCXX355mseoLFvjp9u3b+8ywQMGDEgxO/bAgQPtX//6l3u+bgoUFYBfcskl9swzz9h3333nsrkKVF955RV3O/vss7PUPmWUlXE+GgXQCpiXLFni2idHy/YqQFUwrYx+erRMAazarLJ6PU6Zc2WjVeat5XqfWqYTFspYP/TQQ5ZVej9nnHGGe/7WrVvTlJZ7JwG0Xu/9eCInSGvcuLHL9ut9JycnuxMOkScSAOBoCPLiqy/oj2Cib4ON/g0u+tYf+XJMtxecKjhWibnGO6cXAGpitH79+rkSbmV29+7d6+7XOGqNfdYYbpVaa/zx66+/7krRtT5la5XR1WRlCkrnzJljJ598copxyMdKwa8C4gkTJriycWXrvZJxjX/22ipqy9ChQ10GXJlwBb9qt26azGzKlCnucS+88IL98MMPdvXVV7vSco0Zf//998MnIDRWXdl9nVBQibq3LLvZbgXdCuzT2+ZqoyZc89qnm05mRI6/1+XHlIXXOrQdmEANAAAAQLzKt0G3FwAqk62y8kqVKqVZrhJyBeTr16+3r776ypU0i8aAq4xcGWyNnf7tt9/cuGNlnlVyrfJyjUFW1lvPVZCpMdHZKcdW+bUC+9Q3lVRrRnFNbKZgX6XeN910k8vCq1xbZdgaZ64stYJ/BaY6eaD7la3WZGreMmW1//Of/4TL6jdv3uzGiisQ17h1TZbmtVnl9Vqm9/jzzz+75+bk8mra5jr5oO2iGdJTu+WWW9zM7xpnru2qEwG6pZ7hXGXv2q5aF0E3AAAAgHiVb8vLRYGoSq7Ty7iKAmqVkLdq1cqNr9a4bJVzr1ixwgW7Cqr1GAWzmoBMs4rrMZq0TGOtVZatTLSCWs1eHjkuOTNaT3o06ZjGPKvcWmPG5b777rN33nnHTfKm11G7FCArY60AXCcLNMZcJk6c6Nqs8m2dVFB5vGZZF83ArnJtBfN///23C4qfeOIJt0zbQZl9XW5M20zr69u3b7a3uS51ppMSKlX3xpJH0qR1w4cPd9tPP0899VR78skn0wTouqzZkSNH3GR1miwOAAAAAOJRQki10kDA7es2PNZNABAnknt3jnUT8j1N2KOJZzSpHUchwULfBhv9G1z0bc4lJWU+kVq+Li8HAAAAAMBP+bq8PLdpNvNOnToddcZyTbqWl2hmd03OlhGVs6sUHAAAAADyI4LuXFS9enWbPXt2xp1xlMt9xauxY8e6yd0ykvpa4wAAAACQn+S9KC8PK1KkiLsEVpAoO58XFBvZg7GDAcT4o2CjfwEAQBAwphsAAAAAAJ8QdAMAAAAA4BOCbgAAAAAAfMKYbuSb63SXjHUj4It9ZvRtwPvX+nBdbQAAkHeR6QYAAAAAwCcE3QAAAAAA+ISgGwAAAAAAnxB0B8TBgwdtzJgx1rx5c6tZs6Y1bdrUhg0bZrt3787S87ds2WIPPPCA1a9f3y666CL33P3790elbc2aNbNq1arZl19+mWbZp59+6pb16tUr0/XMmDHDatWqZXv27EmzTG2tU6eOvfvuu1FpMwAAAABEA0F3QIwYMcLef/99Gzp0qM2bN88FzZ999pl179490+eGQiEXcO/du9emTp1qo0aNso8++sieeuqpqLWvcOHC9uGHH6a5f8GCBZaQkJCldbRo0cK19ZNPPkk3ePcCfAAAAACIFwTdAfHGG29Y165drVGjRlaxYkX3c+DAgS543rp161Gf++uvv9qyZctcoH7mmWdavXr1XBD+zjvvRK19WmfqoFsBtO47//zzs7SO0qVLuyz8e++9l2bZ3Llz7bLLLrNixYpFrc0AAAAAcKwIugNC2eLFixfbkSNHwvfVrl3b5syZYyeccMJRn5uUlGTPPfeclStXLsX9Xmn6rFmz7IYbbnDZdK1Tpesq9c4OPWfDhg22evXq8H0K9BVIV6lSJcVj58+fb1dddZWdd955du2119rSpUvDy9q0aeOy2pGl7/v27XMnF1q3bp2tNgEAAACA3wi6A+Lmm2+2KVOmuPLqAQMGuGywgtEzzjjDlXYfzfHHH+8yyB4F7i+//LI1bNgwfN/3339vK1assNdee83uu+8+GzRokC1atCjL7dNr1K1bN0W2W8G1stORVq5caT179rTOnTvbW2+9ZW3btrU777zT1q1b55Zfeuml7ufChQvDz1G5efHixe3CCy/McnsAAAAAIDcQdAdEly5d7IknnrCTTjrJpk+f7srDFUi//vrr2V6X1vPjjz/aQw89lCKTPnz4cDvrrLNc9rlVq1budbJDk7xFBt0ffPBBmqD7+eeftw4dOriMduXKld3JhIsvvtimTZvmliu41noUsEeWll955ZVWqFChbL9XAPFP0z5wC942oG9j3wf0bey3VV68se/Gvg/oW4u7fSIzRCkBoqywbn/++afLQitb3bdvXzc7uGY0z2rA/eKLL7rJ1BRgexQAJyYmhv/W+l599dVstU/B8uOPP247duxwN5WIazbySCo/VxCtjHrkzOxNmjQJ/60y8h49erj7Dx065DLdkyZNylZbAOQdiYmlYt0E+IS+DS76Ntjo3+Cib/1B0B0AKsmePXt2+LJbGsOtTHHLli3djN8a652VoHvIkCEuo6zAW8+NlDqLfPjwYStQIHuFEprgTeXuH3/8sZvcLXWW21uvysnbtWuX4v7ICdIaN27sMu9Lliyx5ORkK1u2rBtrDiCYtm9PtlAo1q1ANCkzoAM7+jZ46Ntgo3+Di77NuXLlMk8OEHQHgALVyZMnuyx3jRo1wvcXKVLEBasKSjMzduxYl7keOXKkXXHFFWmWa0y1ro993HHHub+XL1+eIhOenWy3gu7ff//dHn744TTLq1at6iZcU2bdo7J23X/ddde5vzVGXScFVJ7+119/MYEaEHAKuAm6g4m+DS76Ntjo3+Cib/3BmO4AOOecc9zs4Pfee6+9/fbbLmjVzOCaUO3AgQMu2300KukeN26cyzBrsrM//vgjfPP8/fffbn16rMZy61rgN954Y46Cbk2Ctn79ervgggvSLL/lllvs3XfftZdeesl+++03e+GFF9wt9QznyuQreNe6mLUcAAAAQLwi0x0QTz31lE2YMMFlrDdt2mQlSpRw46A1rrtkyZJHfa4yxsqWjx8/3t0irVq1yv08+eST3aXFNImafqoEXQF6dqnMXTOZ6zriBQsWTLNc1+xWZnvMmDHu56mnnmpPPvlkmgBd1/3WLOuaOE7XFgcAAACAeJQQClG0h6PTdboVzEfOPJ7X7Os2PNZNAJBDu/t0prw8gGMHNQZu2zbG6wcNfRts9G9w0bc5l5SU+ZhuyssBAAAAAPAJ5eX5QIMGDdzY7ozMmTPHKlSokKN1t2/f3tasWZPh8okTJ7pScAAAAADIjwi684GZM2e68c8ZOfHEEzMNrHVLj8rOdb3sjJQvXz4bLQUAAACAYCHozgcqVark27pzmiHPbcVG9mDsYAAx/ih/9O/ubcmxbgoAAECOMaYbAAAAAACfEHQDAAAAAOATgm4AAAAAAHxC0A0AAAAAgE+YSA35wr5uw61krBsBX+wzo28DJrl351g3AQAAIGrIdAMAAAAA4BOCbgAAAAAAfELQDQAAAACATwi6kadUq1bNHn744TT3z5o1y5o1axaTNgEAAABARgi6kee888479sUXX8S6GQAAAACQKYJu5DmnnHKKDR482A4cOBDrpgAAAADAURF0I8958MEHbcuWLfb888/HuikAAAAAcFRcpxt5Tvny5e2BBx6wUaNGWevWra1SpUqxbhKAKEpISP8ngoO+DS76Ntjo3+Cib/1F0I08qWPHjm7ytP/85z82YcKEWDcHQBSVK1cqxd+JiSn/RnDQt8FF3wYb/Rtc9K0/CLqRJxUsWNAGDhxoN954oy1YsCDWzQEQRdu2JYfPuus//+3bky0UYhMHCX0bXPRtsNG/wUXfRi9ZkB6CbuRZderUsWuuucZlu++4445YNwdAlKQOsPU3QXcw0bfBRd8GG/0bXPStP5hIDXla9+7d7e+//2ZSNQAAAABxiaAbedoJJ5zgAu+NGzfGuikAAAAAkAZBN/K8a6+91mrXrh3rZgAAAABAGozpRp6yatWqNPclJCTYq6++GpP2AAAAAMDRkOkGAAAAAMAnBN0AAAAAAPiE8nLkC8VG9nDX/uWyQ8G7pqSujUjfAgAAIF6R6QYAAAAAwCcE3QAAAAAA+ISgGwAAAAAAnxB0AwAAAADgEyZSQ76wr9twKxnrRsAX+8zo2ziU3LtzrJsAAAAQF8h0AwAAAADgE4JuAAAAAAB8QtANAAAAAIBPCLoD4uDBgzZmzBhr3ry51axZ05o2bWrDhg2z3bt3Z+n5W7ZssQceeMDq169vF110kXvu/v37o9K2jh07WrVq1Wz27Nlplq1evdot02My88UXX7jHrl27Nt3lLVu2tIkTJ0alzQAAAAAQDQTdATFixAh7//33bejQoTZv3jwXNH/22WfWvXv3TJ8bCoVcwL13716bOnWqjRo1yj766CN76qmnota+woUL24cffpjm/gULFlhCQkKW1qETAklJSe59pvbjjz/aunXrrHXr1lFpLwAAAABEA0F3QLzxxhvWtWtXa9SokVWsWNH9HDhwoAuet27detTn/vrrr7Zs2TIXqJ955plWr149F4S/8847UWuf1rlo0SI7cOBAmqD7/PPPz9I6ChYsaFdccUW6QffcuXOtbt26dvLJJ0etzQAAAABwrAi6A0LZ4sWLF9uRI0fC99WuXdvmzJljJ5xwwlGfq+zxc889Z+XKlUtxv1eaPmvWLFf+PXr0aGvQoIELoBWgK0OeVWpL0aJFXRsjS9qVndY6I3311VfWvn17O/fcc61Nmzb23nvvhZfp7+XLl9vvv/+e4jnK7pPlBgAAABBvuE53QNx8880uKFbm+JJLLrELL7zQmjRpYmeccUamzz3++OPdOG6PAveXX37ZGjZsGL7v22+/dUH5tGnT7Pvvv7devXrZxRdfbI0bN85S+woUKODGmavEXM8TtVWvW6jQ/30M//jjD7v77rvtoYcecsuUgddrJSYmumD/vPPOc5l8Zbs7derknuMF4cqCA4gPWRw1kqV1RGNdiC/0bXDRt8FG/wYXfesvgu6A6NKli1WqVMleeeUVmz59ur366qt23HHHWd++fe2aa67J1rqeeOIJN0Z65syZ4fsOHz5sQ4YMsZIlS9ppp51mL7zwggu+sxp0iyZ50zpU9i4ffPCBdejQwX7++efwYzSmXCcMbrrpJvd35cqVbcWKFfbiiy+6oFtatWpl8+fPDwfdKi3XCYbMMvoAck+5cqWitq7ExOitC/GFvg0u+jbY6N/gom/9QdAdIG3btnW3P//8042fVrZaQbdm/NaM5lkNuBXgajK1s846K3y/Ms0KuD36/dChQ9lqnwL0nTt32g8//OBOECiLrRnXI4NujS/XOHSVo0fOzF61atXw3yojf/bZZ2379u2uXSotV2YcQPzYti05Kmfd9Z//9u3Jlo3RLMgD6Nvgom+Djf4NLvrW30QDQXcArFy50l2OS2XYooyvxj7rElotWrRw46izEnQrC63ycQXeem6kIkWKpHl8dsZ0S/HixV0WWyXmVapUcbORKxsfSYG82n7PPfekuD+yBF2Tvemm8vSzzz7bduzY4bLoAOJHNINkrYugO5jo2+Cib4ON/g0u+tYfTKQWACr9njx5sisJTx0oFytWzMqWLZvpOsaOHetK0keOHOnKt/2i4FiZbJWWX3755WmWK6OtydVUVu7d9Ni33347xeOU7db9CrybNWvmAnoAAAAAiDcE3QFwzjnnuEnK7r33XhecbtiwwZVuDxgwwF2iS9nuo1m9erWNGzfO7rzzTnfZLU1m5t2i7dJLL7VVq1a58nf9ntqNN97oJkZTefvatWvd+9GJgAoVKqR4nE4MLF261E2opsw4AAAAAMQjyssD4qmnnrIJEya4jPWmTZusRIkSbnIxjeuOHIudHmWMlS0fP368u0VSgBxNGoOtS4GpXDy9DPwpp5zi3seIESPs+eeft/Lly7uyeY1VT/246tWr25o1a7I1mRsAAAAA5KaEUHYH5gJ50L5uw2PdBCBfSe7dOSqTumhyEk3Kxv9UwULfBhd9G2z0b3DRtzmXlJT5RGqUlwMAAAAA4BPKy/OBBg0auLHdGZkzZ06aMdPZuT74559/nuHyQYMGpSkNBwAAAID8gqA7H5g5c6YdOXIkw+Unnnhijtetydr27t171DHcAAAAAJBfEXTnA5UqVfJt3ccSsOemYiN7MC40gBh/BAAAgHjHmG4AAAAAAHxC0A0AAAAAgE8IugEAAAAA8AljupFvrtNdMtaNgC/2mdG3eeS62wAAAPkRmW4AAAAAAHxC0A0AAAAAgE8IugEAAAAA8AlBd0AcPHjQxowZY82bN7eaNWta06ZNbdiwYbZ79+5srefAgQPWunVrW7JkSdTa1qxZM6tWrZp9+eWXaZZ9+umnblmvXr0yXc+MGTOsVq1atmfPnjTL9u/fb3Xq1LF33303au0GAAAAgGNF0B0QI0aMsPfff9+GDh1q8+bNcwH3Z599Zt27d8/yOhS4duvWzX7++eeot69w4cL24Ycfprl/wYIFlpCQkKV1tGjRwkKhkH3yySfpBu9egA8AAAAA8YKgOyDeeOMN69q1qzVq1MgqVqzofg4cONA++ugj27p1a6bP/+WXX6xDhw7222+/+dK+evXqpQm6FUDrvvPPPz9L6yhdurRddNFF9t5776VZNnfuXLvsssusWLFiUWszAAAAABwrgu6AULZ48eLFduTIkfB9tWvXtjlz5tgJJ5yQ6fOXLl1qDRo0sNdeey3NslmzZtkNN9zgsulap0rXVeqdHXrOhg0bbPXq1eH7li1b5gLpKlWqpHjs/Pnz7aqrrrLzzjvPrr32Wtc2T5s2bVxWW1l5z759+9zJBZXFAwAAAEA84TrdAXHzzTfb6NGjXbn2JZdcYhdeeKE1adLEzjjjjCw9/8Ybbzzq8u+//95KlCjhgvLvvvvOZdFPPvlk9xpZcfzxx1vdunVdZvv0008PB9fKTm/ZsiX8uJUrV1rPnj1t0KBBdu6557pS8jvvvNPeeustq1y5sl166aXucQsXLnTPFT2mePHi7j0DAAAAQDwh0x0QXbp0sSeeeMJOOukkmz59uj3wwAOuFPv111+PWiZ9+PDhdtZZZ7nsc6tWrdzrZIcmeYssMf/ggw/CgbPn+eefd2XuymgryNbJhIsvvtimTZvmliu41noUsEeWll955ZVWqBDnkAC/aOqFWNxi+drc6Fs+A+y3fAb4Xs5PnwH+z7Ucb7fMEKUESNu2bd3tzz//tEWLFtnLL79sffv2dbODa0bzY6EAODExMfy31vfqq69max0Klh9//HHbsWOHu6lEXLORR1L5uYLoyDJ3zcwemVFXGXmPHj3c/YcOHXKZ7kmTJh3T+wNwdOXKlYrZJkpMjN1rw1/0bXDRt8FG/wYXfesPgu4AUEn27Nmzw5fd0hhuZYpbtmzpZvzWWO9jDbpTZ5EPHz5sBQpkr1BCE7yp3P3jjz92k7ulznJ761U5ebt27VLcHzlBWuPGjV3mXZc1S05OtrJly7qx5gD8s21bcq5vXp091n/+27cnWyiU6y8PH9G3wUXfBhv9G1z0rb+JCYLuAFCgOnnyZJflrlGjRvj+IkWKuGBVQemxWrdunbs+9nHHHef+Xr58uSs1zy5luxV0//777/bwww+nWV61alU34Zoy6x6Vtev+6667Lnz5MZ1QUHn6X3/9xQRqQC6IZdCr1yboDib6Nrjo22Cjf4OLvvUHY7oD4JxzznGzg99777329ttvu6BVM4MPGDDADhw44LLdx+rvv/9261P5t8Zy61rgmU2+llHQrUnQ1q9fbxdccEGa5bfccou9++679tJLL7nLl73wwgvulnqGc2XyFbxrXcxaDgAAACBekekOiKeeesomTJhgY8eOtU2bNrmZxjUOWuO6S5Yseczr10zlSUlJbhI1/dSkbZqNPLtU5q6ZzHUd8YIFC6ZZrmt2K7M9ZswY9/PUU0+1J598Mk2Arut+6/JomjjuzDPPPKb3BgAAAAB+SQiFKNrD0ek63QrmI2cez2v2dRse6yYAeVpy784xGV+mcVIaT87/VMFC3wYXfRts9G9w0bc5l5SU+ZhuyssBAAAAAPAJ5eX5QIMGDdzY7ozMmTPHKlSokKN1t2/f3tasWZPh8okTJ7pScAAAAADIjwi684GZM2e68c8ZOfHEEzMNrHVLj8rOdb3sjJQvXz4bLQUAAACAYCHozgcqVark27pzmiHPbcVG9mBcaAAx/ggAAADxjjHdAAAAAAD4hKAbAAAAAACfEHQDAAAAAOATgm4AAAAAAHzCRGrIF/Z1G24lY90I+GKfGX3rs+Tenf1+CQAAgMAi0w0AAAAAgE8IugEAAAAA8AlBNwAAAAAAPiHoRtw5cOCATZ8+PcuPX7ZsmbVo0cJq1aplM2bM8LVtAAAAAJAdBN2IO3PmzLEJEyZk+fHPPvusnXrqqTZ37ly78sorfW0bAAAAAGQHs5cj7oRCoWw9Pjk52S644AKrWLGib20CAAAAgJwg0w3fbN682bp27Wr169e3Bg0a2NChQ13p+KxZs6xZs2YpHtuxY0cbM2aMLVmyxHr37m0bN260atWq2YYNG476Gnre0qVL7emnn3aPBwAAAIB4QqYbvlBw3alTJ6tcubJNmTLFduzYYf369XPLatSokeHzateubX369LFJkybZzJkzrWzZskd9HQXq99xzj3vebbfdFvX3AcAsISG2rxur14d/6Nvgom+Djf4NLvrWXwTd8MXChQtty5YtbkK00qVLu/v69+9vnTt3dpnsjBQpUsRKlSplBQsWtKSkpExfp0yZMla4cGErUaJElh4PIPvKlSsV082WmBjb14d/6Nvgom+Djf4NLvrWHwTd8MXq1autSpUq4YBb6tSpY4cOHXI3AHnHtm3JMTvrrv/8t29PtmxO9YA4R98GF30bbPRvcNG3/iYnCLrhi6JFi6a57/Dhw+7n7t270ywjEAfiV6wDXr1+rNsAf9C3wUXfBhv9G1z0rT+YSA2+qFq1qq1du9Z27tyZ4nrahQoVchnwPXv2pJitPHLCtAQGcAIAAAAICIJu+KJx48ZWqVIl69Gjh61atcoWL15sQ4YMsdatW1vNmjVdMK4J1tavX2/Dhg2zXbt2hZ9bvHhx97eCdjLgAAAAAPIygm74QhOhjRs3zv3eoUMH69atmzVv3twGDx7sMt09e/a08ePHW7t27Vymu2XLluHnNmzY0M163qZNG1uxYgU9BAAAACDPSggp4gECbl+34bFuApBnJffuHJPX1UgTTU6iidz4nypY6Nvgom+Djf4NLvo255KSMp9IjUw3AAAAAAA+YfZyxLX27dvbmjVrMlw+ceJEq1evXq62CQAAAACyiqAbcW3s2LF28ODBDJeXL18+S+spNrIHJaoBRCkUAAAA4h1BN+JahQoVYt0EAAAAAMgxxnQDAAAAAOATgm4AAAAAAHxC0A0AAAAAgE8Y0418c53ukrFuBHyxzyzP9m2srn8NAACA3EOmGwAAAAAAnxB0AwAAAADgE4JuAAAAAAB8QtCNuHDgwAGbPn16rJsBAAAAAFFF0I24MGfOHJswYUKsmwEAAAAAUUXQjbgQCoVi3QQAAAAAiDqCbkTV5s2brWvXrla/fn1r0KCBDR061JWOz5o1y5o1a5bisR07drQxY8bYkiVLrHfv3rZx40arVq2abdiwIdPX0eNmzJhhl112mdWuXdsefvhh27NnD70JAAAAIK5wnW5EjYLrTp06WeXKlW3KlCm2Y8cO69evn1tWo0aNDJ+noLlPnz42adIkmzlzppUtWzZLr/ff//7XBfWJiYnu+f3797cnn3wyau8H8FtCAts4K9uH7RQ89G1w0bfBRv8GF33rL4JuRM3ChQtty5YtbkK00qVLu/sUCHfu3NllsjNSpEgRK1WqlBUsWNCSkpKy/Hp33nmnNW3a1P3et29fu+2222zgwIFuXUBeUK4cn9WsSExkOwUVfRtc9G2w0b/BRd/6g6AbUbN69WqrUqVKOOCWOnXq2KFDh9wt2rRuT82aNe3w4cO2Zs0aO/fcc6P+WoAftm1LZsNmctZd//lv355sTPsQLPRtcNG3wUb/Bhd9628ShaAbUVO0aNE09ykQlt27d6dZdqyBeOHChcO/HzlyxP0sUIBpCpB3EEhmfTuxrYKJvg0u+jbY6N/gom/9QYSCqKlataqtXbvWdu7cGb5v2bJlVqhQIZcBj5zoTLOVR06YlpCDQZsrVqwI/758+XIXhKsNAAAAABAvCLoRNY0bN7ZKlSpZjx49bNWqVbZ48WIbMmSItW7d2pV/KxjXBGvr16+3YcOG2a5du8LPLV68uPtbQXtWM+CjR4+2pUuX2v/+9z83odrVV19txx13HD0KAAAAIG4QdCNqNBHauHHj3O8dOnSwbt26WfPmzW3w4MEu092zZ08bP368tWvXzmW6W7ZsGX5uw4YN3aznbdq0SZHBPhqtp1evXnb77bfbBRdcEJ4pHQAAAADiRUJI0Q+Qx+g63S+99JK7FnhW7Os23Pc2AdmV3LszG+0oNOpEk5Nowjn+pwoW+ja46Ntgo3+Di77NuaSkzCdSI9MNAAAAAIBPmL0ccad9+/bu0l8ZmThxYq62BwAAAAByiqAbcWfs2LF28ODBDJeXL1/eTdQGAAAAAPGOoBtxp0KFClFfZ7GRPRgXGkCMPwIAAEC8Y0w3AAAAAAA+IegGAAAAAMAnBN0AAAAAAPiEMd3IF3Sd7pKxbgQyxXWrAQAAEDRkugEAAAAA8AlBNwAAAAAAPiHoBgAAAADAJwTdyLYNGzZYtWrV3M94sWLFCvvmm29i3QwAAAAASIGgG9l28skn26JFi9zPeNGlSxdbu3ZtrJsBAAAAACkwezmyrWDBgpaUlMSWAwAAAIBMkOnGMZWXv/vuu9ayZUurVauWXXXVVbZgwYIsrWPWrFnWsWNHGz9+vF1wwQXWuHFjmz17ts2bN88uvfRSq1evnj3xxBPhxx84cMCGDh1qDRo0cLfu3bvbzp073TKtZ+PGjda7d2/r1asXPQoAAAAgbhB0I8d27NhhPXr0sLvvvtsFy9dcc41169YtHAxn5ttvv7X169fbzJkzrVWrVjZw4EB76aWXXCCu4Pm5556zH3/80T125MiRtnz5cps4caJ7zO7du61r165u2ZgxY+ykk06yPn36WN++felRAAAAAHGD8nLk/MNTqJAdPHjQBbynnHKK3XbbbS4DXrRo0Sw9PxQK2SOPPGIlSpSwf/7zn/biiy/a/fffb9WrV3c3Bdq//vqrVa1a1V5++WV7/fXX3fpl+PDhLuO9atUqd59K3kuVKuVuyLsSEnL2+Ow+D3kD/Rtc9G1w0bfBRv8GF33rL4Ju5JgC3KZNm9qtt97qAuPmzZvbddddZ8WLF8/S8xMTE13ALV6gXrFixfDyYsWKubJyZcMV3F9//fUpnn/kyBE3eZoXiCPvK1cuZydNEhM52RJk9G9w0bfBRd8GG/0bXPStPwi6kWMJCQn2zDPP2HfffWcffPCBzZ8/31555RV3O/vsszP/8BUqlO46Uzt8+LD7qfV6QXpk4I7g2LYtOVuP18dF/zls355soZBvzUKM0L/BRd8GF30bbPRvcNG3/iaNCLqRY/v377fHH3/cevbsaeeee649+OCDbmz2woULsxR0Z1WlSpVc+bjGinvr3b59uxu/rcnTSpYsSS8GRE4DZz2PoDu46N/gom+Di74NNvo3uOhbfxB0I8eSk5Nt2rRprsy8TZs29ssvv7hZxGvUqBHVraqgWmXrmmht8ODBLrs9bNgw27RpU7gcXRlwjf9WYF6mTJmovj4AAAAA5BSzlyPHypUr52YOf++991yGWwGxZi9v0qRJ1LeqZjNv1KiRPfDAA9ahQwdXmv7ss8+6DLjccMMNNnXqVDcxGwAAAADEi4SQppAGAm5ft+GxbgKyILl352yPP9I4Go0F55sseOjf4KJvg4u+DTb6N7jo25xLSsp8TDeZbgAAAAAAfMKYbkSdZjPv1KlThssrVKhgc+bMYcsDAAAACDyCbkRd9erVbfbs2dm6VBgAAAAABBHRD6KuSJEiVrly5bjassVG9mDcLwAAAIBcx5huAAAAAAB8QtANAAAAAIBPCLoBAAAAAPAJQTcAAAAAAD5hIjXkC/u6DbeSsW5EPpTcu3OsmwAAAADEFJluAAAAAAB8QtANAAAAAIBPCLoBAAAAAPAJQTfiwoEDB2z69OmxbgYAAAAARBVBN+LCnDlzbMKECbFuBgAAAABEFUE34kIoFIp1EwAAAAAg6gi6EVWbN2+2rl27Wv369a1BgwY2dOhQVzo+a9Ysa9asWYrHduzY0caMGWNLliyx3r1728aNG61atWq2YcOGTF/nl19+sdtvv91q165ttWrVshtvvNFWr15NbwIAAACIK1ynG1Gj4LpTp05WuXJlmzJliu3YscP69evnltWoUSPD5ylw7tOnj02aNMlmzpxpZcuWPerrHDlyxO655x678MILbcCAAZacnGyDBw+2J554ghL1OJOQkDvr9/t1EBv0b3DRt8FF3wYb/Rtc9K2/CLoRNQsXLrQtW7a4CdFKly7t7uvfv7917tzZZbIzUqRIEStVqpQVLFjQkpKSMn2dffv22fXXX++y2yVKlHD3XX311fbcc8/Rm3GmXLlSufI6iYm58zqIDfo3uOjb4KJvg43+DS761h8E3YgalXdXqVIlHHBLnTp17NChQ+4WLQq0b7jhBps9e7YtX77cfv31V/vxxx+tXLlyUXsNRMe2bcm+n5XVfw7btycb0wIED/0bXPRtcNG3wUb/Bhd962+SiaAbUVO0aNE09x0+fNj93L17d5plOQ3E9+zZY9dee62dcMIJbpx469atXeCt8nTEl9wKhPU6BN3BRf8GF30bXPRtsNG/wUXf+oOgG1FTtWpVW7t2re3cudPKlCnj7lu2bJkVKlTIZcAVLEfOVh45YVpCNgblLl261LZu3Wpvv/22W7csWrSIGdABAAAAxB1mL0fUNG7c2CpVqmQ9evSwVatW2eLFi23IkCEuE12zZk0XjGuCtfXr19uwYcNs165d4ecWL17c/a2gPbMMuAL6v//+2xYsWOAC9xkzZtjUqVPdRG4AAAAAEE8IuhE1mght3Lhx7vcOHTpYt27drHnz5m5mcWW6e/bsaePHj7d27dq5rHTLli3Dz23YsKGb9bxNmza2YsWKo76OZjvv0qWLDRo0yNq2besuR6YJ27Zv3+4mcgMAAACAeJEQUvQDBNy+bsNj3YR8Kbl3Z1/Xr1EJmrxCE7bxTRY89G9w0bfBRd8GG/0bXPRtziUlZT6RGpluAAAAAAB8wkRqiDvt27e3NWvWZLh84sSJVq9evVxtEwAAAADkBEE34s7YsWPt4MGDGS4vX758ttdZbGQPSpABAAAA5DqCbsSdChUqxLoJAAAAABAVjOkGAAAAAMAnBN0AAAAAAPiEoBsAAAAAAJ8wphv55jrdJQN2jWoAAAAA8Y9MNwAAAAAAPiHoBgAAAADAJwTdAAAAAAD4hKAbcefAgQM2ffr0LD9+/fr19sknn/jaJgAAAADICYJuxJ05c+bYhAkTsvz4Pn362HfffedrmwAAAAAgJwi6EXdCoVCsmwAAAAAAUUHQDd9s3rzZunbtavXr17cGDRrY0KFDXen4rFmzrFmzZike27FjRxszZowtWbLEevfubRs3brRq1arZhg0bjvoavXr1sqVLl9rYsWPdOgAAAAAgnnCdbvhCwXWnTp2scuXKNmXKFNuxY4f169fPLatRo0aGz6tdu7YrF580aZLNnDnTypYte9TX6du3r61du9Y97+6777Z4kpAQ6xYEn7eN2dbBRP8GF30bXPRtsNG/wUXf+ougG75YuHChbdmyxU2IVrp0aXdf//79rXPnzi6TnZEiRYpYqVKlrGDBgpaUlJTp6+ixhQsXthIlSliZMmUsnpQrVyrWTcg3EhPZ1kFG/wYXfRtc9G2w0b/BRd/6g6Abvli9erVVqVIlHHBLnTp17NChQ+6WH2zblhzrJuSLs7L6z2H79mRjKoDgoX+Di74NLvo22Ojf4KJv/U20EXTDF0WLFk1z3+HDh93P3bt3p1kWxECcIDB3tzXbO7jo3+Cib4OLvg02+je46Ft/MJEafFG1alU31nrnzp3h+5YtW2aFChVyGfA9e/akmK08csK0BAboAgAAAAgIgm74onHjxlapUiXr0aOHrVq1yhYvXmxDhgyx1q1bW82aNV0wrgnW1q9fb8OGDbNdu3aFn1u8eHH3t4L2rGTANZ5bj92+fTu9CQAAACCuEHTDF5oIbdy4ce73Dh06WLdu3ax58+Y2ePBgl+nu2bOnjR8/3tq1a+cy3S1btgw/t2HDhm7W8zZt2tiKFSsyfa3rrrvOTdx2xx130JsAAAAA4kpCSBEPEHD7ug3P9ddM7t05118zv9FIBE1eoUnr+CYLHvo3uOjb4KJvg43+DS76NueSkjKfSI1MNwAAAAAAPmH2csS19u3b25o1azJcPnHiRKtXr16utgkAAAAAsoqgG3Ft7NixdvDgwQyXly9fPlfbAwAAAADZQdCNuFahQoWorKfYyB6M+wUAAACQ6xjTDQAAAACATwi6AQAAAADwCUE3AAAAAAA+YUw38s11uktGcX1cgxsAAABAVpDpBgAAAADAJwTdAAAAAAD4hKAbAAAAAACfEHQjLhw4cMCmT5+e4+fPmjXLmjVrFtU2AQAAAMCxIuhGXJgzZ45NmDAh1s0AAAAAgKgi6EZcCIVCsW4CAAAAAEQdQTeiavPmzda1a1erX7++NWjQwIYOHepKx9Mr/+7YsaONGTPGlixZYr1797aNGzdatWrVbMOGDZm+zpYtW+yOO+6w888/366++mr77bff6EkAAAAAcYfrdCNqFFx36tTJKleubFOmTLEdO3ZYv3793LIaNWpk+LzatWtbnz59bNKkSTZz5kwrW7Zspq+lwL5EiRI2Y8YM+/nnn61v3752wgkn0JsAAAAA4gpBN6Jm4cKFLgOtCdFKly7t7uvfv7917tzZZbIzUqRIEStVqpQVLFjQkpKSMn0dBdnffvutffTRR1ahQgU788wzbfny5TZv3rxc682EhFx7KWShH+iPYKJ/g4u+DS76Ntjo3+Cib/1F0I2oWb16tVWpUiUccEudOnXs0KFD7hYtv/zyi5UpU8YF3J5atWrlatBdrlypXHstZC4xkf4IMvo3uOjb4KJvg43+DS761h8E3YiaokWLprnv8OHD7ufu3bvTLDuWQDz1xGuFCxe23LRtW3Kuvh4yPiur/xy2b0825uILHvo3uOjb4KJvg43+DS761t9kHEE3oqZq1aq2du1a27lzp8tEy7Jly6xQoUIuA75nz54UQXPkhGkJ2agPPuuss2zXrl22bt06N35cVqxYkas9SYAXX9Qf9Elw0b/BRd8GF30bbPRvcNG3/mD2ckRN48aNrVKlStajRw9btWqVLV682IYMGWKtW7e2mjVrumBcE6ytX7/ehg0b5gJnT/Hixd3fCtozy4Cffvrp1qhRIzf52sqVK23BggX28ssv05MAAAAA4g5BN6JGE6GNGzfO/d6hQwfr1q2bNW/e3AYPHuwy3T179rTx48dbu3btXKa7ZcuW4ec2bNjQZa3btGmTpaz1qFGj3Gzl119/vY0cOdJdfgwAAAAA4k1CKPXgWCCA9nUbHtX1JffuHNX1IWc0KkHjaDTGnm+y4KF/g4u+DS76Ntjo3+Cib3MuKSnzMd1kugEAAAAA8AkTqSHutG/f3tasWZPh8okTJ1q9evVytU0AAAAAkBME3Yg7Y8eOtYMHD2a4vHz58rnaHgAAAADIKYJuxJ0KFSpEfZ3FRvZg3C8AAACAXMeYbgAAAAAAfELQDQAAAACATwi6AQAAAADwCUE3AAAAAAA+IegGAAAAAMAnBN0AAAAAAPiEoBsAAAAAAJ8QdAMAAAAA4BOCbsSFAwcO2PTp07P8+GrVqtmSJUt8bRMAAAAAHCuCbsSFOXPm2IQJE2LdDAAAAACIKoJuxIVQKBTrJgAAAABA1BF0I6o2b95sXbt2tfr161uDBg1s6NChrnR81qxZ1qxZsxSP7dixo40ZM8aViffu3ds2btzoysY3bNiQpdf66quvrE2bNlarVi276aab3PMBAAAAIJ4UinUDEBwKrjt16mSVK1e2KVOm2I4dO6xfv35uWY0aNTJ8Xu3ata1Pnz42adIkmzlzppUtWzZLrzdjxgx7/PHHrUyZMta9e3cbMWKEjRo1KsPHJyTk4E0hrnl9St8GE/0bXPRtcNG3wUb/Bhd96y+CbkTNwoULbcuWLW5CtNKlS7v7+vfvb507d3aZ7IwUKVLESpUqZQULFrSkpKQsv57Wq2y6XHvttfbqq68e9fGJiaWyvG7kLfRtsNG/wUXfBhd9G2z0b3DRt/4g6EbUrF692qpUqRIOuKVOnTp26NAhd4u2U089Nfy7gvb9+/cf9fHbtycbQ8eDd1ZW/znQt8FE/wYXfRtc9G2w0b/BRd/mXLlymSf2CLoRNUWLFk1z3+HDh93P3bt3p1l2rIF4gQLZm5JAATdBdzDRt8FG/wYXfRtc9G2w0b/BRd/6g4nUEDVVq1a1tWvX2s6dO8P3LVu2zAoVKuQy4Hv27EkxW3nkhGkJDMoFAAAAEEAE3Yiaxo0bW6VKlaxHjx62atUqW7x4sQ0ZMsRat25tNWvWdMG4Jlhbv369DRs2zHbt2hV+bvHixd3fCtr9KEUHAAAAgFgg6EbUaCK0cePGud87dOhg3bp1s+bNm9vgwYNdprtnz542fvx4a9eunct0t2zZMvzchg0bulnPdQmwFStW0CsAAAAAAiEhpOgHyAe2bWMitaDRqARNXkHfBhP9G1z0bXDRt8FG/wYXfZtzSUmZT6RGphsAAAAAAJ8wezniTvv27W3NmjUZLp84caLVq1cvV9sEAAAAADlB0I24M3bsWDt48GCGy8uXL5+r7QEAAACAnCLoRtypUKFCrJsAAAAAAFHBmG4AAAAAAHxC0A0AAAAAgE8IugEAAAAA8AlBNwAAAAAAPiHoBgAAAADAJwTdAAAAAAD4hKAbAAAAAACfEHQDAAAAAOATgm4AAAAAAHxC0A0AAAAAgE8IugEAAAAAIOgGAAAAACBvIdMNAAAAAIBPCLoBAAAAAPAJQTcAAAAAAD4h6AYAAAAAwCcE3QAAAAAA+ISgGwAAAAAAnxB0AwAAAADgE4JuAAAAAAB8QtANAAAAAIBPEkKhUMivlQMAAAAAkJ+R6QYAAAAAwCcE3QAAAAAA+ISgGwAAAAAAnxB0AwAAAADgE4JuBNr+/futT58+Vq9ePWvSpIlNmjQp1k1CBubPn2/VqlVLcXvggQfcsh9//NGuu+46O++88+yaa66x5cuXp3juO++8Y5dddplb3qVLF9uxY0d4meaKHDFihDVs2NDq169vw4cPtyNHjtAPueTAgQPWunVrW7JkSfi+9evX2y233GLnn3++XXXVVbZo0aIUz/n888/dc9SfN998s3t8pBdeeMEuuugiq127ttu/9+7dG17GPh/bvh06dGia/fjll1+Oyr76559/2v333+/6vVmzZvbmm2/m4rvNP7Zs2eK+e9UH2s+GDRvm9ith3w1u37Lv5m3r1q2z22+/3X0/Nm3a1J577rnwMvbbOKHZy4GgGjx4cKhNmzah5cuXh95///1Q7dq1Q3Pnzo11s5COcePGhe6+++7Q1q1bw7ddu3aF9uzZE2rcuHHoscceC/3yyy+hIUOGhC688EJ3v/zvf/8LnXvuuaE33ngjtGLFitBNN90Uuuuuu8Lrff7550OXXHJJ6Msvvwx98cUXoSZNmoSee+45+iAX7Nu3L9SlS5fQWWedFVq8eLG778iRI26ffPjhh11/TpgwIXTeeeeFNm7c6Jbr5/nnn+/67aeffgp17do11Lp1a/c8mTdvXqhu3bqhDz/80PX9VVddFRo0aFD4NdnnY9e3csstt4SeeeaZFPvx33//HZV9Vd8PnTp1Cq1atSo0ffr0UM2aNd06ET3azzp06BC644473P6nvrj88svd9y/7bnD7Vth3867Dhw+HWrRo4f5fXbNmTejjjz8O1alTJ/TWW2+x38YRgm4EloKyWrVqpTggfPrpp92BHuKP/rN48skn09w/Y8aMULNmzcJBl37qQOH11193f//73/8O9ezZM/z4TZs2hapVqxb67bff3N86iPceK7Nnzw5deumlufCO8reff/451LZtWxdgRwZmn3/+uQuqvZMmokBq9OjR7vennnoqxT6qgE0ny7zn33jjjeHHig4cFcjpcezzse1bueiii0ILFy5M93nHsq+uW7fOvdb69evDy/v06ZNifTh2OhGm7fzHH3+E73v77bfdCRD23eD2rbDv5l1btmxxJ6iTk5PD9+mk6IABA9hv4wjl5QislStX2qFDh1ypjadu3br2v//9j/LiOLR69WqrUqVKmvvVX+q3hIQE97d+1qlTx5YtWxZeruEDnpNPPtkqVKjg7lcp3e+//24XXHBBeLnWtXHjRtu6dWuuvK/8aunSpdagQQN77bXXUtyvfqlRo4aVKFEiRZ9k1J/Fixe3c845xy0/fPiwff/99ymWq0T94MGDbn9nn49t3+7evdvtc+ntx8e6r+oxenzFihVTLP/22299eY/5VVJSkitLLVeuXJq+Zd8Nbt+y7+ZtJ554oj311FNWsmRJN0zn66+/ti+//NINI2C/jR+FYt0AwC9//PGHnXDCCVakSJHwffrPRuOXdu7caWXLlmXjxwn9J7FmzRo3tveZZ55xwdUVV1zhxp6pH88444wUj09MTLSff/7Z/a4Dcv2Hk3r55s2b3XMlcrl3wKHlqZ+H6LnxxhvTvV99klF/Zbb8r7/+cvtv5PJChQpZmTJl3PICBQqwz8ewb3XiTCfFJkyYYJ9++qnrl1tvvdWuvvrqY95XM/pcKFhH9Bx//PFurK9HY+o1Jl/j7Nl3g9u37LvBofkuNm3aZJdeeqm1bNnSHn30Uf7PjRME3QgsTa4UGXCL97cmAEL80H8QXn/pbO2GDRvcpC779u3LsB+9PtRjMlquZd7fkcuEz0BsZNafR1ueXn9GLtfJG/b52Pn1119d0H3aaafZTTfd5DIt/fr1c9mXyy+//Jj21cw+N/DHE0884SaynDlzppvAkH03mH37ww8/sO8GxOjRo23btm02cOBAN1Ee/+fGD4JuBFbRokXTHJB5fxcrVixGrUJ6TjnlFDcDcunSpd1//GeffbY7C//vf//blUel149eH2bUzypLjjxo1+O830XLkfvUD6o0yW5/KkuTug8jl6s/VSHBPh877dq1c9kVZbilevXqtnbtWps2bZoLuo9lX83ouXyX+xuUvfjiizZq1Cg766yz2HcD3Ldnnnkm+25A1KpVy/1UVVj37t3dFV8ir/Ah/J8bG4zpRmCVL1/eXWJG47o9Ko/TQZoO4BFfdKDujduW008/3f2noXFoOmsbSX97pabq5/SW63laJl7pauTvWo7cl1F/ZaU/9RlR8BW5XPu3gnivv9nnY0f7rxdwe5T19krAj2VfPdpzEX1DhgyxyZMnu+BMJapH6z/23bzft+y7eZv2wwULFqS4T8PyNN/JsRxD8X9udBF0I7CULdV4T2+CJtHkEjoLqLGfiB8LFy50EzNFno1dsWKF+8L3JktS6bDo5zfffOOu8yv6qX71aDIm3XS//jPRRE2Ry/W77mM8d2yoX1TK6JUTe32SUX/qM6ESSN2v/Vb7b+Ry7d/az5VVZZ+Prf/+97/u+uuRNLmdAu9j3Vc1YZ4mVfPG/nvLdT+ia+zYsfbqq6/ayJEjrVWrVuH72XeD27fsu3mbhuTdd999Kea4WL58uZu7SMdQ/J8bJ2I9fTrgp379+oVatWrlruU6f/58d93C9957j40eZ3SZC12upFu3bqHVq1e7a0zqMibPPvusW9awYUN3fW5dqkg/dd1u75JT33zzTeicc85x1+31rv2r6/l6dM1grUuXNdJNv0+aNCmG7zb/ibys1KFDh9y1tR988EF3rVj1jy4h5l2nW5eE0qX+dL93nW5dmsq7ZNw777zj9mPtz9qvtX/rM+Fhn49d36o/atSo4a6trUt8TZ061V1LW/toNPbV2267zT1Hz9U69DnhOt3Rv6zU2WefHRo1alSKa63rxr6btx2tb9l38zbtm+3bt3ffkTpO0jHUhRdeGHrhhRfYb+MIQTcCTdfu7dGjhzuo1wHc5MmTY90kZEAB1i233OL6SkH1mDFjwoGWDgjatWvnDrKvvfba0A8//JDiubq2r67xq+fq2pQ7duxI8Z/Ro48+GqpXr16oQYMGoSeeeCK8XuSO1NdyXrt2behf//qXC8gUNH/22WcpHq8DhhYtWrjrb+sa3t51nCODs0aNGoXq1q0b6t27d2jfvn3hZezzse1bnQzRSRLtq1dccUWak5zHsq9u27bNBelad7Nmzdw1hhFd2rfUp+ndhH03uH3Lvpu3bd682X2n6qS0jqHGjx8f/v5kv40PCfon1tl2AAAAAACCiIGtAAAAAAD4hKAbAAAAAACfEHQDAAAAAOATgm4AAAAAAHxC0A0AAAAAgE8IugEAAAAA8AlBNwAAAAAAPiHoBgAAedKRI0di3QQAADJF0A0AQD7VrFkzq1atmj377LOWlxw4cMCef/55e/TRRy0vnzC47rrrrEWLFhYKhVLcP23aNLv++uutQYMGdu6551rz5s3tgQcesKVLl+ZqP0+YMMHOOecc+/HHH3P0ugCA/4+gGwAA5Cn//ve/bfjw4bZ7927Lq2bOnGnfffed/etf/7KEhAR3399//20333yzDRw40L799lv3d/HixW3Dhg323nvvuWVTp07N9mslJSVZ+fLl7bjjjsvW8zp06GAFChSwvn37UlUAAMeAoBsAAOQpeTnYlsOHD9szzzxjhQsXtquvvjp8f//+/e3LL7+0okWL2n/+8x/7+uuvbcmSJfbRRx9ZkyZNXEb8scces+3bt2fr9V577TX79NNPXYCfHWXLlrXLLrvMZbo/+OCDbD0XAPB/CLoBAIAzZswYV4b80EMP2ezZs13ps8qbb7/9dtu6dastWLDArrrqKqtVq5Zdc801LlPr6dWrl3uugsVJkybZJZdcYuedd57dc889tnHjxhRbeOfOnTZ06FC79NJLrWbNmi6wGzVqlO3bty/8mFmzZrn1tW/f3saOHWu1a9e2pk2bujYtWrTIPeaNN95wj1EmWD777DO78cYb7YILLnBt1HpHjhxpBw8eDK9Xj9ftm2++sX79+rnH1q1b13r37u0yy5E+/PBD++c//+m2gUq9tR0i37MoGFUb9XqNGjVy6/njjz+O+olauHCha3PDhg3t+OOPd/etW7fO3nnnHfd7ly5d7Nprr7UiRYq4vytUqGBPPvmkPfzwwzZ69GgXlHuy8p5Tl5crkNffek9r1qxx70t9dfHFF9vEiRNTtPXyyy93P1966SX2EgDIoUI5fSIAAAgmBWXvvvuulSxZ0vbv3++C3I4dO9pvv/1mJUqUcGOqly9fbvfdd5/LwhYsWDD8XD1v27ZtrpRZQbSW//TTT/bWW2+59e3atcsFlOvXr3eP1336XeOH9boK7rxgU/TcH374wQWnpUqVsqpVq9rvv//u2qDSa91fqFAh97i7777bBZt6bWWRtV5llPUad911V5oS9S1btri2q50K8suVK+cCW3n77bete/fu7vdixYrZ3r173XZQsD5jxgw744wz3Hvt1q2by0CrHcrAaz16jH5mVM79ySefuJ8KuiMDfG9s9w033JDmOWXKlEnzHrL7nlNT3950003uZIO2p7bHiBEjrHr16nbRRRelaKOy7uq70qVLH3WdAIC0yHQDAIAUVL6szLMCLU3oJWvXrrXbbrvNvvrqK5fNFgVpuj+SAu7HH3/cBZ4vvviiGxOsTPfrr7/ulj/99NMuMDzhhBPszTffdK/xwgsvuIBR45hTj1lWQKnAVmXXepwyvfXr13fLrrjiClc2fdJJJ7lMsTLSrVu3do9VO6+88kr3OK03NZ080HMXL17sJguLDIY1mdkTTzzhfm/VqpVb1xdffOGy8grQdQJBAbLGleunVxaukwZqm7aJAvOMaNuIgluPVw2g4NrLfosqApSBjrxNnjzZLcvue05NJxIaN27s2q0x49omkdvBKzHXmHCVxGv9AIDsI9MNAABSUDZTZeSisu5XX33V/a6JvDTpl+7z7NmzJ8VzTzvtNGvXrl04S6qSa5VAK7ju1KmTzZ8/3y1TSbQXdOoxej0F4Vp+6623plint77ExMQMe0pl0Lop26xZvhV0rlixIt02isrjFVCKAlll073HqeRaJxREpdc6IaCbMsgKTHX79ddfXcZdxo8f75ZFjjdXkH7LLbek21aV6osy66lFVg14pfheWzzea2T3PadH21qVBaeeeqqdffbZrp9SP1fbXSXzmzdvztI6AQApEXQDAIAUlG31KNj0eEFi5Jji1NfKTh1IatZsSU5ODmfCpWLFiike5/2d3iRhyrRmZseOHTZgwABXpq2srIJ/r+2Rl+TyKNPuUZl65OMU6Kb3uMj3FvmY9MZwHy1A9baFl1lO/f61bq8PVO6tmzc2O3J8fHbfc3qOth08Xju9dgMAsofycgAAkPLgoED6hweps7DpST1pmpfV9YJIL4D2Jj/zeGO8UwfYCiJTt8e7xFakIUOG2Pvvv++y659//rkbb62J2jKiceAZrS/ypENkllnj2LXe1atXp2inJkBbtWqVuynbrJ/K2mdEY9O9MdUeBdQerxQ/NQXWx/Kec9qnXmad8dwAkDME3QAAIGoUdE+bNs39rgBUY6alXr167qdmNZdXXnnFVq5cGS7Fnjt3rvtds5NnFmB7AbOCQWVllW3XpGKiCcUUNCvTrIA0vWx8ZjRZm5eh12zemmRMk41pfLVmdh83bpydcsop7iYqLddjNNFY27Zt3UziR7uetmYjT50NV3n3P/7xD/f7U089ZdOnT3frFI0Rv/POO9Nkz6P5no/Gq06oUqVK1NYJAPkJ5eUAACBqVIo8cOBANxGZNzZYwZp3PWrNeK5yaAWICjI1y7aXSdUkZOnN3J2aV4qt8d+63JcC3Dp16tgvv/ziJgTTehQke5nhv/76K1vvQZl1zW6u2ct1STCdMFDwr0nU9P4UAOsxDz74oHucZjpXW3QCQNlrlaHr0l0ZUZuVNddJB2+WcNGEbMqs60SFLmemIF8l35Gl7Fq3xsBLNN9zRlSpoDJ2ZcQ1aRsAIPvIdAMAgKhRIDho0CAXTOtSWyqb1izm3rhgTcql62vrUlXK+CpIVRDduXNne+6551KMIc+InqvrSmtsuUqeldXt0aOHm3BNGV8FyApsvVnWFZh6Ze5Z1aZNG5fR1uuI3osCZL0XbwI4ZbWVldb1sUUBsoLtl19+OZwpT4+uN+5l+CNpm2lm8scee8wF1prFXCcuVMquyd50MkPBvVc1EO33nJ5ly5a5n3rvGV0CDQBwdAmhrM60AQAAkIFevXq5YLpJkyb2/PPPs52OQodeLVu2dFltXa5LAX286t27t7vmuE5ANG/ePNbNAYA8iUw3AABALlJWWiXqKlefN29e3G57Zdk1RlyZ/MiJ3gAA2UPQDQAAkMt0nfBzzjnHlZPHqxkzZrjAW2PN05vQDgCQNZSXAwAAAADgEzLdAAAAAAD4hKAbAAAAAACfEHQDAAAAAOATgm4AAAAAAHxC0A0AAAAAgE8IugEAAAAA8AlBNwAAAAAAPiHoBgAAAADAJwTdAAAAAACYP/4fDqFhduXvumQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Most Important Features:\n",
      "     Feature    Importance\n",
      "12         Z  31673.291016\n",
      "14         A  25156.460938\n",
      "15  S_1n_MeV  24204.935547\n",
      "16    Energy  21177.593750\n",
      "1      out_g  18813.681641\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance\n",
    "importance = xgb_model.get_feature_importance()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(importance['Feature'], importance['Importance'])\n",
    "ax.set_xlabel('Importance (Gain)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('XGBoost Feature Importance (Tier-Based Features)', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(importance.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}