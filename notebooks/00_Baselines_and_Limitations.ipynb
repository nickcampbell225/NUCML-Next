{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Notebook 00: Baselines and Limitations\n\n## Understanding Why Classical ML Fails for Nuclear Data\n\n**Learning Objective:** Understand *why* classical machine learning fails for nuclear data evaluation using real experimental data.\n\n### The Problem\n\nNuclear cross sections œÉ(E) are smooth, continuous functions of energy. They exhibit:\n- **Resonance peaks**: Sharp but smooth features\n- **Threshold behavior**: œÉ(E) = 0 for E < E_threshold, then rises smoothly\n- **Physical constraints**: Conservation laws, unitarity, causality\n\n### Why This Matters\n\nA reactor calculation uses millions of cross-section evaluations. If predictions are:\n- **Jagged** ‚Üí Unphysical neutron transport\n- **Discontinuous** ‚Üí Numerical instabilities\n- **Wrong at key energies** ‚Üí Incorrect k_eff (criticality)\n\nThis is the **Validation Paradox**: Low MSE ‚â† Safe Reactor!\n\n---\n\n## Part 1: The Naive Approach\n\nLet's examine why tree-based models struggle with real nuclear cross-section data from IAEA EXFOR."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.append('..')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\n\nfrom nucml_next.data import NucmlDataset\nfrom nucml_next.baselines import XGBoostEvaluator, DecisionTreeEvaluator\n\n# Set plotting style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n%matplotlib inline\n\n# Verify EXFOR data exists\nexfor_path = Path('../data/exfor_processed.parquet')\nif not exfor_path.exists():\n    raise FileNotFoundError(\n        f\"EXFOR data not found at {exfor_path}\\n\"\n        \"Please run: python scripts/ingest_exfor.py --exfor-root <path> --output data/exfor_processed.parquet\"\n    )\n\nprint(\"‚úì Imports successful\")\nprint(\"‚úì EXFOR data found\")\nprint(\"Welcome to NUCML-Next: Understanding ML Limitations with Real Nuclear Data\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Step 1.1: Load Real EXFOR Data (Tabular View)\n\nWe'll use the **tabular projection** of real IAEA EXFOR nuclear cross-section data - this is what classical ML expects."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load real EXFOR data in tabular mode\ndataset = NucmlDataset(\n    data_path='../data/exfor_processed.parquet',\n    mode='tabular'\n)\n\n# Project to tabular format with NAIVE features\n# This shows how classical ML sees the data: [Z, A, E, MT_onehot]\ndf_naive = dataset.to_tabular(mode='naive')\n\nprint(f\"Dataset shape: {df_naive.shape}\")\nprint(f\"\\nFeatures (Naive Mode):\")\nprint(df_naive.columns.tolist())\nprint(f\"\\nFirst few rows:\")\ndf_naive.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice:** The naive approach treats reactions as independent categories (MT_2, MT_18, etc.).\n",
    "\n",
    "**Problem:** This ignores physics! (n,2n) and (n,3n) are related - they differ by one neutron.\n",
    "\n",
    "But tree-based models don't know this. To them, MT=16 and MT=17 are just labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2: Train Decision Tree (The \"Villain\")\n",
    "\n",
    "We'll intentionally configure the tree to show the **staircase effect**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Decision Tree with limited depth (exaggerates stairs)\n",
    "dt_model = DecisionTreeEvaluator(\n",
    "    max_depth=6,          # Shallow tree = coarse stairs\n",
    "    min_samples_leaf=20,  # Large leaves = big steps\n",
    ")\n",
    "\n",
    "# Train on naive features\n",
    "dt_metrics = dt_model.train(df_naive)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Decision Tree Performance:\")\n",
    "print(\"=\"*60)\n",
    "for key, value in dt_metrics.items():\n",
    "    print(f\"  {key:20s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.3: The Failure Mode - Visualize the Staircase Effect\n",
    "\n",
    "Let's predict cross sections in a resonance region and see what happens..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for U-235 capture reaction in resonance region\n",
    "Z, A = 92, 235\n",
    "mt_code = 102  # (n,Œ≥) capture\n",
    "energy_range = (1.0, 100.0)  # 1-100 eV (resonance region)\n",
    "\n",
    "# Get ground truth\n",
    "mask = (dataset.df['Z'] == Z) & (dataset.df['A'] == A) & (dataset.df['MT'] == mt_code)\n",
    "df_truth = dataset.df[mask].copy()\n",
    "df_truth = df_truth[(df_truth['Energy'] >= energy_range[0]) & \n",
    "                     (df_truth['Energy'] <= energy_range[1])]\n",
    "\n",
    "# Get Decision Tree predictions (dense sampling to see steps)\n",
    "energies_dt, predictions_dt = dt_model.predict_resonance_region(\n",
    "    Z, A, mt_code, energy_range, num_points=1000, mode='naive'\n",
    ")\n",
    "\n",
    "# Plot the catastrophe\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Ground truth (smooth curve)\n",
    "ax.plot(df_truth['Energy'], df_truth['CrossSection'], \n",
    "        'b-', linewidth=2, label='Ground Truth (Physics)', alpha=0.7)\n",
    "\n",
    "# Decision Tree predictions (jagged stairs)\n",
    "ax.plot(energies_dt, predictions_dt, \n",
    "        'r-', linewidth=1.5, label='Decision Tree', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Energy (eV)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Cross Section (barns)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('The Staircase Effect: Why Decision Trees Fail\\nU-235 (n,Œ≥) Resonance Region',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotate the problem\n",
    "ax.annotate('Unphysical discontinuities!\\n(Real cross sections are smooth)',\n",
    "            xy=(30, predictions_dt[300]), xytext=(50, predictions_dt[300]*5),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2),\n",
    "            fontsize=10, color='red', fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  OBSERVATION: Decision Tree creates JAGGED predictions!\")\n",
    "print(\"    Real nuclear cross sections are SMOOTH.\")\n",
    "print(\"    These stairs would cause numerical instabilities in reactor codes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¥ Critical Insight #1: Piecewise Constant ‚â† Physics\n",
    "\n",
    "Decision trees partition feature space into rectangles:\n",
    "```\n",
    "if Energy < 10.5:\n",
    "    if Energy < 5.2:\n",
    "        return 150.0  # Constant!\n",
    "    else:\n",
    "        return 89.0   # Jump!\n",
    "else:\n",
    "    return 45.0\n",
    "```\n",
    "\n",
    "Real physics:\n",
    "```\n",
    "œÉ(E) = œÉ_0 * Œì / ((E - E_r)¬≤ + Œì¬≤/4)  # Smooth Breit-Wigner!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Can XGBoost Save Us?\n",
    "\n",
    "Let's try a more sophisticated ensemble method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBoost\n",
    "xgb_naive = XGBoostEvaluator(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    ")\n",
    "\n",
    "# Train on naive features\n",
    "xgb_metrics_naive = xgb_naive.train(df_naive)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"XGBoost Performance (Naive Features):\")\n",
    "print(\"=\"*60)\n",
    "for key, value in xgb_metrics_naive.items():\n",
    "    if value is not None:\n",
    "        print(f\"  {key:20s}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get XGBoost predictions\n",
    "energies_xgb, predictions_xgb = xgb_naive.predict_resonance_region(\n",
    "    Z, A, mt_code, energy_range, num_points=1000, mode='naive'\n",
    ")\n",
    "\n",
    "# Comparative plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Ground truth\n",
    "ax.plot(df_truth['Energy'], df_truth['CrossSection'], \n",
    "        'b-', linewidth=3, label='Ground Truth', alpha=0.7, zorder=1)\n",
    "\n",
    "# Decision Tree (stairs)\n",
    "ax.plot(energies_dt, predictions_dt, \n",
    "        'r--', linewidth=1.5, label='Decision Tree (Staircase)', alpha=0.6, zorder=2)\n",
    "\n",
    "# XGBoost (smoother but not smooth)\n",
    "ax.plot(energies_xgb, predictions_xgb, \n",
    "        'g-', linewidth=2, label='XGBoost (Better, but...)', alpha=0.8, zorder=3)\n",
    "\n",
    "ax.set_xlabel('Energy (eV)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Cross Section (barns)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('XGBoost vs Decision Tree: Improvement but Still Not Physics-Compliant',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì XGBoost is SMOOTHER (ensemble averaging)\")\n",
    "print(\"‚úó But still has micro-steps and can't guarantee smoothness\")\n",
    "print(\"‚úó No awareness of resonance physics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üü° Critical Insight #2: Ensembles Help, But...\n",
    "\n",
    "XGBoost averages many trees, which smooths predictions.\n",
    "\n",
    "**BUT:**\n",
    "- Still piecewise constant at fine scale\n",
    "- No guarantee of smoothness\n",
    "- Can't learn resonance physics (Breit-Wigner shape)\n",
    "- Poor extrapolation beyond training data\n",
    "\n",
    "---\n",
    "\n",
    "## Part 3: The Upgrade - Physics-Aware Features\n",
    "\n",
    "What if we give XGBoost *better features*?\n",
    "\n",
    "Instead of naive [Z, A, E, MT_onehot], use physics-derived features from the graph:\n",
    "- **Q-value**: Reaction energy\n",
    "- **Threshold**: E_threshold\n",
    "- **ŒîZ, ŒîA**: Nuclear topology\n",
    "\n",
    "This is the bridge to deep learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get physics-aware tabular projection\n",
    "df_physics = dataset.to_tabular(mode='physics')\n",
    "\n",
    "print(\"Physics-Aware Features:\")\n",
    "print(df_physics.columns.tolist())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df_physics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost with physics features\n",
    "xgb_physics = XGBoostEvaluator(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    ")\n",
    "\n",
    "xgb_metrics_physics = xgb_physics.train(df_physics)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"XGBoost Performance (Physics Features):\")\n",
    "print(\"=\"*60)\n",
    "for key, value in xgb_metrics_physics.items():\n",
    "    if value is not None:\n",
    "        print(f\"  {key:20s}: {value}\")\n",
    "\n",
    "print(\"\\nComparison with Naive Features:\")\n",
    "print(f\"  Test MSE (Naive):   {xgb_metrics_naive['test_mse']:.4e}\")\n",
    "print(f\"  Test MSE (Physics): {xgb_metrics_physics['test_mse']:.4e}\")\n",
    "improvement = (xgb_metrics_naive['test_mse'] - xgb_metrics_physics['test_mse']) / xgb_metrics_naive['test_mse'] * 100\n",
    "print(f\"  Improvement: {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get physics-mode predictions\n",
    "energies_xgb_phys, predictions_xgb_phys = xgb_physics.predict_resonance_region(\n",
    "    Z, A, mt_code, energy_range, num_points=1000, mode='physics'\n",
    ")\n",
    "\n",
    "# Final comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Ground truth\n",
    "ax.plot(df_truth['Energy'], df_truth['CrossSection'], \n",
    "        'b-', linewidth=3, label='Ground Truth (Physics)', alpha=0.8, zorder=1)\n",
    "\n",
    "# XGBoost naive\n",
    "ax.plot(energies_xgb, predictions_xgb, \n",
    "        'orange', linewidth=2, linestyle='--', label='XGBoost (Naive Features)', alpha=0.6, zorder=2)\n",
    "\n",
    "# XGBoost physics\n",
    "ax.plot(energies_xgb_phys, predictions_xgb_phys, \n",
    "        'g-', linewidth=2.5, label='XGBoost (Physics Features)', alpha=0.8, zorder=3)\n",
    "\n",
    "ax.set_xlabel('Energy (eV)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Cross Section (barns)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Physics Features Help... But We Can Do Better!\\nU-235 (n,Œ≥) Resonance Region',\n",
    "             fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=12, loc='best')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Physics features improve accuracy\")\n",
    "print(\"‚úì Model learns about thresholds and reaction energetics\")\n",
    "print(\"‚úó STILL can't guarantee smooth resonance curves\")\n",
    "print(\"‚úó STILL poor extrapolation\")\n",
    "print(\"‚úó No explicit physics constraints (unitarity, conservation laws)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üü¢ Critical Insight #3: Features Matter, But Architecture Matters More\n",
    "\n",
    "Physics-aware features help XGBoost understand reactions better.\n",
    "\n",
    "**BUT** the fundamental problem remains:\n",
    "- Tree-based models are **piecewise constant**\n",
    "- No inductive bias for **smoothness**\n",
    "- No way to encode **physical constraints**\n",
    "\n",
    "---\n",
    "\n",
    "## Part 4: Feature Importance Analysis\n",
    "\n",
    "Let's see what XGBoost \"thinks\" is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_physics = xgb_physics.get_feature_importance()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(importance_physics['Feature'], importance_physics['Importance'])\n",
    "ax.set_xlabel('Importance (Gain)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('XGBoost Feature Importance (Physics Mode)', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(importance_physics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### üéì Key Takeaway\n\n> **Low MSE on test data does NOT guarantee safe reactor predictions!**\n>\n> We need models that:\n> 1. Respect physics (smoothness, thresholds, unitarity)\n> 2. Extrapolate correctly (beyond training data)\n> 3. Prioritize safety-critical reactions (sensitivity weighting)\n>\n> This is why we need **Physics-Informed Deep Learning**.\n\n---\n\n## Next Steps\n\nIn **Notebook 01**, we'll:\n- Build the **Chart of Nuclides as a Graph**\n- Visualize nuclear topology with real EXFOR data\n- Understand how GNNs can capture isotope relationships\n\nIn **Notebook 02**, we'll:\n- Implement **GNN + Transformer**\n- Train on graph-structured real data\n- See **smooth, physics-compliant predictions**!\n\nIn **Notebook 03**, we'll:\n- Integrate with **OpenMC** for reactor validation\n- Solve the **Validation Paradox**\n- Achieve reactor-grade accuracy with real nuclear data\n\nContinue to `01_Data_Fabric_and_Graph.ipynb` ‚Üí"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}