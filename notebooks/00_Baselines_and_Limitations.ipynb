{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML for Nuclear Data: A Supervised Learning Starting Point\n",
    "\n",
    "This notebook trains and evaluates two classical supervised-learning models\n",
    "-- a Decision Tree and an XGBoost ensemble -- on neutron-induced\n",
    "cross-section data from the EXFOR database.\n",
    "\n",
    "### Why nuclear data?\n",
    "\n",
    "Nuclear cross sections describe the probability of a reaction occurring\n",
    "when a neutron strikes a target nucleus. They depend on:\n",
    "\n",
    "- **Energy** -- cross sections vary over many orders of magnitude as\n",
    "  incident energy changes from thermal (~0.01 eV) to fast (~20 MeV).\n",
    "- **Isotope** (Z, A) -- each target nucleus has a different cross-section\n",
    "  curve.\n",
    "- **Reaction channel** (MT code) -- fission, capture, elastic scattering,\n",
    "  (n,p), etc. each have distinct energy dependences.\n",
    "\n",
    "The EXFOR database aggregates experimental measurements from laboratories\n",
    "worldwide. Individual datasets vary in energy coverage, resolution, and\n",
    "reported uncertainties, making cross-section prediction a heterogeneous\n",
    "regression problem.\n",
    "\n",
    "### Supervised learning setup\n",
    "\n",
    "| | |\n",
    "|---|---|\n",
    "| **Inputs (features)** | Z, A, N, Energy, particle-emission vector, AME2020 nuclear properties |\n",
    "| **Target** | Cross section $\\sigma$ (barns) |\n",
    "| **Training set** | Full EXFOR database (all isotopes, neutron-induced) |\n",
    "| **Evaluation isotopes** | U-233 total XS (data-rich) and Cl-35 (n,p) (data-sparse) |\n",
    "\n",
    "### What this notebook covers\n",
    "\n",
    "- **Data loading** -- EXFOR measurements filtered to neutron-induced\n",
    "  reactions in the 0.01 eV -- 20 MeV range, with configurable feature tiers.\n",
    "- **Baseline models** -- Decision Tree and XGBoost, each with Bayesian\n",
    "  hyperparameter search so that results reflect tuned performance.\n",
    "- **Evaluation** -- predictions plotted against EXFOR data;\n",
    "  feature-importance analysis.\n",
    "- **Interpretation guidance** -- what the metrics and plots show, and what\n",
    "  to look for when reading the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Imports successful\n",
      "âœ“ EXFOR data found\n",
      "Welcome to NUCML-Next: Understanding ML Limitations with Real Nuclear Data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from nucml_next.data import NucmlDataset\n",
    "from nucml_next.baselines import XGBoostEvaluator, DecisionTreeEvaluator\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Verify EXFOR data exists\n",
    "exfor_path = Path('../data/exfor_test.parquet')\n",
    "if not exfor_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"EXFOR data not found at {exfor_path}\\n\"\n",
    "        \"Please run: python scripts/ingest_exfor.py --x4-db data/x4sqlite1.db --output data/exfor_processed.parquet\"\n",
    "    )\n",
    "\n",
    "print(\"âœ“ Imports successful\")\n",
    "print(\"âœ“ EXFOR data found\")\n",
    "print(\"Welcome to NUCML-Next: Understanding ML Limitations with Real Nuclear Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The cell below sets three groups of options that control the rest of the\n",
    "notebook:\n",
    "\n",
    "1. **Feature tiers** -- which AME2020 / NUBASE2020 nuclear-property columns\n",
    "   to include alongside the core coordinates (Z, A, N, Energy) and\n",
    "   particle-emission vector.\n",
    "2. **Transformation pipeline** -- log-scaling for energy and cross section,\n",
    "   optional feature standardisation.\n",
    "3. **Uncertainty weighting** -- whether to weight training samples by\n",
    "   inverse measurement uncertainty, and how to handle missing values.\n",
    "\n",
    "All settings are defined once here; every subsequent cell reads from these\n",
    "variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# USER CONFIGURATION: Feature Tiers and Transformations\n# ============================================================================\n# Change these settings in ONE place instead of scattered throughout the notebook\n\nfrom nucml_next.data.selection import TransformationConfig\n\n# ============================================================================\n# FEATURE TIER SELECTION\n# ============================================================================\n# Choose which AME2020/NUBASE2020 enrichment tiers to include\n#\n# Tier A (13 features) - ALWAYS INCLUDED:\n#   - Z, A, N, Energy (nuclear coordinates)\n#   - 9-feature Numerical Particle Vector:\n#     out_n, out_p, out_a, out_g, out_f, out_t, out_h, out_d, is_met\n#\n# Tier B (+2 features) - Geometric:\n#   + R_fm (nuclear radius)\n#   + kR (dimensionless interaction parameter)\n#\n# Tier C (+7 features) - Energetics: RECOMMENDED FOR BASELINES\n#   + Mass_Excess_MeV (mass excess)\n#   + Binding_Energy_MeV (total binding energy)\n#   + Binding_Per_Nucleon_MeV (B/A)\n#   + S_1n_MeV, S_2n_MeV (neutron separation energies)\n#   + S_1p_MeV, S_2p_MeV (proton separation energies)\n#\n# Tier D (+9 features) - Topological:\n#   + Spin, Parity (nuclear structure)\n#   + Isomer_Level, Half_Life_log10_s (log10-transformed half-life)\n#   + Valence_N, Valence_P (distance to magic numbers)\n#   + P_Factor (pairing: even-even/odd-odd)\n#   + Shell_Closure_N, Shell_Closure_P\n#\n# Tier E (+8 features) - Complete Q-values:\n#   + Q_alpha_MeV, Q_2beta_minus_MeV, Q_ep_MeV, etc.\n#   + All 8 reaction Q-values from AME2020\n\nSELECTED_TIERS = ['A', 'C']  # Change tiers HERE (only place to modify)\n\nprint(f\"Selected Feature Tiers: {SELECTED_TIERS}\")\nprint(f\"   Features: Tier A (core + particle vector) + Tier C (energetics)\")\nprint()\n\n# ============================================================================\n# TRANSFORMATION CONFIGURATION\n# ============================================================================\n# Configure log-scaling and feature scaling for ML training.\n#\n# ORDER OF OPERATIONS (forward transform):\n#   1. Log-transform cross-section: sigma' = log10(sigma + epsilon)\n#   2. Log-transform energy:        E' = log10(E)\n#   3. Scale ALL features:          X' = (X - min) / (max - min)\n#\n# This ensures the scaler sees compressed log-space values rather than\n# raw multi-order-of-magnitude physical values.\n#\n# For tree-based models (Decision Trees, XGBoost), feature scaling is NOT\n# mathematically necessary because trees only use value ordering.\n# However, MinMax scaling is cheap and doesn't hurt -- and it prepares\n# the pipeline for neural networks where scaling IS required.\n\nTRANSFORMATION_CONFIG = TransformationConfig(\n    # ============================================================================\n    # Target (cross-section) transformations\n    # ============================================================================\n    log_target=True,              # Enable log10 transform for cross-sections\n                                  # Stabilizes gradients and handles wide range (ub to kb)\n    \n    target_epsilon=1e-10,         # Epsilon for log(xs + epsilon) to prevent log(0)\n                                  # Increase if you have very small cross-sections\n    \n    log_base=10,                  # Logarithm base: 10 | 'e' | 2\n                                  # Base-10 is standard in nuclear physics\n    \n    # ============================================================================\n    # Energy transformations\n    # ============================================================================\n    log_energy=True,              # Enable log10 transform for energies\n                                  # Handles wide energy range (eV to MeV)\n    \n    energy_log_base=10,           # Energy log base: 10 | 'e' | 2\n    \n    # ============================================================================\n    # Feature standardization (MinMax, Z-score, etc.)\n    # ============================================================================\n    # Order: Log-transforms are applied FIRST, then feature scaling.\n    # The scaler is fitted on log-transformed values, so Energy in the\n    # scaler's view is log10(E), not raw eV.\n    \n    scaler_type='minmax',         # Feature scaling method:\n                                  # 'minmax'   = Min-max scaling to [0,1] [DEFAULT]\n                                  # 'standard' = Z-score normalization (X-mu)/sigma\n                                  # 'robust'   = Robust scaling using median and IQR\n                                  # 'none'     = No scaling\n    \n    scale_features='all',         # Which columns to scale:\n                                  # 'all'  = Scale every numeric column [DEFAULT]\n                                  # None   = Auto-detect numeric columns (same as 'all')\n                                  # List   = Explicit column names, e.g. ['Z', 'A', 'Energy']\n)\n\nprint(\"Transformation Configuration:\")\nprint(TRANSFORMATION_CONFIG)\nprint()\nprint(\"NOTE: MinMax scaling applied to ALL features AFTER log-transforms.\")\nprint(\"      Trees are scale-invariant, but this prepares the pipeline\")\nprint(\"      for neural networks and doesn't hurt tree performance.\")\nprint()\n\n# ============================================================================\n# UNCERTAINTY WEIGHTING CONFIGURATION\n# ============================================================================\n# Configure how to use experimental uncertainties during training.\n#\n# The EXFOR database contains measurement uncertainties for ~66% of cross-section\n# values. These uncertainties can be used to weight samples during training,\n# giving more influence to precise measurements and less to uncertain ones.\n#\n# Statistical basis: Inverse-variance weighting (w_i = 1/sigma_i^2) is the\n# optimal weighting for least-squares regression when errors are heteroscedastic.\n\nUSE_UNCERTAINTY_WEIGHTS = 'xs'    # Uncertainty weighting mode:\n                                  # None   = No weighting (equal weight)\n                                  # 'xs'   = Weight by cross-section uncertainty (1/sigma_xs^2)\n                                  # 'both' = Weight by XS AND energy uncertainty\n                                  #          (1/sigma_xs^2 * 1/sigma_E^2)\n\nMISSING_UNCERTAINTY_HANDLING = 'exclude'\n                                  # How to handle samples with missing uncertainties\n                                  # (only used when USE_UNCERTAINTY_WEIGHTS is not None):\n                                  # 'median'  = Assign median weight from valid samples (default)\n                                  # 'equal'   = Assign weight of 1.0\n                                  # 'exclude' = Exclude samples without valid uncertainty\n                                  #             (equivalent to requiring uncertainty)\n\nprint(\"=\" * 80)\nprint(\"Uncertainty Weighting Configuration:\")\nprint(f\"  USE_UNCERTAINTY_WEIGHTS:       {USE_UNCERTAINTY_WEIGHTS}\")\nprint(f\"  MISSING_UNCERTAINTY_HANDLING:  '{MISSING_UNCERTAINTY_HANDLING}'\")\nif USE_UNCERTAINTY_WEIGHTS:\n    print(f\"\\n  NOTE: Uncertainty weighting enabled (mode='{USE_UNCERTAINTY_WEIGHTS}').\")\n    print(\"        Samples with lower uncertainty get higher weight.\")\n    if MISSING_UNCERTAINTY_HANDLING == 'exclude':\n        print(\"\\n  NOTE: MISSING_UNCERTAINTY_HANDLING='exclude' will filter to only\")\n        print(\"        samples with valid uncertainty (~66% of data).\")\nprint()\nprint(\"To change settings, modify SELECTED_TIERS and TRANSFORMATION_CONFIG above\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Outlier Detection & Interactive Threshold Selection\n\nThe ingested Parquet contains outlier detection results (if `--outlier-method` \nwas used during ingestion). Two methods are available:\n\n**Per-experiment method (recommended):**\n- Fits independent GPs to each EXFOR experiment (Entry)\n- Builds consensus to identify discrepant experiments\n- Columns: `experiment_outlier`, `point_outlier`, `z_score`, `experiment_id`\n\n**Legacy SVGP method:**\n- Pools all experiments per (Z, A, MT) group\n- Point-level z-scores only\n\nThe interactive explorer below lets you browse any (Z, A, MT) group, \nvisualise the GP predictive distribution, adjust the z-score threshold, \nand see how inlier/outlier counts change in real time.\n\nIf the Parquet does **not** contain outlier columns, this section is skipped\nautomatically and all data is retained."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Interactive Outlier Threshold Explorer ────────────────────────────────────\n# Select any (Z, A, MT) group, adjust the z-score threshold, and inspect\n# the GP fit + probability surface interactively.\n\nEXFOR_DATA_PATH = '../data/exfor_processed.parquet'\n\n# ============================================================================\n# UNCERTAINTY VISIBILITY ON PLOTS\n# ============================================================================\n# When True, EXFOR scatter plots will show ONLY points that have a valid\n# (non-NaN, positive) cross-section uncertainty value.  This lets you\n# preview exactly which measurements survive if you set\n# MISSING_UNCERTAINTY_HANDLING = 'exclude' in cell 3.\n#\n# When False (default), all points are shown regardless of whether they\n# have reported uncertainty.\n\nPLOT_ONLY_WITH_UNCERTAINTY = False   # True  = hide points lacking XS uncertainty\n                                     # False = show all points (default)\n\n# Check for outlier detection columns (supports both per-experiment and SVGP methods)\n_check_cols = ['z_score']\ntry:\n    _raw_check = pd.read_parquet(EXFOR_DATA_PATH, columns=_check_cols)\nexcept Exception:\n    _raw_check = pd.DataFrame()\n\nhas_outlier_data = 'z_score' in _raw_check.columns and _raw_check['z_score'].notna().any()\n\nif has_outlier_data:\n    from nucml_next.visualization.threshold_explorer import ThresholdExplorer\n    explorer = ThresholdExplorer(EXFOR_DATA_PATH)\n    explorer.show()\nelse:\n    print(\"Outlier columns not found -- run ingestion with --outlier-method to enable\")\n    print(\"  Per-experiment (recommended): --outlier-method experiment\")\n    print(\"  Legacy SVGP:                  --outlier-method svgp\")\n    print(\"\\nProceeding without outlier filtering.\\n\")\ndel _raw_check"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Set outlier threshold (used by DataSelection below) ──────────────────────\n# Adjust this value based on the interactive explorer above.\n# Set to None to disable outlier filtering entirely.\n\nZ_THRESHOLD = 3.0   # z-score threshold for outlier removal\n                    # Used with --outlier-method experiment or svgp\n                    # Recommended: 3.0 (removes ~1-2% of data in typical runs)\n                    # Set to None to keep all data\n\n# ============================================================================\nprint(f\"Outlier z-score threshold: {Z_THRESHOLD}\")\nif Z_THRESHOLD is not None:\n    print(f\"  Points with z_score > {Z_THRESHOLD} will be excluded from training.\")\n    print(f\"  (For per-experiment method, 'experiment_outlier' flag is also available)\")\nelse:\n    print(\"  Outlier filtering disabled -- all data will be used.\")\nprint()\nprint(f\"Plot uncertainty filter: PLOT_ONLY_WITH_UNCERTAINTY = {PLOT_ONLY_WITH_UNCERTAINTY}\")\nif PLOT_ONLY_WITH_UNCERTAINTY:\n    print(\"  Plots will show ONLY points with valid cross-section uncertainty.\")\n    print(\"  This previews the training set when MISSING_UNCERTAINTY_HANDLING = 'exclude'.\")\nelse:\n    print(\"  Plots will show all data points (including those without uncertainty).\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: EXFOR-derived processed dataset\n",
    "\n",
    "The notebook loads a Parquet file produced by the NUCML-Next ingestion\n",
    "pipeline (`scripts/ingest_exfor.py`). A `DataSelection` object specifies\n",
    "the selection constraints used here for consistency:\n",
    "\n",
    "- **Projectile**: neutron only.\n",
    "- **Energy range**: 1e-5 eV to 2e7 eV (thermal through fast reactor\n",
    "  energies).\n",
    "- **Reaction channels**: all physical MT codes, including bookkeeping\n",
    "  channels (MT 0, 1, >= 9000).\n",
    "- **Validity filter**: rows with NaN or non-positive cross sections are\n",
    "  dropped so that log-transforms are well-defined.\n",
    "\n",
    "The full training set contains all isotopes. Two evaluation isotopes are\n",
    "loaded separately:\n",
    "\n",
    "| Isotope | Reaction | Role |\n",
    "|---------|----------|------|\n",
    "| U-233 | Total XS (MT 1) | Data-rich: thousands of EXFOR points |\n",
    "| Cl-35 | (n,p) (MT 103) | Data-sparse: tens of EXFOR points |\n",
    "\n",
    "Comparing a data-rich and a data-sparse case illustrates how model\n",
    "behaviour changes with measurement density.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:33:01.695938Z",
     "iopub.status.busy": "2026-01-26T21:33:01.694354Z",
     "iopub.status.idle": "2026-01-26T21:34:53.672027Z",
     "shell.execute_reply": "2026-01-26T21:34:53.655001Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATA SELECTION & LOADING\n",
    "# ============================================================================\n",
    "# Physics-aware selection with predicate pushdown for efficient loading.\n",
    "\n",
    "from nucml_next.data import DataSelection\n",
    "from nucml_next.experiment import HoldoutConfig, ExperimentManager, compute_holdout_metrics\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA SELECTION & LOADING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE-SPACE HOLDOUT CONFIGURATION\n",
    "# ============================================================================\n",
    "# Define holdout rules to measure extrapolation accuracy on unseen data.\n",
    "# Rules are AND-intersected within, OR-unioned across (any match => holdout).\n",
    "#\n",
    "# Supported keys:\n",
    "#   Z, A            — isotope (int)\n",
    "#   MT              — reaction channel (int or list)\n",
    "#   energy_range    — (E_min, E_max) in eV\n",
    "#   xs_range        — (XS_min, XS_max) in barns\n",
    "#   Entry           — EXFOR Entry ID(s) (str or list)\n",
    "#\n",
    "# Examples (uncomment to enable):\n",
    "#   {'Z': 92, 'A': 233}                         — hold out ALL U-233 data\n",
    "#   {'Z': 92, 'A': 235, 'MT': 102,\n",
    "#    'energy_range': (1e-3, 1.0)}               — U-235 capture in resonance region\n",
    "#   {'MT': 18}                                  — hold out ALL fission data\n",
    "#   {'xs_range': (1e-6, 1e-3)}                  — hold out low cross-section points\n",
    "\n",
    "HOLDOUT_CONFIG = HoldoutConfig(rules=[\n",
    "    # ── Uncomment rules below to enable holdout ──────────────────────────\n",
    "    # {'Z': 92, 'A': 233},\n",
    "    # {'Z': 92, 'A': 235, 'MT': 102, 'energy_range': (1e-3, 1.0)},\n",
    "    # {'MT': 18},\n",
    "])\n",
    "\n",
    "holdout_config = HOLDOUT_CONFIG if HOLDOUT_CONFIG.rules else None\n",
    "\n",
    "if holdout_config:\n",
    "    print(f\"\\nPhase-Space Holdout: {len(holdout_config.rules)} rule(s)\")\n",
    "    print(holdout_config)\n",
    "else:\n",
    "    print(\"\\nPhase-Space Holdout: DISABLED\")\n",
    "\n",
    "# ============================================================================\n",
    "# DATA SELECTION\n",
    "# ============================================================================\n",
    "training_selection = DataSelection(\n",
    "    # ========================================================================\n",
    "    # PROJECTILE SELECTION\n",
    "    # ========================================================================\n",
    "    projectile='neutron',          # Options: 'neutron' | 'all'\n",
    "                                   # 'neutron' = Only neutron-induced reactions (reactor physics)\n",
    "                                   # 'all' = All projectiles (n, p, d, α, γ, etc.)\n",
    "\n",
    "    # ========================================================================\n",
    "    # ENERGY RANGE (eV)\n",
    "    # ========================================================================\n",
    "    energy_min=1e-5,               # Minimum energy in eV (1e-5 = 0.01 eV, thermal neutrons)\n",
    "    energy_max=2e7,                # Maximum energy in eV (2e7 = 20 MeV, reactor physics upper bound)\n",
    "                                   # Common ranges:\n",
    "                                   #   - Thermal: 1e-5 to 1 eV\n",
    "                                   #   - Resonance: 1 to 1e4 eV\n",
    "                                   #   - Fast: 1e4 to 2e7 eV (20 MeV)\n",
    "                                   #   - High energy: up to 1e9 eV (1 GeV)\n",
    "\n",
    "    # ========================================================================\n",
    "    # REACTION (MT) MODE SELECTION\n",
    "    # ========================================================================\n",
    "    mt_mode='all_physical',        # Options:\n",
    "                                   # 'reactor_core'   → Essential for reactor modeling\n",
    "                                   #                    (MT 2, 4, 16, 18, 102, 103, 107)\n",
    "                                   #                    [elastic, inelastic, (n,2n), fission,\n",
    "                                   #                     capture, (n,p), (n,α)]\n",
    "                                   #\n",
    "                                   # 'threshold_only' → Reactions with energy thresholds\n",
    "                                   #                    (MT 16, 17, 103, 104, 105, 106, 107)\n",
    "                                   #                    [(n,2n), (n,3n), (n,p), (n,d), (n,t),\n",
    "                                   #                     (n,³He), (n,α)]\n",
    "                                   #\n",
    "                                   # 'fission_details'→ Fission breakdown channels\n",
    "                                   #                    (MT 18, 19, 20, 21, 38)\n",
    "                                   #                    [total fission, 1st chance, 2nd chance,\n",
    "                                   #                     3rd chance, 4th chance]\n",
    "                                   #\n",
    "                                   # 'all_physical'   → All MT codes including bookkeeping\n",
    "                                   #                    (MT 0, 1, and >=9000 now INCLUDED)\n",
    "                                   #\n",
    "                                   # 'custom'         → Use custom_mt_codes list (see below)\n",
    "\n",
    "    # ========================================================================\n",
    "    # EXCLUSION RULES\n",
    "    # ========================================================================\n",
    "    exclude_bookkeeping=False,     # Set to False to INCLUDE MT 0, 1, and MT >= 9000\n",
    "                                   # MT 0 = Undefined\n",
    "                                   # MT 1 = Total cross-section (sum of others)\n",
    "                                   # MT >= 9000 = Lumped reaction covariances\n",
    "\n",
    "    # ========================================================================\n",
    "    # DATA VALIDITY\n",
    "    # ========================================================================\n",
    "    drop_invalid=True,             # Drop NaN or non-positive cross-sections\n",
    "                                   # Essential for log-transform: log(σ) requires σ > 0\n",
    "                                   # Prevents training instabilities\n",
    "\n",
    "    # ========================================================================\n",
    "    # PHASE-SPACE HOLDOUT\n",
    "    # ========================================================================\n",
    "    holdout_config=holdout_config, # HoldoutConfig with intersection/union rule logic\n",
    "                                   # Replaces the legacy holdout_isotopes parameter\n",
    "                                   # Set to None to disable holdout filtering\n",
    "\n",
    "    # ========================================================================\n",
    "    # AME2020/NUBASE2020 ENRICHMENT TIER SELECTION\n",
    "    # ========================================================================\n",
    "    tiers=SELECTED_TIERS,          # Using centralized tier configuration from cell 3\n",
    "    transformation_config=TRANSFORMATION_CONFIG,  # Using centralized transformation config\n",
    "\n",
    "    # ========================================================================\n",
    "    # OUTLIER FILTERING (from SVGP detection, if available)\n",
    "    # ========================================================================\n",
    "    z_threshold=Z_THRESHOLD,       # Z-score threshold from cell 6 (None = no filtering)\n",
    "    include_outliers=Z_THRESHOLD is None,  # Remove outliers when threshold is set\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Training Selection:\")\n",
    "print(training_selection)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATASET\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Loading dataset with predicate pushdown...\")\n",
    "dataset_full = NucmlDataset(\n",
    "    data_path='../data/exfor_processed.parquet',\n",
    "    mode='tabular',\n",
    "    selection=training_selection,\n",
    ")\n",
    "\n",
    "# Retrieve holdout data (if configured)\n",
    "df_holdout = dataset_full.get_holdout_data()\n",
    "if df_holdout is not None:\n",
    "    print(f\"\\n[OK] Holdout reserved: {len(df_holdout):,} points \"\n",
    "          f\"({df_holdout.groupby(['Z','A']).ngroups} isotopes)\")\n",
    "else:\n",
    "    print(\"\\n[--] No holdout data\")\n",
    "\n",
    "# ============================================================================\n",
    "# PROJECT TO TABULAR FORMAT\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Projecting to tabular format (particle vector)...\")\n",
    "_extra_meta = ['Energy_Uncertainty'] if USE_UNCERTAINTY_WEIGHTS == 'both' else None\n",
    "df_tier = dataset_full.to_tabular(extra_metadata=_extra_meta)\n",
    "\n",
    "print(f\"\\n[OK] Training set: {len(df_tier):,} samples x {len(df_tier.columns)} columns\")\n",
    "print(f\"     Energy range: {df_tier['Energy'].min():.2e} – {df_tier['Energy'].max():.2e} eV\")\n",
    "\n",
    "# ============================================================================\n",
    "# UNCERTAINTY COVERAGE SUMMARY\n",
    "# ============================================================================\n",
    "if 'Uncertainty' in df_tier.columns:\n",
    "    valid_unc = df_tier['Uncertainty'].notna() & (df_tier['Uncertainty'] > 0)\n",
    "    pct = 100 * valid_unc.sum() / len(df_tier)\n",
    "    print(f\"     XS uncertainty: {valid_unc.sum():,} / {len(df_tier):,} ({pct:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(f\"Feature Tiers: {SELECTED_TIERS}\")\n",
    "TIER_NAMES = {'A': 'Core+Particle', 'B': 'Geometric', 'C': 'Energetics',\n",
    "              'D': 'Topological', 'E': 'Q-values'}\n",
    "for t in SELECTED_TIERS:\n",
    "    print(f\"  Tier {t}: {TIER_NAMES.get(t, 'Unknown')}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DATA DISTRIBUTION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Top 10 Isotopes:\")\n",
    "for (z, a), cnt in dataset_full.df.groupby(['Z', 'A']).size().nlargest(10).items():\n",
    "    elem = {92:'U', 17:'Cl', 94:'Pu', 26:'Fe', 8:'O', 1:'H', 82:'Pb',\n",
    "            6:'C', 13:'Al', 7:'N', 11:'Na', 79:'Au'}.get(z, f'Z{z}')\n",
    "    print(f\"  {elem}-{a:3d}: {cnt:>8,}\")\n",
    "\n",
    "print(f\"\\nTotal: {dataset_full.df.groupby(['Z','A']).ngroups} isotopes, \"\n",
    "      f\"{dataset_full.df['MT'].nunique()} MT codes, {len(dataset_full.df):,} points\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD EVALUATION ISOTOPES (U-233, Cl-35)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Loading evaluation targets (U-233, Cl-35)...\")\n",
    "eval_selection = DataSelection(\n",
    "    projectile='neutron',\n",
    "    energy_min=training_selection.energy_min,\n",
    "    energy_max=training_selection.energy_max,\n",
    "    mt_mode=training_selection.mt_mode,\n",
    "    exclude_bookkeeping=training_selection.exclude_bookkeeping,\n",
    "    drop_invalid=True,\n",
    "    tiers=SELECTED_TIERS,\n",
    ")\n",
    "\n",
    "dataset_eval = NucmlDataset(\n",
    "    data_path='../data/exfor_processed.parquet',\n",
    "    mode='tabular',\n",
    "    selection=eval_selection,\n",
    ")\n",
    "dataset_eval.df = dataset_eval.df[\n",
    "    ((dataset_eval.df['Z'] == 92) & (dataset_eval.df['A'] == 233)) |\n",
    "    ((dataset_eval.df['Z'] == 17) & (dataset_eval.df['A'] == 35))\n",
    "].copy()\n",
    "\n",
    "print(f\"[OK] Evaluation set: {len(dataset_eval.df):,} points\")\n",
    "for (z, a), grp in dataset_eval.df.groupby(['Z', 'A']):\n",
    "    iso = 'U' if z == 92 else 'Cl'\n",
    "    print(f\"     {iso}-{a}: {len(grp):,} (MT: {sorted(grp['MT'].unique())})\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature representation\n",
    "\n",
    "Reaction channels (MT codes) are encoded as a 9-component\n",
    "**particle-emission vector** (`out_n`, `out_p`, `out_a`, ..., `is_met`)\n",
    "rather than one-hot indicators. This preserves information about which\n",
    "particles are emitted in each reaction.\n",
    "\n",
    "If Tier C is selected, seven AME2020 energetics columns (mass excess,\n",
    "binding energies, separation energies) are appended. The full set of\n",
    "available tiers is documented in the configuration cell above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1 -- Decision Tree\n",
    "\n",
    "A single Decision Tree is trained on the full EXFOR dataset. To ensure the\n",
    "results reflect a well-tuned model rather than arbitrary defaults, Bayesian\n",
    "hyperparameter optimisation (hyperopt with TPE) is run first, and the best\n",
    "parameters are then used to train on the complete training set.\n",
    "\n",
    "A Decision Tree partitions feature space into axis-aligned rectangles,\n",
    "returning a constant prediction within each rectangle. The resulting\n",
    "cross-section curve is therefore piecewise constant by construction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:34:53.746941Z",
     "iopub.status.busy": "2026-01-26T21:34:53.743177Z",
     "iopub.status.idle": "2026-01-26T21:45:39.106787Z",
     "shell.execute_reply": "2026-01-26T21:45:39.099894Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================================\n# HYPERPARAMETER OPTIMIZATION FOR DECISION TREE\n# ============================================================================\n# Find good hyperparameters using one of the available search strategies.\n# The final model is always retrained on FULL data with the best parameters.\n\n# ============================================================================\n# USER CONFIGURATION: Hyperparameter Search Space\n# ============================================================================\n\n# ============================================================================\n# OPTIMIZATION METHOD SELECTION\n# ============================================================================\n# Choose the hyperparameter search strategy:\n#\n# 'bayesian' (RECOMMENDED):\n#   - Uses Tree-structured Parzen Estimator (TPE) via hyperopt\n#   - Most sample-efficient; learns from previous evaluations\n#   - Best for expensive model evaluations and complex parameter interactions\n#   - Requires: pip install hyperopt\n#\n# 'grid':\n#   - Exhaustive search over all parameter combinations\n#   - Guaranteed to find optimum within the grid\n#   - Time complexity: O(n^k) - exponential in number of parameters\n#   - Best for: Small search spaces where exhaustive search is feasible\n#\n# 'random':\n#   - Randomly samples parameter combinations\n#   - Typically finds good solutions faster than grid search\n#   - Good for: Large search spaces, continuous parameters\n#\n# 'halving':\n#   - Successive halving strategy (HalvingRandomSearchCV)\n#   - Progressively eliminates poor candidates using data subsets\n#   - Much faster than full random search on large datasets\n#   - Requires: sklearn >= 0.24\n\nDT_OPTIMIZATION_METHOD = 'bayesian'  # Options: 'bayesian' | 'grid' | 'random' | 'halving'\n\n# max_depth: Maximum tree depth\nDT_MIN_DEPTH = 60\nDT_MAX_DEPTH = 90\nDT_DEPTH_STEP = 2          # choices: 60, 62, 64, ..., 90\n\n# min_samples_split: Minimum samples required to split an internal node\nDT_MIN_MSS = 2\nDT_MAX_MSS = 16\nDT_MSS_STEP = 2            # choices: 2, 4, 6, ..., 16\n\n# min_samples_leaf: Minimum samples required at a leaf node\nDT_MIN_MSL = 1\nDT_MAX_MSL = 12\nDT_MSL_STEP = 1            # choices: 1, 2, 3, ..., 12\n\n# min_impurity_decrease: Minimum impurity decrease required for a split.\n# Default 0.0 means no regularization via impurity threshold.\n# When subsampling for hyperparameter search, absolute impurity thresholds\n# found on subsampled data over-regularize on full data (e.g. depth 36,\n# 1085 leaves on 8M samples). The structural params (max_depth, mss, msl)\n# already control complexity and generalise correctly from subsample to\n# full data. Set to a small positive value (e.g. 1e-7) only if you observe\n# severe overfitting.\nDT_MIN_IMPURITY_DECREASE = 0.0\n\n# Bayesian search budget (only used when DT_OPTIMIZATION_METHOD = 'bayesian')\nDT_MAX_EVALS = 200         # number of hyperopt trials\n\n# ============================================================================\n# VALIDATION STRATEGY\n# ============================================================================\n# How to evaluate candidate hyperparameters during the search.\n#\n# 'holdout' (default):\n#   Splits data into train / val / test.\n#   Each hyperopt trial trains on \"train\" and evaluates on \"val\".\n#   The final model is retrained on train+val and scored on the \"test\" set.\n#   Faster and simpler -- recommended for large datasets.\n#\n# 'kfold':\n#   Each hyperopt trial runs k-fold CV on the train+val portion.\n#   The final model is retrained on train+val and scored on a held-out test set.\n#   More robust estimate of generalisation but k-times slower per trial.\n\nDT_VALIDATION_METHOD = 'holdout'   # 'holdout' or 'kfold'\n\n# Holdout split percentages (must sum to 1.0)\nDT_TRAIN_FRACTION = 0.70          # 70% for training during search\nDT_VAL_FRACTION   = 0.15          # 15% for validation during search\nDT_TEST_FRACTION  = 0.15          # 15% held out for final evaluation\n\n# K-fold settings (only used when DT_VALIDATION_METHOD = 'kfold')\nDT_CV = 3                         # number of cross-validation folds\n\n# Data subsampling for hyperparameter search\n# The full dataset can be millions of rows. Running cross-validated hyperopt\n# on all of it is slow. Subsampling uses a random fraction for the search,\n# then the final model is retrained on the FULL dataset with the best params.\nDT_SUBSAMPLE_FRACTION = 0.1    # fraction of data for search (0.1 = 10%)\nDT_SUBSAMPLE_MAX = 1_000_000   # hard cap on subsample size\n\n# ============================================================================\n# BUILD SEARCH SPACE FROM SETTINGS\n# ============================================================================\nDT_DEPTH_OPTIONS = list(range(DT_MIN_DEPTH, DT_MAX_DEPTH + 1, DT_DEPTH_STEP))\nDT_MSS_OPTIONS = list(range(DT_MIN_MSS, DT_MAX_MSS + 1, DT_MSS_STEP))\nDT_MSL_OPTIONS = list(range(DT_MIN_MSL, DT_MAX_MSL + 1, DT_MSL_STEP))\nDT_MSS_RANGE = (DT_MIN_MSS, DT_MAX_MSS)\nDT_MSL_RANGE = (DT_MIN_MSL, DT_MAX_MSL)\n\nprint(\"=\" * 80)\nprint(\"DECISION TREE HYPERPARAMETER OPTIMIZATION\")\nprint(\"=\" * 80)\nprint(f\"Optimization:\")\nprint(f\"  method:                {DT_OPTIMIZATION_METHOD}\")\nprint(f\"Search space:\")\nprint(f\"  max_depth:             {DT_MIN_DEPTH} to {DT_MAX_DEPTH} (step {DT_DEPTH_STEP}) -> {len(DT_DEPTH_OPTIONS)} choices\")\nprint(f\"  min_samples_split:     {DT_MIN_MSS} to {DT_MAX_MSS} (step {DT_MSS_STEP}) -> {len(DT_MSS_OPTIONS)} choices\")\nprint(f\"  min_samples_leaf:      {DT_MIN_MSL} to {DT_MAX_MSL} (step {DT_MSL_STEP}) -> {len(DT_MSL_OPTIONS)} choices\")\nprint(f\"  min_impurity_decrease: {DT_MIN_IMPURITY_DECREASE} (fixed)\")\nif DT_OPTIMIZATION_METHOD == 'bayesian':\n    print(f\"  max_evals:             {DT_MAX_EVALS}\")\nprint(f\"Validation:\")\nprint(f\"  method:                {DT_VALIDATION_METHOD}\")\nif DT_VALIDATION_METHOD == 'holdout':\n    print(f\"  split:                 train={DT_TRAIN_FRACTION:.0%} / val={DT_VAL_FRACTION:.0%} / test={DT_TEST_FRACTION:.0%}\")\nelse:\n    print(f\"  cv folds:              {DT_CV}\")\nprint(f\"Subsampling:\")\nprint(f\"  fraction:              {DT_SUBSAMPLE_FRACTION*100:.0f}% (max {DT_SUBSAMPLE_MAX:,})\")\nprint(\"=\" * 80)\n\n# ============================================================================\n# RUN HYPERPARAMETER OPTIMIZATION\n# ============================================================================\ndt_optimizer = DecisionTreeEvaluator()\n\nopt_result_dt = dt_optimizer.optimize_hyperparameters(\n    df_tier,\n    method=DT_OPTIMIZATION_METHOD,\n    max_evals=DT_MAX_EVALS,\n    cv_folds=DT_CV,\n    verbose=True,\n    transformation_config=TRANSFORMATION_CONFIG,\n    max_depth_options=DT_DEPTH_OPTIONS,\n    min_samples_split_range=DT_MSS_RANGE,\n    min_samples_leaf_range=DT_MSL_RANGE,\n    min_impurity_decrease=DT_MIN_IMPURITY_DECREASE,\n    subsample_fraction=DT_SUBSAMPLE_FRACTION,\n    subsample_max_samples=DT_SUBSAMPLE_MAX,\n    # Validation strategy\n    validation_method=DT_VALIDATION_METHOD,\n    train_fraction=DT_TRAIN_FRACTION,\n    val_fraction=DT_VAL_FRACTION,\n    test_fraction=DT_TEST_FRACTION,\n    # Uncertainty-based sample filtering\n    use_uncertainty_weights=USE_UNCERTAINTY_WEIGHTS,\n    missing_uncertainty_handling=MISSING_UNCERTAINTY_HANDLING,\n)\n\n# ============================================================================\n# TRAIN FINAL MODEL WITH OPTIMAL HYPERPARAMETERS ON FULL DATA\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"TRAINING FINAL MODEL WITH OPTIMAL HYPERPARAMETERS\")\nprint(\"=\" * 80)\n\nprint(f\"\\nUncertainty Weighting:\")\nprint(f\"  use_uncertainty_weights:      {USE_UNCERTAINTY_WEIGHTS}\")\nprint(f\"  missing_uncertainty_handling: '{MISSING_UNCERTAINTY_HANDLING}'\")\nprint()\n\ndt_model = DecisionTreeEvaluator(**opt_result_dt['best_params'])\ndt_metrics = dt_model.train(\n    df_tier,\n    transformation_config=TRANSFORMATION_CONFIG,\n    use_uncertainty_weights=USE_UNCERTAINTY_WEIGHTS,\n    missing_uncertainty_handling=MISSING_UNCERTAINTY_HANDLING,\n)\n\n# ============================================================================\n# PHASE-SPACE HOLDOUT EVALUATION (Decision Tree)\n# ============================================================================\ndt_holdout_metrics = None\nif df_holdout is not None and len(df_holdout) > 0:\n    dt_holdout_metrics = compute_holdout_metrics(\n        dt_model, df_holdout, dt_model.pipeline)\n    print(\"\\n\" + \"=\" * 80)\n    print(\"PHASE-SPACE HOLDOUT METRICS (Decision Tree)\")\n    print(\"=\" * 80)\n    for k, v in dt_holdout_metrics.items():\n        if isinstance(v, float):\n            print(f\"  {k:30s}: {v:.6f}\")\n        else:\n            print(f\"  {k:30s}: {v}\")\n    print(\"=\" * 80)\nelse:\n    print(\"\\n[--] Holdout evaluation skipped (no holdout data)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree predictions\n",
    "\n",
    "The plots below overlay the Decision Tree's predictions on actual EXFOR\n",
    "data points for two evaluation isotopes.\n",
    "\n",
    "- **U-233 total XS** (data-rich): many training points are available for\n",
    "  this isotope/reaction.\n",
    "- **Cl-35 (n,p)** (data-sparse): the model relies on patterns learned from\n",
    "  other isotopes to fill gaps in energy coverage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:45:39.157756Z",
     "iopub.status.busy": "2026-01-26T21:45:39.155688Z",
     "iopub.status.idle": "2026-01-26T21:45:48.995366Z",
     "shell.execute_reply": "2026-01-26T21:45:48.991588Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================================\n# VISUALIZATION: Decision Tree predictions on evaluation isotopes\n# ============================================================================\n# IsotopePlotter handles all data filtering, prediction generation, and\n# plotting in a single call.  Just specify Z, A, MT.\n\nfrom nucml_next.visualization import IsotopePlotter\n\n# Energy range for all plots\nE_MIN_PLOT = 1e-4   # 10^-4 eV\nE_MAX_PLOT = 1e7    # 10^7 eV\n\n# ── Apply uncertainty visibility filter ──────────────────────────────────────\n# When PLOT_ONLY_WITH_UNCERTAINTY is True, the plot DataFrame excludes\n# points that lack a valid cross-section uncertainty so you can preview\n# exactly which measurements survive uncertainty-based filtering.\nif PLOT_ONLY_WITH_UNCERTAINTY and 'Uncertainty' in df_tier.columns:\n    _unc_mask = df_tier['Uncertainty'].notna() & (df_tier['Uncertainty'] > 0)\n    df_plot = df_tier.loc[_unc_mask].copy()\n    print(f\"[Uncertainty filter ON] Plotting {len(df_plot):,} / {len(df_tier):,} \"\n          f\"points ({100*len(df_plot)/len(df_tier):.1f}%) with valid XS uncertainty\")\nelse:\n    df_plot = df_tier\n    if PLOT_ONLY_WITH_UNCERTAINTY:\n        print(\"[Uncertainty filter ON but Uncertainty column not found -- showing all points]\")\n\n# ── Combine training + holdout for visualization ─────────────────────────────\n# The model was trained on df_tier only (excluding holdout). Combining them\n# here allows plotting holdout isotopes (their EXFOR ground truth comes from\n# df_holdout, but the model prediction is still based on training data).\nif df_holdout is not None and len(df_holdout) > 0:\n    df_plot_all = pd.concat([df_plot, df_holdout], ignore_index=True)\n    print(f\"[Holdout included] Combined {len(df_plot):,} training + {len(df_holdout):,} holdout = {len(df_plot_all):,} total for plotting\")\nelse:\n    df_plot_all = df_plot\n\n# Create plotter with combined data (no experiment_dir -- saving is in cell 19)\nplotter_dt = IsotopePlotter(\n    training_df=df_plot_all,\n    models={'Decision Tree': dt_model},\n    energy_range=(E_MIN_PLOT, E_MAX_PLOT),\n)\n\n# U-233 Total XS (data-rich)\nplotter_dt.plot(Z=92, A=233, MT=1)\n\n# Cl-35 (n,p) (data-sparse)\nplotter_dt.plot(Z=17, A=35, MT=103)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Decision Trees produce predictions\n",
    "\n",
    "A Decision Tree recursively splits on feature thresholds:\n",
    "\n",
    "```\n",
    "if Energy < 10.5:\n",
    "    if Energy < 5.2:\n",
    "        return 150.0   # constant within this leaf\n",
    "    else:\n",
    "        return 89.0    # discontinuous jump at boundary\n",
    "else:\n",
    "    return 45.0\n",
    "```\n",
    "\n",
    "Each leaf returns a single value, so the predicted cross-section curve is a\n",
    "step function regardless of how the tree is tuned. Compare this with the\n",
    "smooth Breit-Wigner form that describes resonance peaks in nuclear\n",
    "cross sections:\n",
    "\n",
    "$$\\sigma(E) = \\sigma_0 \\frac{\\Gamma}{(E - E_r)^2 + \\Gamma^2/4}$$\n",
    "\n",
    "---\n",
    "\n",
    "## Baseline 2 -- XGBoost\n",
    "\n",
    "XGBoost builds an ensemble of shallow decision trees via gradient boosting.\n",
    "Because many trees contribute to each prediction, the resulting curve is\n",
    "a sum of many step functions -- still piecewise constant, but with finer\n",
    "steps.\n",
    "\n",
    "The same Bayesian hyperparameter search strategy is applied here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:45:49.019962Z",
     "iopub.status.busy": "2026-01-26T21:45:49.018865Z",
     "iopub.status.idle": "2026-01-26T21:53:51.719087Z",
     "shell.execute_reply": "2026-01-26T21:53:51.711598Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================================\n# HYPERPARAMETER OPTIMIZATION FOR XGBOOST\n# ============================================================================\n# Use Randomized Search with subsampling to find good hyperparameters efficiently.\n# XGBoost is an ensemble of decision trees trained via gradient boosting.\n#\n# MEMORY OPTIMIZATION: The full dataset (~10M samples) is too large for grid search.\n# We use two strategies:\n#   1. SUBSAMPLING: Use 10% of data (~1M samples) for hyperparameter search\n#   2. RANDOMIZED SEARCH: Sample from parameter space instead of exhaustive grid\n#\n# The final model is still trained on FULL data with the best found parameters.\n\n# ============================================================================\n# USER CONFIGURATION: Hyperparameter Search Space\n# ============================================================================\n\n# ----------------------------------------------------------------------------\n# n_estimators: Number of boosting rounds (trees in the ensemble)\n# ----------------------------------------------------------------------------\n# More trees = more capacity, but diminishing returns after ~200-500\nXGB_ESTIMATORS = [100, 150, 200, 250, 300]  # Options to sample from\n\n# ----------------------------------------------------------------------------\n# max_depth: Maximum depth of each tree in the ensemble\n# ----------------------------------------------------------------------------\n# XGBoost trees are typically SHALLOWER than single Decision Trees\n# because the ensemble combines many weak learners.\nXGB_DEPTHS = [4, 5, 6, 7, 8, 10]  # Options to sample from\n\n# ----------------------------------------------------------------------------\n# learning_rate (eta): Step size shrinkage to prevent overfitting\n# ----------------------------------------------------------------------------\n# Lower = more conservative, needs more trees\n# Higher = faster learning, risk of overfitting\nXGB_LEARNING_RATES = [0.01, 0.05, 0.1, 0.15, 0.2]  # Options to sample from\n\n# ----------------------------------------------------------------------------\n# subsample: Fraction of training samples used per tree\n# ----------------------------------------------------------------------------\n# Lower values add randomness, reducing overfitting\nXGB_SUBSAMPLES = [0.7, 0.8, 0.9, 1.0]  # Options to sample from\n\n# ----------------------------------------------------------------------------\n# colsample_bytree: Fraction of features used per tree\n# ----------------------------------------------------------------------------\nXGB_COLSAMPLE = [0.7, 0.8, 0.9, 1.0]  # Options to sample from\n\n# ----------------------------------------------------------------------------\n# Subsampling for memory efficiency (data subsampling, not XGBoost subsample)\n# ----------------------------------------------------------------------------\nXGB_DATA_SUBSAMPLE_FRACTION = 0.1  # 10% of data for search\nXGB_DATA_SUBSAMPLE_MAX = 1_000_000  # Cap at 1M samples\n\n# ----------------------------------------------------------------------------\n# Randomized search settings\n# ----------------------------------------------------------------------------\nXGB_N_ITER = 20  # Number of random combinations to try\nXGB_CV = 2  # Cross-validation folds\nXGB_N_JOBS = -1  # Use all CPU cores\nXGB_SCORING = 'neg_mean_squared_error'\n\n# ============================================================================\n# BUILD PARAMETER GRID\n# ============================================================================\nXGB_PARAM_GRID = {\n    'n_estimators': XGB_ESTIMATORS,\n    'max_depth': XGB_DEPTHS,\n    'learning_rate': XGB_LEARNING_RATES,\n    'subsample': XGB_SUBSAMPLES,\n    'colsample_bytree': XGB_COLSAMPLE,\n}\n\nprint(\"=\" * 80)\nprint(\"XGBOOST HYPERPARAMETER OPTIMIZATION (Randomized Search + Subsampling)\")\nprint(\"=\" * 80)\nprint(f\"Parameter search space:\")\nprint(f\"  n_estimators:     {XGB_ESTIMATORS}\")\nprint(f\"  max_depth:        {XGB_DEPTHS}\")\nprint(f\"  learning_rate:    {XGB_LEARNING_RATES}\")\nprint(f\"  subsample:        {XGB_SUBSAMPLES}\")\nprint(f\"  colsample_bytree: {XGB_COLSAMPLE}\")\nprint(f\"\\nMemory optimization:\")\nprint(f\"  data_subsample_fraction: {XGB_DATA_SUBSAMPLE_FRACTION} ({XGB_DATA_SUBSAMPLE_FRACTION*100:.0f}% of data)\")\nprint(f\"  data_subsample_max:      {XGB_DATA_SUBSAMPLE_MAX:,}\")\nprint(f\"\\nOptimization settings:\")\nprint(f\"  method: Randomized Search (n_iter={XGB_N_ITER})\")\nprint(f\"  cv={XGB_CV}, n_jobs={XGB_N_JOBS}, scoring='{XGB_SCORING}'\")\nprint(\"=\" * 80)\n\n# ============================================================================\n# PREPARE DATA FOR RANDOMIZED SEARCH\n# ============================================================================\nfrom sklearn.model_selection import RandomizedSearchCV\nimport xgboost as xgb\nfrom nucml_next.data.transformations import TransformationPipeline\nfrom nucml_next.data.selection import TransformationConfig\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Use the centralized TRANSFORMATION_CONFIG from cell 3\n# This ensures XGBoost uses the same pipeline settings as the Decision Tree\nxgb_transform_config = TRANSFORMATION_CONFIG\n\n# Get feature columns (same logic as evaluators)\nexclude_columns = ['CrossSection', 'Uncertainty', 'Energy_Uncertainty', 'Entry', 'MT']\nnumeric_cols = df_tier.select_dtypes(include=[np.number]).columns.tolist()\nfeature_columns = [col for col in numeric_cols if col not in exclude_columns]\n\nX_features = df_tier[feature_columns]\ny = df_tier['CrossSection']\nenergy = df_tier['Energy']\n\n# Fit and transform\nxgb_pipeline = TransformationPipeline(config=xgb_transform_config)\nxgb_pipeline.fit(X_features, y, energy, feature_columns=feature_columns)\n\nX_transformed = xgb_pipeline.transform(X_features, energy)\ny_transformed = xgb_pipeline.transform_target(y)\n\nX_arr = X_transformed[feature_columns].values\ny_arr = y_transformed.values\n\n# Handle NaN/inf\nvalid_target = np.isfinite(y_arr)\nif not valid_target.all():\n    print(f\"  Removing {(~valid_target).sum():,} rows with invalid target\")\n    X_arr = X_arr[valid_target]\n    y_arr = y_arr[valid_target]\n\nif MISSING_UNCERTAINTY_HANDLING == 'exclude':\n    # Drop rows with any NaN/inf in features (no imputation)\n    nan_rows = np.isnan(X_arr).any(axis=1) | np.isinf(X_arr).any(axis=1)\n    if nan_rows.any():\n        n_before = len(X_arr)\n        X_arr = X_arr[~nan_rows]\n        y_arr = y_arr[~nan_rows]\n        print(f\"  Dropping {n_before - len(X_arr):,} rows with NaN/inf features (exclude mode)\")\nelse:\n    X_arr = np.nan_to_num(X_arr, nan=0.0, posinf=1e10, neginf=-1e10)\n\nprint(f\"\\nFull dataset: {X_arr.shape[0]:,} samples x {X_arr.shape[1]} features\")\n\n# ============================================================================\n# APPLY SUBSAMPLING FOR HYPERPARAMETER SEARCH\n# ============================================================================\nn_samples = len(X_arr)\ntarget_size = min(\n    int(n_samples * XGB_DATA_SUBSAMPLE_FRACTION),\n    XGB_DATA_SUBSAMPLE_MAX\n)\n\nif target_size < n_samples:\n    rng = np.random.default_rng(42)\n    subsample_idx = rng.choice(n_samples, size=target_size, replace=False)\n    X_arr_search = X_arr[subsample_idx]\n    y_arr_search = y_arr[subsample_idx]\n    print(f\"Subsampled for search: {n_samples:,} -> {target_size:,} samples ({100*target_size/n_samples:.1f}%)\")\nelse:\n    X_arr_search = X_arr\n    y_arr_search = y_arr\n\n# Split subsampled data for search\nX_train_search, X_test_search, y_train_search, y_test_search = train_test_split(\n    X_arr_search, y_arr_search, test_size=0.2, random_state=42\n)\n\n# Also split full data for final evaluation\nX_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n    X_arr, y_arr, test_size=0.2, random_state=42\n)\n\nprint(f\"Search train set: {len(X_train_search):,} samples\")\nprint(f\"Full train set:   {len(X_train_full):,} samples\")\n\n# ============================================================================\n# RUN RANDOMIZED SEARCH\n# ============================================================================\nprint(\"\\nStarting Randomized Search...\")\nprint(\"-\" * 80)\n\nbase_xgb = xgb.XGBRegressor(\n    random_state=42,\n    objective='reg:squarederror',\n    tree_method='hist',\n    n_jobs=-1,\n    verbosity=0,\n)\n\nrandom_search = RandomizedSearchCV(\n    base_xgb,\n    XGB_PARAM_GRID,\n    n_iter=XGB_N_ITER,\n    cv=XGB_CV,\n    scoring=XGB_SCORING,\n    n_jobs=XGB_N_JOBS,\n    verbose=2,\n    random_state=42,\n    return_train_score=True,\n)\n\nrandom_search.fit(X_train_search, y_train_search)\n\nprint(\"-\" * 80)\n\n# Get best params\nbest_params_xgb = random_search.best_params_.copy()\nbest_params_xgb['random_state'] = 42\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"SEARCH COMPLETE\")\nprint(\"=\" * 80)\nprint(f\"Best CV Score ({XGB_SCORING}): {random_search.best_score_:.6f}\")\nprint()\nprint(\"Optimal Hyperparameters (found on subsampled data):\")\nfor key, value in best_params_xgb.items():\n    if key != 'random_state':\n        print(f\"  {key:20s}: {value}\")\n\n# ============================================================================\n# RETRAIN ON FULL DATA WITH BEST PARAMETERS\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"RETRAINING ON FULL DATA WITH OPTIMAL HYPERPARAMETERS\")\nprint(f\"Training set: {len(X_train_full):,} samples\")\nprint(\"=\" * 80)\n\nfinal_xgb = xgb.XGBRegressor(\n    **best_params_xgb,\n    objective='reg:squarederror',\n    tree_method='hist',\n    n_jobs=-1,\n    verbosity=0,\n)\nfinal_xgb.fit(X_train_full, y_train_full)\n\n# Evaluate on full test set\ny_test_pred = final_xgb.predict(X_test_full)\n\n# Inverse transform\nimport pandas as pd\ny_test_pred_orig = xgb_pipeline.inverse_transform_target(pd.Series(y_test_pred)).values\ny_test_orig = xgb_pipeline.inverse_transform_target(pd.Series(y_test_full)).values\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\ntest_mse = mean_squared_error(y_test_orig, y_test_pred_orig)\ntest_mae = mean_absolute_error(y_test_orig, y_test_pred_orig)\ntest_r2 = r2_score(y_test_orig, y_test_pred_orig)\n\nprint(f\"\\nFinal Model Performance (on full test set):\")\nprint(f\"  Test MSE: {test_mse:.4e}\")\nprint(f\"  Test MAE: {test_mae:.4e}\")\nprint(f\"  Test R²:  {test_r2:.4f}\")\n\n# ============================================================================\n# TRAIN FINAL MODEL VIA EVALUATOR FOR CONSISTENT API\n# ============================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"TRAINING FINAL MODEL WITH EVALUATOR API\")\nprint(\"=\" * 80)\n\n# Show uncertainty weighting configuration\nprint(f\"\\nUncertainty Weighting:\")\nprint(f\"  use_uncertainty_weights:      {USE_UNCERTAINTY_WEIGHTS}\")\nprint(f\"  missing_uncertainty_handling: '{MISSING_UNCERTAINTY_HANDLING}'\")\nprint()\n\nxgb_model = XGBoostEvaluator(**best_params_xgb)\nxgb_metrics = xgb_model.train(\n    df_tier,\n    transformation_config=TRANSFORMATION_CONFIG,\n    use_uncertainty_weights=USE_UNCERTAINTY_WEIGHTS,\n    missing_uncertainty_handling=MISSING_UNCERTAINTY_HANDLING,\n)\n\n# Store pipeline for predictions\nxgb_model.pipeline = xgb_pipeline\nxgb_model.feature_columns = feature_columns\n\n# ============================================================================\n# PHASE-SPACE HOLDOUT EVALUATION (XGBoost)\n# ============================================================================\nxgb_holdout_metrics = None\nif df_holdout is not None and len(df_holdout) > 0:\n    xgb_holdout_metrics = compute_holdout_metrics(\n        xgb_model, df_holdout, xgb_model.pipeline)\n    print(\"\\n\" + \"=\" * 80)\n    print(\"PHASE-SPACE HOLDOUT METRICS (XGBoost)\")\n    print(\"=\" * 80)\n    for k, v in xgb_holdout_metrics.items():\n        if isinstance(v, float):\n            print(f\"  {k:30s}: {v:.6f}\")\n        else:\n            print(f\"  {k:30s}: {v}\")\n    print(\"=\" * 80)\nelse:\n    print(\"\\n[--] Holdout evaluation skipped (no holdout data)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:53:51.758854Z",
     "iopub.status.busy": "2026-01-26T21:53:51.756731Z",
     "iopub.status.idle": "2026-01-26T21:53:54.113670Z",
     "shell.execute_reply": "2026-01-26T21:53:54.110641Z"
    }
   },
   "outputs": [],
   "source": "# ============================================================================\n# XGBoost vs Decision Tree Comparison\n# ============================================================================\n# Both models on the same plot for direct visual comparison.\n# NOTE: df_plot_all is defined in cell 13 and includes holdout data for plotting.\n\nfrom nucml_next.visualization import IsotopePlotter\n\n# Create plotter with BOTH models for side-by-side comparison\nplotter_compare = IsotopePlotter(\n    training_df=df_plot_all,\n    models={'Decision Tree': dt_model, 'XGBoost': xgb_model},\n    energy_range=(E_MIN_PLOT, E_MAX_PLOT),\n)\n\n# U-233 Total XS — both models overlaid\nplotter_compare.plot(\n    Z=92, A=233, MT=1,\n    title='XGBoost vs Decision Tree\\nU-233 Total XS (Model trained on full EXFOR)',\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Decision Tree and XGBoost\n",
    "\n",
    "The comparison plot shows both models on U-233 total cross-section data.\n",
    "You may observe that:\n",
    "\n",
    "- XGBoost produces a smoother curve than the single Decision Tree because\n",
    "  it averages hundreds of weak learners.\n",
    "- Both models are piecewise constant by construction -- the underlying\n",
    "  architecture does not enforce continuity or smoothness.\n",
    "\n",
    "---\n",
    "\n",
    "## Feature importance\n",
    "\n",
    "XGBoost provides per-feature importance scores (gain-based). The bar chart\n",
    "below shows which input features the model relies on most heavily when\n",
    "making splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:53:54.124896Z",
     "iopub.status.busy": "2026-01-26T21:53:54.124306Z",
     "iopub.status.idle": "2026-01-26T21:53:54.598201Z",
     "shell.execute_reply": "2026-01-26T21:53:54.595351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Most Important Features:\n",
      "     Feature    Importance\n",
      "12         Z  31673.291016\n",
      "14         A  25156.460938\n",
      "15  S_1n_MeV  24204.935547\n",
      "16    Energy  21177.593750\n",
      "1      out_g  18813.681641\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance\n",
    "importance = xgb_model.get_feature_importance()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(importance['Feature'], importance['Importance'])\n",
    "ax.set_xlabel('Importance (Gain)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('XGBoost Feature Importance (Tier-Based Features)', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# SAVE EXPERIMENTS (Optional)\n# ============================================================================\n# After reviewing the training results above, decide whether to save:\n#   - Trained model files (.joblib)\n#   - Scaler/pipeline artifacts\n#   - Plots for each evaluation isotope\n#\n# Set SAVE_EXPERIMENTS = True to persist everything to disk.\n# Experiments are saved to: experiments/<model>_<timestamp>/\n\nSAVE_EXPERIMENTS = False  # Set to True to save models, scalers, and plots\n\nif SAVE_EXPERIMENTS:\n    from nucml_next.experiment import ExperimentManager\n    \n    exp_mgr = ExperimentManager()\n    \n    # ── Save Decision Tree experiment ────────────────────────────────────────\n    print(\"=\" * 80)\n    print(\"SAVING DECISION TREE EXPERIMENT\")\n    print(\"=\" * 80)\n    \n    dt_exp_dir = exp_mgr.save_experiment(\n        model=dt_model,\n        model_type='decision_tree',\n        selection=training_selection,\n        holdout_config=HOLDOUT_CONFIG if HOLDOUT_CONFIG.rules else None,\n        holdout_metrics=dt_holdout_metrics,\n        extra_metadata={\n            'metrics': dt_metrics,\n            'hyperopt_result': opt_result_dt,\n            'transformation_config': str(TRANSFORMATION_CONFIG),\n        },\n    )\n    print(f\"[OK] Decision Tree saved to: {dt_exp_dir}\")\n    \n    # Save Decision Tree plots\n    plotter_dt_save = IsotopePlotter(\n        training_df=df_plot_all,\n        models={'Decision Tree': dt_model},\n        energy_range=(E_MIN_PLOT, E_MAX_PLOT),\n        experiment_dir=dt_exp_dir,\n    )\n    plotter_dt_save.plot(Z=92, A=233, MT=1)\n    plotter_dt_save.plot(Z=17, A=35, MT=103)\n    print(f\"[OK] Decision Tree plots saved\")\n    \n    # ── Save XGBoost experiment ──────────────────────────────────────────────\n    print(\"\\n\" + \"=\" * 80)\n    print(\"SAVING XGBOOST EXPERIMENT\")\n    print(\"=\" * 80)\n    \n    xgb_exp_dir = exp_mgr.save_experiment(\n        model=xgb_model,\n        model_type='xgboost',\n        selection=training_selection,\n        holdout_config=HOLDOUT_CONFIG if HOLDOUT_CONFIG.rules else None,\n        holdout_metrics=xgb_holdout_metrics,\n        extra_metadata={\n            'metrics': xgb_metrics,\n            'hyperopt_result': {'best_params': best_params_xgb},\n            'transformation_config': str(TRANSFORMATION_CONFIG),\n        },\n    )\n    print(f\"[OK] XGBoost saved to: {xgb_exp_dir}\")\n    \n    # Save XGBoost plots\n    plotter_xgb_save = IsotopePlotter(\n        training_df=df_plot_all,\n        models={'XGBoost': xgb_model},\n        energy_range=(E_MIN_PLOT, E_MAX_PLOT),\n        experiment_dir=xgb_exp_dir,\n    )\n    plotter_xgb_save.plot(Z=92, A=233, MT=1)\n    plotter_xgb_save.plot(Z=17, A=35, MT=103)\n    print(f\"[OK] XGBoost plots saved\")\n    \n    print(\"\\n\" + \"=\" * 80)\n    print(\"ALL EXPERIMENTS SAVED SUCCESSFULLY\")\n    print(\"=\" * 80)\nelse:\n    print(\"SAVE_EXPERIMENTS = False\")\n    print(\"Set SAVE_EXPERIMENTS = True above and re-run this cell to save models and plots.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Conda base)",
   "language": "python",
   "name": "nucml-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}